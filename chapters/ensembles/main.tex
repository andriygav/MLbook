\section{Композиции классификаторов}

В задачах классификации, регрессии и прогнозирования нередки ситуации,    когда ни один алгоритм не обеспечивает нужного качества исходной модели.  В таких случаях на помощь приходит метод композиции классификаторов, также известный как ансамблевые методы, который сочетает несколько моделей для улучшения точности и устойчивости предсказаний по сравнению с использованием одиночного классификатора. Идея применения метода зключается в том, что объединение различных алгоритмов, каждый из которых может иметь свои сильные и слабые стороны, позволяет компенсировать недостатки отдельных моделей и достигать лучших результатов.

\subsection{Основные понятия}

\begin{itemize}
    \item $X^{l \cdot n} = (x_1, ... , x_\textit{l})$ --- обучающая выборка; $Y^\textit{l} = (y_1, ... , y_\textit{l})$ - вектор ответов;
\item $a_t: X \to Y, \ t = 1, \dots, T$ --- обучаемые алгоритмы $a_t: X \to Y$, аппроксимирующие неизвестную целевую зависимость $y_i = y^*(x_i)$.
\end{itemize}
   \textbf{Идея ансамблирования} (И.Ю.Журавлев): как из множества по отдельности плохих алгоритмов \textit{$ a_t(x) $} сделать один хороший?\\ 
   \\ 
   \textbf{Понятие композиции базовых алгоритмов}  
   
   Любой базовый алгоритм представим в следующем виде: $ a_t(x) = C(b_t(x))$ 
   
   $a_t(x): \textit{X}  \overset{b_t}{\longrightarrow} \textit{R} \overset{C}{\longrightarrow} \textit{Y}$, где \textit{C} --- решающее правило, \textit{R} --- удобное пространство оценок, $b_t$ - алгоритмические операторы.

    Основная идея ансамблирования заключается в декомпозиции базового алгоритма: создании \textbf{ансамбля} \textit{агрегирующей операции F }, которая комбинирует результаты нескольких базовых алгоритмов для повышения точности предсказаний перед использованием решающего правила: 

\ \
    
    $F: \mathbb{R}^T \to \mathbb{R}$ – агрегирующая операция базовых алгоритмов $a_1, \dots, a_T$

    $$a(x) = C(F(b_1(x), \dots, b_T(x)))$$

    
Суперпозиции вида $F(b_1, ... , b_T )$ являются отображениями из X в $\mathbb{R}$, то есть, опять-таки, алгоритмическими операторами. Это позволяет строить иерархические композиции, применяя определение ансамбля рекурсивно.
Ранее не существовало четкого разделения алгоритма на две составляющие. Выбор функции ансамблирования позволяет  агрегировать результат нескольких моделей для повышения итоговой точности предсказаний.

\ \
\begin{itemize}
    \item \textbf{Пример 1:} Классификация, $Y$ – конечное множество.
    
    В этом случае $R = Y$, а $C(b) \equiv b$ – решающее правило не используется.
    \item \textbf{Пример 2:} Классификация на 2 класса, $Y = \{-1, +1\}$, алгоритм имеет вид:
    $$a(x) = \text{sign}(b(x)),$$
    В этом случае алгоритмические операторы называют также вещественнозначными классификаторами \textit{(real-valued classifiers)}: $R = \mathbb{R}$, $b: X \to \mathbb{R}$, $C(b) \equiv \text{sign}(b)$
\end{itemize}

\subsection{Агрегирующие функции}
Агрегирующая функция должна удовлетворять ряду требованиям для обеспечения эффективного комбинирования предсказаний отдельных моделей. Перечислим их:
\begin{itemize}
    \item $F(b_1, \dots, b_T) \in [\min_t b_t, \max_t b_t]$ – среднее по Коши $\forall x$;
    \item $F(b_1, \dots, b_T)$ монотонно не убывает по всем $b_t$;
    \item \textbf{Интерпретируемость}: позволяла понять, как и почему принимается то или иное решение;
    \item  \textbf{Согласованность}: она должна обеспечивать согласованность результатов, т.е. предсказания ансамбля должны быть устойчивыми при малых изменениях в данных или в отдельных моделях.
\end{itemize}

\subsubsection*{Примеры агрегирующих функций:}
\begin{itemize}
    \item \textbf{Простое голосование} (\textit{simple voting}):
    $$F(b_1, \dots , b_T) = \frac{1}{T} \sum_{t=1}^T b_t$$
    \item \textbf{Взвешенное голосование} (\textit{weighted voting}):
    $$F(b_1, \dots, b_T) = \sum_{t=1}^T \alpha_t b_t, \quad \sum_{t=1}^T \alpha_t = 1, \quad \alpha_t \ge 0$$
    \item \textbf{Смесь алгоритмов} (\textit{mixture of experts}) с функциями компетентности (\textit{gating function}) $g_t: X \to \mathbb{R}$
    $$F(b_1, \dots, b_T, x) = \sum_{t=1}^T g_t(x) b_t(x)$$
\end{itemize}
\subsection{Проблема разнообразия базовых алгоритмов}
Явное преимущество композиции алгоритмов - возможность использовать независимые модели при построении ансамбля. Однако на практике  часто возникает ситуация, когда используется один и тот же алгоритм для создания ансамбля. Это, в свою очередь, приводит к тому, что модели в ансамбле не являются полностью независимыми.

Тем не менее, даже в случае использования одного и того же алгоритма, можно добиться некоторого разнообразия между моделями. Это может быть сделано за счет изменения параметров алгоритма, использования различных подмножеств данных для обучения (например, с помощью бэггинга, \textit{см. далее}) или применения различных техник предобработки данных. Кроме того, можно использовать различные способы инициализации или подходы к обучению, что также может привести к созданию моделей с различной производительностью.

\subsection{Методы стохастического ансамблирования} % Stochastic Ensemble Methods
Один из подходов к достижению этого разнообразия заключается в использовании методов рандомизации. Рандомизация позволяет генерировать различные обучающие подмножества данных, выбирать случайные подмножества признаков или изменять параметры моделей, что приводит к созданию разнообразного ансамбля и повышению его обобщающей способности. В данном разделе перечислены различные методы рандомизации, используемые для повышения разнообразия базовых моделей в ансамблях.

\ \

\textbf{Способы повышения разнообразия с помощью рандомизации:} 
\begin{itemize}
    \item \textit{bagging} (\textit{bootstrap aggregating}) – подвыборки обучающей выборки с возвращением: из исходной выборки размером \textit{N} образуется \textit{m} выборок, каждая из которых имеет тот же размер, что и исходный набор данных, но создаются они путем равномерного выбора элементов из исходного набора с возвратом. В каждую выборку попадает $1 - (1 - \frac{1}{\ell})^\ell$ уникальных объектов исходной выборки
    \item \textit{pasting} – случайные обучающие подвыборки 
    \item \textit{random subspaces} – случайные подмножества признаков 
    \item \textit{random patches} – случ. подмн-ва объектов и признаков 
    \item \textit{cross-validated committees} – выборка разбивается на $k$ блоков ($k$-fold) и делается $k$ обучений без одного блока 
\end{itemize}
Пусть $\mu: (G, U) \mapsto b$ – метод обучения по подвыборке $U \subseteq X^\ell$, использующий только признаки из $G \subseteq F^n = \{f_1, \dots, f_n\}$ 

\ \ 

\textbf{Алгоритм стохастического ансамблирования:}
\\
\textbf{Вход:} 

обучающая выборка $X^\ell$; параметры: 

$T$, $\ell'$ – объём обучающих подвыборок, 

$n'$ – размерность признаковых подпространств, 

$\varepsilon_1$ – порог качества базовых алгоритмов на обучении, 

$\varepsilon_2$ – порог качества базовых алгоритмов на контроле.
\\ 
\textbf{Выход:} 

базовые алгоритмы $b_t$,  $t = 1, \dots, T$: 
\begin{itemize}
    \item $U_t$ = случайная подвыборка объёма $\ell'$ из $X^\ell$; 
    \item $G_t$ = случайное подмножество мощности $n'$ из $F^n$; 
    \item $b_t = \mu(G_t, U_t)$; % $b_t = \mu(G_t, U_t)$;
    \item \textbf{если} $Q(b_t, U_t) > \varepsilon_1$ \textbf{то} не включать $b_t$ в ансамбль; 
    \item \textbf{если} $Q(b_t, X^\ell \setminus U_t) > \varepsilon_2$ \textbf{то} не включать $b_t$ в ансамбль; 
\end{itemize}
\ \
\textbf{Применение агрегирующей функции:} 

В простейшем случае используется простое голосование:
$$b(x) = \frac{1}{T} \sum_{t=1}^T  b_t(x)$$

\subsection*{Преобразование простого голосования во взвешенное}
Мы ожидаем, что некоторые базовые алгоритмы могут быть более точными и надежными, чем другие. Поэтому перейдем от простого голосования к взвешенному, где каждому классификатору присваивается определенный вес, отражающий его вклад в итоговое предсказание, для повышения точности и гибкости ансамбля.
\begin{itemize}
    \item \textbf{Линейная модель} над готовыми признаками $b_t(x)$:
    $$b(x) = \sum_{t=1}^T \alpha_t b_t(x)$$
    \item \textbf{Обучение:} МНК для регрессии, LR для классификации: 
    $$Q(\alpha, X^\ell) = \sum_{i=1}^\ell \mathcal{L}(b(x_i), y_i) \to \min_\alpha$$
    \textbf{Регуляризация:} $\alpha_t \ge 0$ либо LASSO: $\sum_{t=1}^T |\alpha_t| \
    \lambda$. 
\end{itemize}
Другой подход при выборе весов модели, заключается в предположении, что наши модели являются \textit{независимыми}. Тогда вохможно применение байесовского классификатора:
\begin{itemize}
    \item \textbf{Наивный байесовский классификатор} предполагает независимость с.в. $b_t(x)$ и даёт аналитическое решение: 
    $$\alpha_t = \ln \frac{1 - p_t}{p_t}, \quad t = 1, \dots, T,$$
    $p_t$ – оценка вероятности ошибки базового алгоритма $b_t$.
\end{itemize}




\subsection*{Задачи}
\subsubsection*{Задача 1}
Напишите декомпозицию алгоритма задачи классификации на K классов в общем случае. Каким в этом случае будет решающее правило С?
\subsubsection*{Задача 2}
Напишите декомпозицию алгоритма задачи регрессии в общем случае. Используется ли в данном случае решающее правило?
\subsubsection*{Задача 3}
Оцените уникальность подвыборки в методе bootstrap aggregating, для избыточного набора объектов исходной выборки, т.е. при $\ell \to \infty$.



\section{Стекинг в машинном оуении}


1. \textbf{Введение}  
С развитием машинного обучения и увеличением доступных данных разработчики ищут способы повысить точность моделей. Одной из популярных техник является \textbf{ансамблевое обучение} — метод, где несколько моделей объединяются для достижения лучшего результата.  

Стекинг (\textbf{Stacking}) — один из методов ансамблевого обучения. Это мощный инструмент, который помогает улучшить производительность за счет объединения предсказаний нескольких базовых моделей (например, линейных и нелинейных) с помощью метамодели.  

2. \textbf{Определение}  
Стекинг (\textbf{stacking}) — алгоритм ансамблирования, построение которого выглядит примерно так:

1)общая выборка разделяется на тренировочную и тестовую\\
2)тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются (n-1)  фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались\\
3)на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи


3. \textbf{Свойства стекинга} 

### Основные свойства:  \\
- \textbf{Гибкость:} базовые модели могут быть разными (деревья решений, нейронные сети, регрессии и т.д.). \\ 
- \textbf{Улучшение качества:} метамодель "учится" на ошибках базовых моделей, что позволяет улучшить общую точность.  \\
- \textbf{Устойчивость к переобучению:} при правильной настройке стекинг снижает риск переобучения за счет использования ансамбля моделей.  \\


4. \textbf{Пример использования}

### Задача: прогнозирование цены недвижимости  
Имеем датасет с характеристиками домов (площадь, количество комнат, район и т.д.) и их ценами. Требуется спрогнозировать цену на основе этих данных.  

### Шаги:  \\
1) Разделение данных:  \\
   - Тренировочные данные: 80\%  \\
   - Тестовые данные: 20\% \\
2) Обучение базовых моделей:\\
   - Модель 1: Линейная регрессия.  \\
   - Модель 2: Случайный лес.  \\
   - Модель 3: Градиентный бустинг.  \\
3) Формирование метаданных:\\ 
   - Собираем предсказания от каждой модели для тренировочного набора. Эти предсказания будут входными данными для метамодели.  \\
4) Обучение метамодели: \\
   - Используем простую линейную регрессию или логистическую регрессию как метамодель.  \\
5) Оценка:\\
   - Предсказываем цены на тестовом наборе с помощью метамодели.  \\

5. \textbf{Применение}\\
Стекинг можно и нужно использовать при решении реальных бизнес-задач, поскольку при умелом построении композиции алгоритмов он даже помогает бороться с типичными проблемами реальных данных. \\
Например при нехватки нужных данных, можем в качестве базовых алгоритмов использовать регрессию, а в качестве метаалгоритма использовать что-то основанное на деревьях, то ответ такого стекинга уже не будет совсем неадекватным даже при «повреждении» некоторых признаков.

6. ### \textbf{Преимущества, недостатки, зоны риска}

\textbf{Преимущества}:\\
- Гибкость. Стекинг позволяет комбинировать разные модели — как линейные, так и нелинейные. Это делает метод универсальным и применимым в различных задачах. Можно использовать несколько типов моделей, таких как решающие деревья, случайные леса, градиентный бустинг, нейронные сети и другие.\\
- Улучшение качества. В большинстве случаев стекинг позволяет достичь более высоких результатов по сравнению с использованием одной модели. Это происходит потому, что разные модели могут улавливать различные аспекты данных и компенсировать слабые стороны друг друга.\\
- Эффективное использование разнородных данных. Стекинг особенно полезен, когда разные модели хорошо работают с различными аспектами данных. \\
  
\textbf{Недостатки}:\\
- Сложность настройки. Выбор базовых моделей и метамодели требует тщательной настройки и кросс-валидации. Неправильно выбранная комбинация моделей может привести к ухудшению результата.\\
- Медленное обучение. Поскольку требуется обучить несколько базовых моделей, а затем еще и метамодель, процесс обучения может стать очень долгим и потребовать значительных вычислительных ресурсов.\\
- Сложность интерпретации. Многоуровневые ансамбли из нескольких моделей могут быть сложны для интерпретации.\\
- Риск переобучения. Если метамодель слишком сильно подстраивается под ошибки базовых моделей, есть риск переобучения.\\
\\
\\
\\
\\
\\
\textbf{Зоны риска}:\\
- Качество данных. Как и в других методах машинного обучения, стекинг сильно зависит от качества исходных данных. Если данные содержат много шума или выбросов, модели могут переобучиться, что приведет к снижению производительности.\\
- Сложность в реализации. Реализация стекинга требует аккуратного разделения данных на этапах обучения и тестирования, чтобы избежать утечек (leakage) между обучающими и тестовыми данными на разных уровнях. \\
- Переиспользование данных. Если стекинг не настроен правильно, например, если не используется кросс-валидация для получения метапризнаков, то возможно переобучение. Это может произойти из-за того, что одна и та же информация используется на нескольких этапах обучения, и модели начинают "запоминать" данные, а не обобщать закономерности.\\

### \textbf{Задачи}:

### \textbf{Задача 1}:

Вопрос: Представьте, что у вас есть три модели: решающее дерево, логистическая регрессия и случайный лес. Вы решили применить стекинг для улучшения качества предсказаний. Объясните, как будет выглядеть процесс применения стекинга на этих моделях, какие шаги необходимо выполнить, чтобы получить финальное предсказание.

Примерный ответ: \\
1. Обучение трех базовых моделей (решающее дерево, логистическая регрессия и случайный лес) на обучающей выборке.\\
2. Получение предсказаний от каждой из этих моделей на тестовой выборке. Эти предсказания становятся новыми признаками.\\
3. Обучение метамодели (например, логистической регрессии или другой модели) на этих новых признаках (предсказаниях базовых моделей).\\
4. Финальное предсказание делается на основе предсказаний метамодели.


### \textbf{Задача 2}: 

Вопрос: У вас есть набор данных для задачи бинарной классификации. Вы решили использовать стекинг с двумя базовыми моделями — решающим деревом и случайным лесом. Какой из следующих подходов к обучению метамодели будет корректным?

a) Обучить метамодель на тех же данных, что и базовые модели, чтобы улучшить результат.  \\
b) Обучить метамодель на кросс-валидационных предсказаниях базовых моделей на обучающей выборке.  \\
c) Обучить метамодель на случайных подвыборках данных, не связанных с предсказаниями базовых моделей.

Правильный ответ:  \\
b. Обучение метамодели на кросс-валидационных предсказаниях базовых моделей на обучающей выборке помогает избежать утечки данных и переобучения, так как метамодель не видит исходные данные, на которых обучались базовые модели.


### \textbf{Задача 3}:

Вопрос: Вам нужно реализовать стекинг вручную на Python (без использования готовых библиотек для стекинга). Опишите последовательность действий в виде простого псевдокода на основе следующего сценария:

- У вас есть обучающая выборка $X_{train}$ и метки $y_{train}$ \\
- Используйте две модели: логистическую регрессию и случайный лес \\
- Для метамодели используйте линейную регрессию.

Примерный ответ:\\
(Опишу примерный алгоритм)\\
1. Импорт нужных библмотек

2. Определение базовых моделей

3. Кросс-валидация для генерации метапризнаков

4. Обучение базовых моделей на каждом фолде
    
5. Получение предсказаний на валидационном фолде
    
6. Сохранение предсказаний как метапризнаки

7. Обучение метамодели на метапризнаках

8. Финальное предсказание на тестовых данных


\section{Нелинейные монотонные композиции}
\subsection{Основные обозначения} 
 \textbf{Определение 1}
 
 Произвольная линейная корректирующая операция $F(b_1,... , b_T ) = \alpha_1 b_1 + · · · + \alpha_T b_T$ с неотрицательными коэффициентами $\alpha_t$ является монотонным отображением из $R_T$ в Y и называется \textit{монотонной корректирующей операцией}.\\
 
 Искомый алгоритм $a$ имеет вид $a(x) = F(b_1(x), . . . , b_T (x))$
 
\subsection{Лемма о проведении монотонной функции через заданные точки.}
 
 \textbf{Определение 2}
 
 Пусть U, V -- произвольные частично уторядоченные множества. Совокупность пар $(u_i, v_i)_{i=1}^l$ из $U\times V$ назвыается \textit{монотонной}, если из $u_i\leq u_k$ следует $v_i\leq v_k$ для всех $j,k = 1,...,l.$\\
 
 \textbf{Лемма 1}
 
Пусть  $U, V$ -- произвольные частично упорядоченные множества. Монотонная функция $f : U \longrightarrow V$ такая, что $f(u_i) = v_i$ для всех $i = 1, . . . , l$, существует
тогда и только тогда, когда совокупность $(u_i
, v_i)^l_{i=1}$ монотонна.

\textbf{Доказательство.}

Необходимость вытекает из определения монотонной функции: если $f$ монотонна, то совокупность $(u_i,f(u_i))^l_{i=1}$ монотонна.

Докажем достаточность. Предполагая, что совокупность $(u_i,f(u_i))^l_{i=1}$ монотонна,
построим функцию $f$ в классе кусочно-постоянных функций. Определим для произвольного $u \in U $ множество индексов $I(u) = {k : u_i \leq u}$ и положим

\begin{equation*}
    f(u) =
    \begin{cases}
        \min\limits_{i=1,...,l}v_i, \text{ если } I(u) = \varnothing; \\
        \max\limits_{i\in I(u)}v_i, \text{ если } I(u) \in \varnothing .
    \end{cases}
\end{equation*}


Докажем, что функция f монотонна. Для произвольных $u$ и $u\prime $ из $u_i \leq u$ следует $I(u)\subseteq I( u\prime)$, значит $f(u)\leq f(u\prime )$.
Докажем, что $f(u_i) = v_i$ для всех $i = 1, . . . , l$. Множество $I(u_i)$ не пусто, так
как $i \in I(u_i)$. Для любого $k \in I(u_i)$ в силу монотонности $(u_i, v_i)^l_{i=1}$ из $u_k \leq u_i$ следует $v_k \leq v_i$. Но тогда $max_{k\in I(u_i)} v_k$ достигается при $k = i$, откуда следует $f(u_i) = v_i$.$\blacksquare$\\




Предложенный способ построения функции $f$ мало пригоден для практических нужд.
 В регрессионных задачах желательно, чтобы функция $f$ была гладкой или хотя бы непрерывной,здесь  $f$ кусочно-постоянна. В задачах классификации  -- чтобы разделяющая поверхность проходила как можно дальше от точек выборки, здесь разделяющая полоса целиком относится к классу 0.


\subsection{Оптимизация базовых алгоритмов}

Обозначим через $u_i$ вектор значений базовых алгоритмов на объекте $x_i$, через $f_i$ — значение, выданное алгоритмом a(x) на объекте $x_i$:
\[u_i = (b_1(x_i), . . . , b_t(x_i));\]
\[f_i = a(x_i) = F(b_1(x_i), . . . , b_t(x_i)) = F(u_i); \; i = 1, . . . , l.\]
В новых обозначениях условие корректности алгоритма $a(x_i) = y_i$ примет вид
\[F(u_i) = y_i
, \; i = 1, . . . , l. 
\]\\

\textbf{Определение 3} 

Пусть $V$ — произвольное упорядоченное множество. Пара индексов $(j, k)$
называется дефектной для функции $b : X \rightarrow V$ , если $y_j < y_k$ и $b(x_j ) > b(x_k)$. Дефектом функции $b(x)$ называется множество всех её дефектных пар:
\[D(b) = {(j, k): y_j < y_k \wedge b(x_j ) > b(x_k)} .\]


Следовательно любой монотонный оператор, а следовательно и алгоритм $a(x) = F(b1(x), . . . , bt(x)) $ допустят ошибку в точке $x_j$ или $x_k$ при дефектной паре $(j, k)$.
\\

\textbf{Определение 4} 

Совокупным дефектом операторов $b_1, . . . , b_t$ называется множество
$D_T (b_1, . . . , b_t) = D(b_1) \cap ... \cap D(b_t) = {(j, k): y_j < y_k \wedge u_j > u_k}.$
Будем также пользоваться сокращённым обозначением $D_t = D_t(b_1, . . . , b_t).$
\\
Для любой пары $(j, k)$ из совокупного дефекта и любой монотонной функции $F$ алгоритм $a(x) = F(b_1(x), . . . , b_t(x)) $ допустит ошибку хотя бы на одном из двух объектов $x_j$ или $x_k$.\\

\textbf{
Теорема 1} 

 Монотонная функция $F : R^t \rightarrow Y $, удовлетворяющая условию корректности существует тогда и только тогда, когда совокупный дефект операторов $b_1, . . . , b_t$ пуст. При этом дефект алгоритма $a(x) = F(b_1(x), . . . , b_t(x)) $ также пуст.


\textbf{Доказательство.}

Справедлива следующая цепочка равносильных утверждений:
а) совокупный дефект пуст: $D_t(b_1, . . . , b_t) = \varnothing$;
б) для любых $j, k$ не выполняется $(u_k \leq u_j ) \wedge (y_j < y_k)$ (согласно Опр. 1.6);
в) для любых $j, k$ справедлива импликация $(u_k \leq u_j ) \rightarrow (y_k \leq y_j )$;
г) совокупность пар $(u_i, y_i)^l_{i=1}$ монотонна (согласно Опр. 1.4);
д) существует монотонная функция $F : R_t \rightarrow Y$ такая, что $F(u_i) = y_i$ для всех
$i = 1, . . . , l$ (согласно Лемме 1.5).
Из утверждения д) следует, что условия $y_j < y_k$ и $F(u_j ) > F(u_k)$ не могут
выполняться одновременно, значит, дефект $D(F(b_1, . . . , b_t))$ также пуст. $\blacksquare$\\


Таким образом, для корректной работы алгоритма необходимо построить операторы $ b_1, . . . , b_t$
, совокупный дефект которых пуст. А добавление такого оператора $b$, что 
\begin{equation}\label{iter}
b_t (x_j) < b_t(x_k) (j, k) \in D_{t-1}
\end{equation}
приводит к устранению дефектной пары.\\

\textbf{Теорема 2 (о сходимости)}. 

Пусть на первом шаге построен оператор $b_1$, и семейство операторов $B$ выбрано так, что для любой подвыборки $X^{2m}$
длины $2m, m > 1$, найдётся оператор $b\in B$ и монотонная корректирующая операция $F$, удовлетворяющие системе ограничений
\[
F(b(x_i)) = y_i
, x_i \in X^{2m}.\]
Тогда итерационный процесс, аналогичный последовательному построению смеси алгоритмов, приводит к построению корректной композиции
$a = F(b_1, . . . , b_T )$ за конечное число шагов $T \leq [D(b_1)/m]+ 1$.


\textbf{Доказательство.}

Рассмотрим t-й шаг, t > 2, итерационного процесса . Если $\vert D_{t-1}\vert > m$,
то выберем некоторое m-элементное подмножество совокупного дефекта $\Delta_{t-1} \subseteq D_{t-1}$.
Если $\vert D_{t-1}\vert \leq m$, то положим $\Delta{t-1} = D_{t-1}$. Рассмотрим подмножество объектов
выборки, образующих всевозможные дефектные пары из $\Delta{t-1}$:
\[ U = \lbrace x_i \in X^l \exists k : (k, i) \in \Delta_{t-1} \; \text{или} \; (i, k) \in \Delta_{t-1} \rbrace\].

Очевидно, мощность $U$ не превышает 2m. Согласно условию теоремы существует оператор $b_t \in B$ и монотонная корректирующая операция $F$, удовлетворяющие системе
ограничений $F(b_t(x_i)) = y_i$ при всех $x_i \in U$. Но тогда для оператора $b_t$ выполняется
также система ограничений
\[ b_t(x_j) < b_t(x_k) \; \, (j, k) \in \Delta_{t-1}\]


Докажем это от противного: пусть $b_t(x_k) \leq b_t(x_j )$, тогда $F(b_t(x_k)) \leq F(b_t(x_j ))$, следовательно, $y_k \leq y_j$
, что противоречит условию $y_j < y_k$, входящему в определение
дефектной пары $(j, k)$.
Если выбирать операторы $b_t , \; t = 2, 3, . . .$ указанным способом, то мощность
совокупного дефекта будет уменьшаться, как минимум, на m на каждом шаге итерационного процесса: $\vert D_t \vert \leq \vert D_{t-1}\vert -m$. Для полного устранения дефекта потребуется не более $\lceil D(b_1)/m\rceil$
операторов, не считая $b_1$. $\blacksquare$
\\

Процесс последовательного построения базовых алгоритмов организуется
по принципу \textit{наискорейшего устранения дефекта}.
Если специальным образом задать веса
обучающих объектов, мощность совокупного дефекта можно оценить сверху
обычным функционалом числа ошибок.

Следующая теорема показывает, что в случае классификации вес i-го объекта
можно положить равным числу пар из совокупного дефекта $D_{t-1}$, в которых участвует данный объект.\\

\textbf{Теорема 3} 

Если $Y = {0, 1}$ и функция потерь имеет вид $\overset{\sim}{L}(b, y) =[[b > 0]\neq y]$ , то справедлива оценка \[\vert D_t(b_1, . . . , b_t)\vert \leq \operatornamewithlimits{\sum}^l_{i=1} w_i \overset{\sim}{L} (b_t(x_i), y_i); \]
\[w_i = \vert D(i)\vert ;\]
\[D(i) = \lbrace x_k \in X^l \vert (k, i) \in D_{t-1} \text{ или } (i, k) \in D_{t-1} \rbrace; \; i = 1, . . . , l.\]

\textbf{Доказательство.}

Обозначим через $\beta_i = b_t(x_i)$ значение t-го оператора на i-м обучающем объекте, через $L_i = \overset{\sim}{L}(\beta_i, y_i) = [\beta_i > 0] \neq y_i$

— значение функции потерь, равное 1, если
оператор $b_t$ допускает ошибку на i-м объекте, 0 в противном случае.
Для любых действительных $\beta_j, \beta_k$ справедливо неравенство
\[[\beta_j > \beta_k] \leq [\beta_j > 0] + [\beta_k \leq 0]\].



Если $y_j < y_k$, то из двухэлементности множества Y следует:
\[y_j = 0; \; [\beta_j > 0] =[\beta_j > 0] \neq 0 = [\beta_j > 0] \neq y_j = L_j;\]
\[y_k = 1; \; [\beta_k \leq 0] =
[\beta_k > 0] \neq 1=[\beta_k > 0] \neq y_k= L_k.\]

Используя представление $D_t = D_{t-1} \bigcap D(b_t)$, распишем мощность совокупного
дефекта в виде суммы по парам объектов и применим оценку $[\beta_j > \beta_k] \in L_j + L_k$:
\[\vert D_t \vert = \operatornamewithlimits{\sum}_{(j,k)\in D_{t-1}} [(j, k) \in D(b_t)]=
\operatornamewithlimits{\sum}_{(j,k)\in D_{t-1}}  [\beta_j > \beta_k] \leq 
\operatornamewithlimits{\sum}_{(j,k)\in D_{t-1}}(L_j + L_k) =\]
\[ = \operatornamewithlimits{\sum}^l_{\operatornamewithlimits{j=1}\limits_{y_j=0}} L_j
\operatornamewithlimits{\sum}^l_{k=1}[(j, k) \in D_{t-1}] +
\operatornamewithlimits{\sum}^l_{\operatornamewithlimits{k=1}\limits_{y_k=1}} L_k
\operatornamewithlimits{\sum}^l_{j=1}[(j, k) \in D_{t-1}]=\]
\[=\operatornamewithlimits{\sum}^l_{i\in 1} L_i \operatornamewithlimits{\sum}^l_{k=1} [(k, i) \in D_{t-1}\text{ или }(i, k)\in D_{t-1}=\operatornamewithlimits{\sum}^l_{i\in 1} L_i \vert D(i)\vert.\] $\blacksquare$\\





%\begin{figure}[h!]
%	\centering
%	\includegraphics[height=0.3\textheight]{signal}
%	\caption{Зависимость тока от времени для GaAs в диоде Ганна}
%\end{figure}


\subsection*{Задачи}
\textbf{\emph{Задача 1}}

Имеется алгоритм $a(x)=F(b_1(x)...,b_t(x))$, где $F$ монотонная корректирующая операция. 
Если $\forall i; \; i = 1,...,t; \; b_i\in B$, функция $a \in A$, является ли верным утверждение, что $A=B$?

\textit{Решение}

Класс $B$ может накладывать определенные ограничения на функции, которые он содержит (например, линейность, непрерывность, ограниченность). Монотонная операция $F$ может изменить эти ограничения.

 Монотонная операция F может расширить или сузить множество функций, которые могут быть получены. Eсли $F$ – нелинейная функция (например, $F(x_1, ..., x_t) = max(x_1, ..., x_t))$, то класс $A$ будет содержать нелинейные функции (даже если все $b_i$ линейны), которые не принадлежат классу $B$. В этом случае $A \neq B$ а именно $A \supset B $.\\

\textbf{\emph{Задача 2}}

Напишите пример монотонной корректирующей операции $F$, такой что в предыдущей задаче достигнется развенство классов $A$ и $B$.


\textit{Решение}

Пусть класс $B$ содержит только линейные функции вида $b_i(x) = k_i x + c_i$. Если $F(x_1, x_2) = x_1 + x_2$, то класс $A$ также будет содержать только линейные функции. В этом случае $A = B$.\\

\textbf{\emph{Задача 3}}

Рассмотрим класс функций $F$, представляющих собой композиции монотонно неубывающих функций. Пусть $b_i: \mathbb{R} \rightarrow \mathbb{R}$ для $i = 1, ..., t$ — монотонно неубывающие функции, и $g_i: \mathbb{R}^n \rightarrow \mathbb{R}$ для $i = 1, ..., t$ — также монотонно неубывающая функция. Тогда функция $F(x_1, ..., x_n) = g(f_1(x_1), ..., f_n(x_n))$ принадлежит классу $F$.

Верно ли следуюшее утверждение? Если функция $h(x_1, x_2) \in F$ удовлетворяет условиям:

\begin{itemize}
\item $h(0, 0) = 0$
\item $h(1, 1) = 1$
\item $h(x, y) = h(y, x)$
\item Для любых $x_1, x_2 \geq 0$ выполняется $h(x_1, x_2) \geq max(x_1, x_2)$,

\end{itemize}


то функция $h(x, y)$ тождественно равна $max(x, y)$ при $x, y \in [0, 1]$.\\

\textit{Решение}

Докажем от противного.

Пусть $\exists h(x_1, x_2) \in F, \; h(x_1, x_2) \neq max(x_1, x_2)$ на [0, 1], удовлетворяющая условиям 1-4.  Значит существует хотя бы одна пара $(x_0, y_0) \in [0, 1] \; : \; h(x_0, y_0)> max(x_0, y_0)$.

Предположим $x_0 \geq y_0$. Тогда $h(x_0, y_0) > x_0$.

Так как $h \in F$,  она является композицией монотонно неубывающих функций.  Это означает, что если $x_1 \geq x_2$ и $y_1 \geq y_2$, то $h(x_1, y_1) \geq h(x_2, y_2)$.

Рассмотрим точку $(x_0, x_0)$.  По свойству 3,$ h(x_0, y_0) = h(y_0, x_0)$.  По условию 4, $h(x_0, x_0) \geq x_0$.  Но так как $h(x_0, y_0) > x_0$ и $y_0 \neq x_0$,  из монотонности $h$ следует   $h(x_0, x_0) \geq h(x_0, y_0) > x_0$.

Теперь рассмотрим случай, когда $x_0 = 1$ и $y_0 < 1$.  Тогда $h(1, y_0) > 1$  (поскольку $h(1,y_0) > max(1, y_0) = 1$). Но это противоречит условию 4, что $h(x,y) \neq 1 \; \forall x, y \in [0, 1]$ ввиду монотонного неубывания $h(x,y)$ по обоим аргументам и $h(1,1) = 1$.  Если бы $h(1, y_0) > 1$, то и $h(1,1)$ должна быть больше 1, что противоречит условию.

Аналогично, если  $x_0 < 1$ и $y_0 = 1$.

Если же $0 < x_0 < 1$ и $0 < y_0 < 1$, и  $h(x_0, y_0) > max(x_0, y_0)$, то можно построить последовательность точек, приближающихся к (1, 1),  где значение $h$ будет продолжать расти, что приведет к противоречию с условием $h(1, 1) = 1$ из-за монотонности $h$.

Следовательно изначальное предположение неверно и $h(x,y)\equiv max(x,y).\blacksquare$

\subsection{DummyEnsemble}
DummyEnsemble — это метод машинного обучения, который объединяет несколько базовых моделей для повышения точности прогнозирования. Он основан на идее использования различных моделей, которые могут иметь разные предположения и подходы к решению задачи.

В основе DummyEnsemble лежит принцип объединения нескольких «слабых» моделей (например, решающих деревьев, линейных моделей и т. д.) в одну «сильную» модель. Это позволяет уменьшить дисперсию и смещение, что приводит к более точному и стабильному прогнозированию. Эта техника, применяется для создания элементарных ансамблей, которые могут служить базовыми моделями для сравнения их с более сложными алгоритмами машинного обучения. Они могут быть использованы для оценки базового уровня производительности модели на задаче и служить ориентиром при улучшении моделей.

Преимущества использования DummyEnsemble:
\begin{enumerate}
	\item Устойчивость к переобучению: использование нескольких моделей помогает снизить риск переобучения, особенно если базовые модели имеют разные предположения и подходы.
	\item Простота реализации: DummyEnsemble легко реализовать, поскольку он не требует сложных алгоритмов или оптимизации параметров.
	\item Интерпретируемость: результаты каждой базовой модели могут быть интерпретированы отдельно, что позволяет лучше понять процесс принятия решений.
\end{enumerate}

\subsection*{Задачи}
\subsubsection*{Задача 1}
    Что такое DummyEnsemble и каких целей можно достичь, используя его в машинном обучении? 
\subsubsection*{Ответ}
    Описано выше
\subsubsection*{Задача 2}
    В каких ситуациях может быть полезно использование DummyEnsemble в процессе разработки модели?
\subsubsection*{Ответ}
\begin{itemize}
    \item Для установления базового уровня производительности, который должны превосходить более сложные модели.
    \item При неуверенности в сложности задачи, чтобы понять, насколько сложную модель нужно разрабатывать.
    \item Для тестирования инфраструктуры машинного обучения или конвейера обработки данных.
\end{itemize}
\subsubsection*{Задача 3}
    Представьте, что вы обучили свою модель и сравнили её результаты с DummyEnsemble. Ваши метрики показывают небольшое улучшение. Какие действия вы предпримете?
\subsubsection*{Ответ}
    Перепроверить подготовку данных и чистоту данных, провести более тщательную настройку гиперпараметров модели. Изучить возможность извлечения дополнительных признаков или другие способы общего улучшения данных. То, что ваша модель показывает лишь небольшое улучшение по сравнению с DummeEnsemble говорит о том, что можно добиться результата лучше.
