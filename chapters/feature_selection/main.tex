\section{Методы отбора признаков}


\subsection*{Постановка задачи}
Пусть исходный набор признаков состоит из \( n \) элементов. Тогда задача отбора признаков формализуется следующим образом: 
Найти подмножество $S \subseteq \{1, 2, \dots, n\}$, такое, что $f(S)$ максимизирует (или минимизирует) целевую функцию. Где \( $f(S)$ \) — метрика, характеризующая качество модели (например, точность, $ R^2 $, AUC-ROC).

Сложность задачи заключается в её комбинаторной природе: общее количество подмножеств \( S \) равно \( 2^n \). Для больших \( n \) полный перебор становится вычислительно неэффективным.

\subsection*{Классификация алгоритмов}

\textbf{1. Фильтрационные методы}
Фильтрационные методы работают независимо от модели и используют статистические меры для оценки значимости признаков.

Примеры:
\begin{itemize}
    \item Многорядный итерационный алгоритм МГУА 
\end{itemize}

\textbf{2. Обёрточные методы}
Обёрточные методы оценивают подмножества признаков на основе качества модели, что обеспечивает высокую точность, но увеличивает вычислительную сложность.  

Примеры:
\begin{itemize}
    \item Полный перебор.
    \item Метод добавления и удаления (шаговая регрессия).
    \item Поиск в глубину.
    \item Метод ветвей и границ.
\end{itemize}

\textbf{3. Встроенные методы}
Встроенные методы выбирают признаки в процессе построения модели, используя регуляризацию или другие встроенные механизмы.  

Примеры:
\begin{itemize}
    \item L2, L1, L0-регуляризация 
\end{itemize}

\textbf{4. Эвристические и случайные методы}
Эти методы используют эвристики или случайный подход для нахождения подмножеств признаков, что снижает вычислительную сложность.  

Примеры:
\begin{itemize}
    \item Генетический алгоритм
    \item Случайный поиск 
    \item Случайный поиск с адаптацией (СПА) 
\end{itemize}

\subsection*{Задача 1: Выбор оптимального метода отбора признаков}

\textbf{Условие задачи}
Имеется набор данных, содержащий: 20 признаков \( X_1, X_2, \dots, X_{20} \), 500 записей, целевую переменную \( Y \). 
Цель — построить модель линейной регрессии, которая предсказывает \( Y \) с минимальной среднеквадратической ошибкой (MSE).  
\subsubsection*{Ограничения:}
\begin{enumerate}
    \item Требуется сократить число признаков, чтобы модель была проще и быстрее, но при этом сохранить качество.  
    \item Время на выполнение задачи ограничено: не более 5 минут вычислений.  
\end{enumerate}

\textbf{Вопрос:} Какой метод вы выберете для решения задачи? Обоснуйте выбор и оцените его время работы.
\subsection*{Задача 2: Полный перебор для отбора признаков}

\textbf{Условие задачи}
Дан набор данных с 4 признаками: $X_1, X_2, X_3, X_4$
Необходимо:  
\begin{enumerate}
    \item Перебрать все возможные подмножества признаков.
    \item Для каждого подмножества вычислить точность модели классификации.
    \item Найти подмножество, обеспечивающее максимальную точность.
\end{enumerate}

\textbf{Вопросы}
 Можно ли было применить более быстрый метод вместо полного перебора?

\subsection*{Задача 3}

Рассмотрите три задачи:  
\begin{enumerate}
    \item Для набора данных с 5 признаками требуется построить модель линейной регрессии с минимальной среднеквадратической ошибкой. Время на выполнение не ограничено.  
    \item Для набора данных с 50 признаками и 1000 объектов необходимо выбрать наиболее значимые признаки для задачи классификации. Требуется уложиться в 10 минут вычислений.  
    \item Для набора данных с 20 признаками известны сильные корреляции между некоторыми из них. Задача — исключить избыточные признаки и построить компактную модель.  
\end{enumerate}

Какой тип метода отбора признаков (\textbf{фильтрационный}, \textbf{обёрточный} или \textbf{встроенный}) вы бы выбрали для каждой задачи? Обоснуйте свой выбор.

\chapter{Критерии отбора признаков}

Критерии отбора признаков — это методы, которые используются для выбора подмножества признаков (или переменных), которые наиболее важны для предсказания целевой переменной. Эти критерии помогают уменьшить размерность данных, улучшить производительность модели и избежать переобучения. Критерии отбора признаков делятся на два типа: 

\begin{itemize}
  \item Внутренние критерии (Internal Criteria)
  \item Внешние критерии (External Criteria)
\end{itemize}

\subsection{Внутренние критерии отбора признаков}

\textbf{Внутренние критерии} оценивают качество модели, основываясь на её обучении на имеющемся подмножестве данных. Эти критерии минимизируют ошибку модели на обучающих данных.

Пример:
Функция потерь \( L(w, x) \) — функция потерь модели \( a(w, x) \) на объекте \( x \). Для оценки качества модели на подмножестве \( X^\ell \) используется:
\[
Q(w, X^\ell) = \frac{1}{\ell} \sum_{i=1}^{\ell} L(w, x_i),
\]
где \( L(w, x_i) \) — функционал качества модели на объекте \( x_i \).

\textbf{Недостаток}: Оценка может быть смещена, так как модель оптимизирует её на обучающей выборке, что может привести к переобучению.

\subsection{Внешние критерии отбора признаков}

\textbf{Внешние критерии} оценивают качество модели на основе её работы на "вне обучающих данных", например, на отложенной (hold-out) контрольной выборке. Эти методы оценивают способность модели к обобщению.

Пример:
Для подмножества \( X^\ell \) и контрольной выборки \( X^k \) можно использовать внешний критерий:
\[
Q_\mu(X^\ell, X^k) = Q(\mu(X^\ell), X^k),
\]
где \( \mu \) — это модель, которая обучается на данных \( X^\ell \) и тестируется на \( X^k \).

\textbf{Недостаток}: Оценка зависит от того, как был выполнен разбиение данных, что может повлиять на стабильность и точность результатов.
\subsection{Основные типы внешних критериев}

1. \textbf{Кросс-валидация (cross-validation, CV)}: Этот метод включает разделение данных на несколько частей и использование разных подмножеств для обучения и тестирования модели.

   \[
   CV(\mu, X^\ell) = \frac{1}{|N|} \sum_{n \in N} Q_\mu(X^\ell_n, X^k_n),
   \]
   где \( |N| \) — количество подмножеств разбиений.

   \textbf{Виды кросс-валидации}:
   \begin{itemize}
     \item \textbf{Hold-out}: Единственное разбиение данных на обучающие и тестовые.
     \item \textbf{Метод Монте-Карло}: Случайное разбиение данных на несколько частей.
     \item \textbf{Полная кросс-валидация}: Все возможные разбиения данных.
   \end{itemize}

   \textbf{Недостаток}: Оценка может быть вычислительно сложной.
\subsection{Задачи}
\textbf{Задача 1}.
Чем отличаются внутренний и внешний критерии?
\begin{itemize}
  \item \textbf{Внутренний критерий}: Обычно, с увеличением сложности модели (например, числа признаков) ошибка на обучении уменьшается, но ошибка на тестовых данных может увеличиваться, что приводит к переобучению.
  \item \textbf{Внешний критерий}: Он имеет характерный минимум, соответствующий оптимальной сложности модели. Например, ошибка на обучении сначала уменьшается, а затем начинает расти при увеличении числа признаков.
\end{itemize}

\textbf{Задача 2: Применение кросс-валидации для оценки качества модели}

У вас есть набор данных с 50 признаками и 200 объектами. Вам нужно отобрать признаки для модели классификации с использованием кросс-валидации. Какие типы кросс-валидации вы бы использовали для этой задачи и какие методы отбора признаков могут быть совместимы с кросс-валидацией? Обоснуйте выбор метода для получения стабильных и надежных результатов.

\textbf{Задача 3: Оценка качества с использованием критериев отбора признаков}

У вас есть набор данных с 30 признаками и 1000 объектами, который используется для задачи классификации. Вы хотите использовать метод оценки качества модели, чтобы отобрать наиболее значимые признаки для построения модели с высокой точностью. Рассмотрите следующие критерии:

\begin{enumerate}
    \item \textbf{Внутренний критерий:} Оценка качества модели по данным обучающей выборки. Этот критерий оценивает модель на основании обучающих данных, при этом она может быть склонна к переобучению.
    \item \textbf{Внешний критерий:} Оценка качества модели с использованием кросс-валидации, которая разделяет данные на несколько подмножеств для получения независимой оценки.
\end{enumerate}

Для каждой из этих стратегий предложите, какие методы отбора признаков и критерии оценки вы будете использовать в задаче классификации. Обоснуйте выбор метода и обсудите, какие преимущества и недостатки могут возникнуть при использовании каждого из этих критериев.

\section{Качество классификации}
Рассмотрим задачу бинарной классификации с обучающей выборкой $D = \{(x_i, y_i)\}_{i=1}^n$, где $x_i \in \mathbb{R}^d$ --- вектор признаков, $y_i \in \{0, 1\}$ --- бинарная переменная.
Мы хотим построить модель $f: \mathbb{R}^d \to \{0, 1\}$, которая принимает на вход вектор признаков и выдает предсказание класса.
Есть следующие способы измерять качество модели:

Accuracy

Precision

Recall

$F_{\beta}$ score

ROC AUC

Для каждого объекта из выборки мы имеем 4 варианта разивития событий:

TP --- True Positive, классификатор предсказал 1, верное значение тоже 1

FP --- False Positive, классификатор предсказал 1, верное значение 0

TN --- True Negative, классификатор предсказал 0, верное значение тоже 0

FN --- False Negative, классификатор предсказал 0, верное значение 1


Ясно, что мы хотим видеть как можно больше TP и TN и как можно меньше FP и FN.

Accuracy --- это доля правильных ответов классификатора.
$$
    \text{Accuracy} = \frac{TP + TN}{TP + FP + TN + FN} = \frac{1}{n} \sum_{i=1}^n \mathbb{I}(y_i = f(x_i))
$$

Достаточно банальная метрика, которая не учитывает дисбаланса классов, но в качестве базового варианта подходит отлично.

Precision --- это доля объектов, которые классификатор предсказал как 1, среди всех объектов, которые он предсказал как 1.
$$
    \text{Precision} = \frac{TP}{TP + FP}
$$

Recall --- это доля объектов, которые классификатор предсказал как 1, среди всех объектов, которые действительно равны 1.
$$
    \text{Recall} = \frac{TP}{TP + FN}
$$

Precision и Recall --- базовые метрики, но по отдельности их использовать нельзя, поэтому придумали $F_{\beta}$ score.

$F_{\beta}$ score --- это взвешенное среднее гармоническое precision и recall.
$$
    F_{\beta} = (1 + \beta^2) \frac{precision \cdot recall}{\beta^2 \cdot precision + recall}
$$

$TPR$ --- это доля объектов, которые классификатор предсказал как 1, среди всех объектов, которые действительно равны 1.
$$
    TPR = \frac{TP}{TP + FN}
$$

$FPR$ --- это доля объектов, которые классификатор предсказал как 1, среди всех объектов, которые действительно равны 0.
$$
    FPR = \frac{FP}{FP + TN}
$$

Обычно, когда мы решаем задачу бинарной классификации, то мы не предсказываем явный класс, а предсказываем какое-то значение, и чем больше это значение, тем больше вероятность того, что объект принадлежит к классу 1.
Следовательно, мы можем устанавливать пороговое значение, которое будет определять, к какому классу отнести объект.
При увеличении порога отсечения мы увеличиваем количество объектов, которые отнесены к классу 0, и уменьшаем количество объектов, которые отнесены к классу 1.
Заметим, что также при увеличении порога отсечения TPR и FPR будут уменьшаться.

ROC кривая --- это кривая, которая показывает зависимость TPR от FPR при изменении порога отсечения. То есть по оси $x$ откладывается $FPR$, а по оси $y$ --- $TPR$.

Строго говоря, ROC кривая --- это множество точек вида $(FPR(t), TPR(t))$, где $t$ --- пороговое значение вероятности.

ROC-AUC --- это площадь под ROC кривой.

\subsection*{Задача 1}

Мы хотим построить модель бинарной классификации, которая будет по некоторому описанию пациента предсказывать, болен ли он раком.
В случае, если наша модель скажет, что пациент болен раком, то мы отправим его на дополнительное обследование, что обойдется пациенту в некоторую неприятную, но не критичную сумму денег.
Если же наша модель скажет, что пациент здоров, то мы ничего не будем предпринимать.
Мы хотим выбрать метрику качества для нашей модели из следующего списка: Accuracy, Precision, Recall, $F_{\beta}$ score, что нам лучше всего подойдет?
Если мы хотим выбрать $F_{\beta}$ score, то какие значения $\beta$ нам лучше всего подойдут?

\subsection*{Решение}
Accuracy --- не лучший вариант, так как ошибка FP и FN в нашем случае не равнозначны.
Не отправить больного на дополнительное обследование значительно хуже, чем отправить здорового пациента на обследование.
Precision и Recall --- достаточно плохие метрики, ведь есть очень простая модель, которая даст 100\% Precision --- просто предсказывать, что все пациенты больны, аналогичная проблема и с Recall.
$F_{\beta}$ score --- отличный вариант, ведь с помощью $\beta$ мы можем выбирать, какое предпочтение мы отдаем Precision, а какое Recall.
В нашем случае, мы хотим, чтобы Precision был предпочтительнее Recall, поэтому $\beta$ должно быть меньше 1.
Если мы для себя решили, что смерть человека стоит как 10 дообследований, то стоит брать $\beta = \frac{1}{10}$.

\subsection*{Задача 2}
Предположим, что мы измеряем качество модели с помощью ROC-AUC. Допустим, что у нас есть две модели, чьи ROC кривые выглядят следующим образом:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/feature_selection/roc_curves_comparison_1.png}
    \caption{Две ROC кривые}
\end{figure}
Как эти модели упорядочить по качеству?

\subsection*{Решение}
Первая модель самая худшая, ведь ее ROC кривая максимально близка к диагонали, значит она имеет миниимальную ROC-AUC.
Это плохо, но что по смыслу означает близкая к диагонали ROC кривая?

Это означает, что для любого порога отсечения $t$ имеем примерно $TPR(t) = FPR(t)$.
Что означает $TPR(t) = FPR(t)$? Это означает, что модель просто случайным образом с вероятностью $TPR(t)=FPR(t)$ предсказывает 1 класс.
Вторая модель лучшая, но почему?

А что означает график, который близок к уголку, как на рисунке 2?
Это означает, что мы можем взять такой порог отсечения $t$, что почти выполнено $TPR(t) = 1$ и $FPR(t) = 0$.
А это идеальная модель, которая никогда не ошибается.

Заметим, что чем больше площадь под ROC кривой, тем ближе эта кривая к уголку, а значит тем лучше модель.

\subsection*{Задача 3}
Продолжим измерять качество моделей с помощью ROC-AUC. Допустим, что у нас есть две модели, чьи ROC кривые выглядят следующим образом:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/feature_selection/roc_curves_comparison_2.png}
    \caption{Две ROC кривые}
\end{figure}
Как эти модели упорядочить по качеству? А как выбрать порог отсечения? В чем преимущество ROC перед $F_{\beta}$ score?

\subsection*{Решение}
В данном случае, обе ROC кривые имеют одинаковую площадь под графиком, а значит одинаковую ROC-AUC, поэтому просто посмотреть на метрику ROC-AUC нельзя.
На самом деле, однозначного ответа нет, всё зависит от конкретной задачи.

Первая кривая быстро достигает высокого значения TPR, при не самом высоком значении FPR.

Это означает, что выбрав порог отсечения $t$, при котором $TPR(t)$ будет близок к 1, а $FPR(t)$ будет близок к 0.5, мы получим модель,
которая угадывает почти всех, кто попадает в 1 класс, но при этом не сильно много ошибается на классе 0.
Такая модель отлично подойдет в первой задаче, где мы хотим отгадать почти всех больных, но при этом не сильно много отправлять на дополнительное обследование здоровых людей.

На втором графике ситуация обратная, мы можем выбрать порог отсечения $t$, при котором $TPR(t)$ будет близок к 0.5, а $FPR(t)$ будет близок к 1.
Такая модель будет полезна в случае, когда мы хотим минимизировать количество ошибок на классе 0, но при этом не сильно много ошибаться на классе 1.
В контексте первой задачи, это означает, что мы не хотим тратить лишние деньги на дополнительное обследование здоровых людей даже ценой смерти больных, которых мы не отправляем на дополнительное обследование.

Исходя из этих примеров, становится понятно, как стоит выбирать порог отсечения. По сути его выбор означает, насколько мы готовы пожертвовать ошибками на предсказаниях одного класса, чтобы минимизировать ошибки на предсказаниях другого класса.
Это такой аналог $\beta$ в $F_{\beta}$ score, только $\beta$ мы выбирали до измерения метрики, а в случае ROC кривой мы выбираем порог отсечения глядя на график и имея какую-то дополнительную информацию о том, как работает модель при разных порогах.
Это может быть очень полезно, ведь далеко не всегда мы готовы определиться с балансом ошибок на классах перед тем, как начать решать задачу.


\section*{Отбор признаков: алгоритм Add-Del}

Отбор признаков — это важный этап работы с данными в машинном обучении. Его цель — выбрать подмножество признаков, которые наиболее значимы для построения качественной модели. Используя разные методы отбора признаков, мы можем улучшить производительность модели, сократить время обучения и избежать переобучения. 




\subsection*{Алгоритм Add-Del (Stepwise Selection)}

Этот жадный метод объединяет добавление и удаление признаков. Он пытается улучшить результат, проверяя, можно ли удалить ранее добавленные признаки.

\subsubsection*{План действий}

\begin{enumerate}

\item Начинаем с пустого набора (или с начального набора признаков).

\item Добавление признаков: находим и добавляем тот признак, который максимизирует качество модели.

\item Удаление признаков: после добавления нового признака проверяется, можно ли удалить какой-либо из уже добавленных без ухудшения качества модели.

\item Шаги повторяются, пока не перестанет улучшаться метрика или не будут обработаны все признаки.

\end{enumerate}


\subsubsection*{Алгоритм}


Инициализация:
\[
J_0 := \emptyset; \quad Q^* := Q(\emptyset); \quad t := 0;
\]

\textbf{Повторять:}
\begin{itemize}
    \item Пока \( |J_t| < n \), добавлять признаки (итерации Add):
    \begin{itemize}
        \item \( t := t + 1 \) — началась следующая итерация;
        \item Найти признак:
        \[
        f^* := \arg \min_{f \in F \setminus J_{t-1}} Q(J_{t-1} \cup \{f\});
        \]
        \item Добавить признак:
        \[
        J_t := J_{t-1} \cup \{f^*\};
        \]
        \item Если \( Q(J_t) < Q^* \), то:
        \[
        t^* := t; \quad Q^* := Q(J_t);
        \]
        \item Если \( t - t^* \geq d \), то прервать цикл.
    \end{itemize}
    \item Пока \( |J_t| > 0 \), удалять признаки (итерации Del):
    \begin{itemize}
        \item \( t := t + 1 \) — началась следующая итерация;
        \item Найти признак:
        \[
        f^* := \arg \min_{f \in J_{t-1}} Q(J_{t-1} \setminus \{f\});
        \]
        \item Удалить признак:
        \[
        J_t := J_{t-1} \setminus \{f^*\};
        \]
        \item Если \( Q(J_t) < Q^* \), то:
        \[
        t^* := t; \quad Q^* := Q(J_t);
        \]
        \item Если \( t - t^* \geq d \), то прервать цикл.
    \end{itemize}
\end{itemize}

\textbf{Пока значения критерия \( Q(J_{t^*}) \) уменьшаются:}

\[ \text{Вернуть} \ ( J_{t^*} ).\]


\begin{figure}[h!!!!!!!!!!]
	\centering
	\includegraphics[width=1\linewidth]{add-del.png}
\end{figure}



\subsubsection*{Преимущества}

\begin{itemize}

    \item Как правило лучше, чем Add и Del по отдельности, и болле гибкий, чем полный перебор

    \item Может устранить незначимые признаки, которые случайно попали в набор
    
\end{itemize}

\subsubsection*{Недостатки}

\begin{itemize}

    \item Еще медленнее, чем полный перебор

    \item Не гарантирует оптимальность
    
\end{itemize}



\bigskip
\bigskip




\subsection*{Задачи}



\subsubsection*{Задача 1. Применение алгоритма Add-Del}

Рассмотрим множество признаков \( F = \{f_1, f_2, f_3, f_4\} \) и следующую таблицу значений критерия \( Q(J) \) для различных наборов признаков \( J \):

\[
\begin{array}{|c|c|}
\hline
J & Q(J) \\
\hline
\emptyset & 10 \\
\{f_1\} & 8 \\
\{f_2\} & 9 \\
\{f_3\} & 6 \\
\{f_4\} & 7 \\
\{f_1, f_2\} & 7.5 \\
\{f_1, f_3\} & 5.5 \\
\{f_1, f_4\} & 6.5 \\
\{f_2, f_3\} & 6.2 \\
\{f_2, f_4\} & 6.8 \\
\{f_3, f_4\} & 5.2 \\
\{f_1, f_2, f_3\} & 5.0 \\
\{f_1, f_2, f_4\} & 5.7 \\
\{f_1, f_3, f_4\} & 4.8 \\
\{f_2, f_3, f_4\} & 5.1 \\
\{f_1, f_2, f_3, f_4\} & 5.2 \\
\hline
\end{array}
\]

Примените алгоритм Add-Del с параметром \( d = 2 \), начиная с пустого множества. Найдите итоговый набор признаков \( J_{t^*} \), при котором значение критерия \( Q \) минимально.

\bigskip

\textbf{Решение}



\begin{enumerate}


\item \textbf{Инициализация}:
\[
J_0 := \emptyset, \quad Q^* := Q(\emptyset) = 10, \quad t := 0.
\]

\item \textbf{Итерации Add}:
\begin{itemize}
    \item \textbf{Итерация 1}: 
    \[
    t = 1, \quad f^* = \arg \min_{f \in F \setminus J_0} Q(J_0 \cup \{f\}) = f_3, \quad Q(J_1) = Q(\{f_3\}) = 6.
    \]
    \[
    J_1 = \{f_3\}, \quad Q^* = 6, \quad t^* = 1.
    \]

    \item \textbf{Итерация 2}: 
    \[
    t = 2, \quad f^* = \arg \min_{f \in F \setminus J_1} Q(J_1 \cup \{f\}) = f_4, \quad Q(J_2) = Q(\{f_3, f_4\}) = 5.2.
    \]
    \[
    J_2 = \{f_3, f_4\}, \quad Q^* = 5.2, \quad t^* = 2.
    \]

    \item \textbf{Итерация 3}: 
    \[
    t = 3, \quad f^* = \arg \min_{f \in F \setminus J_2} Q(J_2 \cup \{f\}) = f_1, \quad Q(J_3) = Q(\{f_3, f_4, f_1\}) = 4.8.
    \]
    \[
    J_3 = \{f_3, f_4, f_1\}, \quad Q^* = 4.8, \quad t^* = 3.
    \]

    \item \textbf{Итерация 4}: 
    \[
    t = 4, \quad f^* = \arg \min_{f \in F \setminus J_3} Q(J_3 \cup \{f\}) = f_2, \quad Q(J_4) = Q(\{f_3, f_4, f_1, f_2\}) = 5.2.
    \]
    \[
    J_4 = \{f_3, f_4, f_1, f_2\}.
    \]
    Здесь \( Q(J_4) \geq Q^* \), но \( t - t^* = 1 < d \), поэтому продолжаем.

    \item \textbf{Итерация 5}: 
    \[
    t = 5.
    \]
    Поскольку \( t - t^* = 2 \geq d \), прерываем цикл Add.
\end{itemize}

\item \textbf{Итерации Del}:
\begin{itemize}
    \item \textbf{Итерация 1}: 
    \[
    t = 6, \quad f^* = \arg \min_{f \in J_4} Q(J_4 \setminus \{f\}) = f_2, \quad Q(J_5) = Q(\{f_3, f_4, f_1\}) = 4.8.
    \]
    \[
    J_5 = \{f_3, f_4, f_1\}, \quad Q^* = 4.8, \quad t^* = 6.
    \]

    \item \textbf{Итерация 2}: 
    \[
    t = 7, \quad f^* = \arg \min_{f \in J_5} Q(J_5 \setminus \{f\}) = f_1, \quad Q(J_6) = Q(\{f_3, f_4\}) = 5.2.
    \]
    \[
    J_6 = \{f_3, f_4\}.
    \]
    Здесь \( Q(J_6) > Q^* \), но \( t - t^* = 1 < d \), продолжаем.

    \item \textbf{Итерация 3}: 
    \[
    t = 8.
    \]
    Поскольку \( t - t^* = 2 \geq d \), прерываем цикл Del.
\end{itemize}

\item \textbf{Результат}:

Итоговый набор признаков:
\[
J_{t^*} = \{f_3, f_4, f_1\}.
\]

\end{enumerate}

Ответ: минимальное значение критерия: $Q^* = 4.8$.




\bigskip



\subsubsection*{Задача 2. Алгоритм Add-Del для максимизации \( Q(J) \)}

У вас есть множество признаков \( F = \{f_1, f_2, f_3, f_4, f_5\} \). Для каждого признака известно его качество (чем выше, тем лучше) и стоимость (чем ниже, тем лучше). Данные представлены в таблице:

\[
\begin{array}{|c|c|c|}
\hline
\text{Признак} & \text{Качество} & \text{Стоимость} \\
\hline
f_1 & 7 & 4 \\
f_2 & 5 & 2 \\
f_3 & 9 & 5 \\
f_4 & 8 & 6 \\
f_5 & 6 & 3 \\
\hline
\end{array}
\]

Критерий \( Q(J) \) для набора \( J \) определяется как:  
\[
Q(J) = \frac{\sum_{f \in J} \text{качество}(f)}{\sum_{f \in J} \text{стоимость}(f) + |J|}.
\]

Чем выше значение \( Q(J) \), тем лучше набор. Используйте алгоритм \textbf{Add-Del} с параметром \( d = 1 \), чтобы найти набор признаков, который максимизирует \( Q(J) \). Начальное множество \( J_0 \) пусто.

\bigskip



\textbf{Решение}

\begin{enumerate}

\item \textbf{Инициализация}
\[
J_0 := \emptyset, \quad Q^* := 0, \quad t := 0.
\]

\item \textbf{Итерации Add}

\textbf{Шаг 1: \( t = 1 \)}
Рассматриваем добавление каждого признака \( f \in F \):  
\[
\begin{aligned}
Q(\{f_1\}) & = \frac{7}{4 + 1} = 1.4, \\
Q(\{f_2\}) & = \frac{5}{2 + 1} = 1.67, \\
Q(\{f_3\}) & = \frac{9}{5 + 1} = 1.5, \\
Q(\{f_4\}) & = \frac{8}{6 + 1} = 1.14, \\
Q(\{f_5\}) & = \frac{6}{3 + 1} = 1.5.
\end{aligned}
\]

Выбираем \( f^* = f_2 \), так как \( Q(\{f_2\}) \) максимально.  
Обновляем:  
\[
J_1 := \{f_2\}, \quad Q^* := 1.67.
\]

\textbf{Шаг 2: \( t = 2 \)}
Рассматриваем добавление признаков \( f \in F \setminus J_1 = \{f_1, f_3, f_4, f_5\} \):  
\[
\begin{aligned}
Q(\{f_2, f_1\}) & = \frac{5 + 7}{2 + 4 + 2} = \frac{12}{8} = 1.5, \\
Q(\{f_2, f_3\}) & = \frac{5 + 9}{2 + 5 + 2} = \frac{14}{9} = 1.56, \\
Q(\{f_2, f_4\}) & = \frac{5 + 8}{2 + 6 + 2} = \frac{13}{10} = 1.3, \\
Q(\{f_2, f_5\}) & = \frac{5 + 6}{2 + 3 + 2} = \frac{11}{7} = 1.57.
\end{aligned}
\]

Выбираем \( f^* = f_5 \), так как \( Q(\{f_2, f_5\}) \) максимально.  
Обновляем:  
\[
J_2 := \{f_2, f_5\}, \quad Q^* := 1.57.
\]

\item \textbf{Итерации Del}

\textbf{Шаг 3: \( t = 3 \)}
Рассматриваем удаление признаков из \( J_2 = \{f_2, f_5\} \):  
\[
\begin{aligned}
Q(\{f_5\}) & = \frac{6}{3 + 1} = 1.5, \\
Q(\{f_2\}) & = \frac{5}{2 + 1} = 1.67.
\end{aligned}
\]

Удаление признака \( f_5 \) не улучшает \( Q^* \). Цикл завершается.

\item \textbf{Результат}

Итоговый набор:  
\[
J_{t^*} = \{f_2, f_5\}, \quad Q^* = 1.57.
\]

\end{enumerate}





\bigskip

\subsubsection*{Задача 3. Оптимизация алгоритма Add-Del с ограничением на размер набора признаков}

\textbf{Условие:}

Рассмотрим 6 признаков $F = \{x_1, x_2, x_3, x_4, x_5, x_6\}$ и известные значения функции ошибки $Q(J)$ для некоторых подмножеств. Установлено, что $Q(J)$ вычисляется по следующему правилу:
\[
Q(J) = 20 - 3|J| + \sum_{i \in J} w_i,
\]
где веса $w_i$ для признаков заданы следующим образом:
\[
w_1 = 5, \, w_2 = 3, \, w_3 = 2, \, w_4 = 1, \, w_5 = 1, \, w_6 = 0.
\]

Пусть максимальное допустимое количество признаков в итоговом наборе равно 4, то есть $|J| \leq 4$. Используя алгоритм Add-Del:
\begin{enumerate}
    \item Найдите итоговый набор признаков $J$.
    \item Объясните, на каком шаге и почему применяется удаление признаков.
    \item Сравните итоговый результат Add-Del с Add.
\end{enumerate}

\textbf{Решение:}

\begin{enumerate}
    \item На начальном этапе множество признаков $J = \emptyset$, и $Q(\emptyset) = 20$.
    \item Алгоритм Add:
    \begin{itemize}
        \item Добавляем $x_4$, так как $w_4 = 1$ минимально, получаем $J = \{x_4\}$, $Q(J) = 20 - 3 \cdot 1 + 1 = 18$.
        \item Добавляем $x_5$, так как $w_5 = 1$, получаем $J = \{x_4, x_5\}$, $Q(J) = 20 - 3 \cdot 2 + 1 + 1 = 16$.
        \item Добавляем $x_6$, так как $w_6 = 0$, получаем $J = \{x_4, x_5, x_6\}$, $Q(J) = 20 - 3 \cdot 3 + 1 + 1 + 0 = 14$.
        \item Добавляем $x_3$, так как $w_3 = 2$, получаем $J = \{x_4, x_5, x_6, x_3\}$, $Q(J) = 20 - 3 \cdot 4 + 1 + 1 + 0 + 2 = 12$.
    \end{itemize}
    Итоговый набор после алгоритма Add: $J = \{x_4, x_5, x_6, x_3\}$.

    \item Алгоритм Add-Del:
    \begin{itemize}
        \item Следуя тем же шагам Add, находим $J = \{x_4, x_5, x_6, x_3\}$, $Q(J) = 12$.
        \item Проверяем возможность удаления признаков:
        \begin{itemize}
            \item Удаляем $x_3$, так как $Q(\{x_4, x_5, x_6\}) = 20 - 3 \cdot 3 + 1 + 1 + 0 = 14$, что хуже текущего значения $Q(J)$.
            \item Удаляем $x_5$, получаем $Q(\{x_4, x_6, x_3\}) = 20 - 3 \cdot 3 + 1 + 0 + 2 = 13$, что тоже хуже.
        \end{itemize}
    \end{itemize}
    Итоговый набор совпадает с Add: $J = \{x_4, x_5, x_6, x_3\}$, $Q(J) = 12$.
    
    \item Сравнение Add и Add-Del:
    \begin{itemize}
        \item Алгоритмы Add и Add-Del дают одинаковый результат, так как все удаленные подмножества не улучшили $Q$.
        \item Однако Add-Del более устойчив к ошибкам из-за возможности отката.
    \end{itemize}
\end{enumerate}

\section{Методы отбора признаков: полный перебор, алгоритм Add}

Работа с признаками включает два основных подхода:
\begin{enumerate}
    \item Генерация новых признаков;
    \item Отбор существующих признаков.
\end{enumerate}

\subsection{Генерация новых признаков}
Генерация новых признаков подразумевает создание таких признаков, которые представляют собой преобразованные версии исходных данных или полностью новые параметры, полученные из имеющихся данных. Примеры методов генерации признаков включают:

\begin{itemize}
    \item Построение статистик на основе существующих признаков (например, среднее, стандартное отклонение, медиана и т.д.);
    \item Использование методов понижения размерности, таких как анализ главных компонент (PCA);
    \item Применение нейросетей, где скрытые слои (за исключением последнего) могут рассматриваться как новое, более информативное признаковое пространство.
\end{itemize}

В этой главе мы сосредоточимся на отборе существующих признаков, рассмотрев два наиболее популярных метода: полный перебор и жадный алгоритм Add.

\subsection{Полный перебор}

Метод полного перебора представляет собой один из самых простых и технически точных подходов к отбору признаков. Суть метода заключается в оценке качества модели на всех возможных комбинациях признаков и выборе той комбинации, которая обеспечивает наилучшую метрику. Таким образом, полный перебор \textbf{гарантирует нахождение оптимального набора признаков}, так как проверяет все возможные варианты.

Основное преимущество полного перебора заключается в его точности: при достаточных вычислительных ресурсах метод всегда найдёт лучшее решение. Тем не менее, с увеличением числа признаков $n$, количество возможных подмножеств растёт экспоненциально ($2^n$). Это делает полный перебор крайне ресурсоёмким для наборов данных с большим $n$. Например, уже при $n=20$ потребуется рассчитать $2^{20} = 1,048,576$ комбинаций.

Метод полного перебора чаще применяется:
\begin{itemize}
    \item Для небольших наборов признаков, где перебор возможен за приемлемое время;
    \item В задачах, где цена ошибки высока (например, в медицинских исследованиях);
    \item Когда требуется хорошая интерпретируемость и точность подмножеств признаков.
\end{itemize}

На больших данных иногда применяются модификации полного перебора, такие как частичный перебор, где анализируется только часть комбинаций (например, сначала отбираются наиболее значимые признаки с помощью другого метода, а затем производится перебор подмножеств только из этих признаков).

\subsection{Жадный алгоритм Add}

Алгоритм Add (жадный подход) используется гораздо чаще, чем полный перебор, благодаря лучшей производительности на больших данных и более простой интерпретации. Суть метода заключается в пошаговом добавлении признаков в модель. На каждом шаге из оставшихся признаков выбирается тот, который обеспечивает наибольшее улучшение метрики модели. Таким образом, итоговый набор строится итеративно, начиная с пустого множества и поочередно добавляя наиболее значимые признаки.

Жадный алгоритм не гарантирует нахождения глобального оптимума, так как выбирает локально лучшие решения на каждом из шагов. Однако его высокая скорость и способность работать с большими наборами признаков делают его востребованным для многих задач.

Очевидно, что из общего числа признаков $n$ должен остаться некоторый $k$-подмножество наиболее значимых признаков. Критерии остановки алгоритма Add могут быть следующими:

\begin{itemize}
    \item \textbf{Фиксированное количество признаков $k$}:  
    Алгоритм останавливается, как только выбрано заданное количество признаков $k$.  
    \textit{Плюсы:} простота реализации и возможность заранее контролировать размерность данных.  
    \textit{Минусы:} фиксированное значение $k$ может оказаться избыточным в одной задаче или недостаточным в другой. Чтобы минимизировать неопределённость, значения параметра $k$ можно подбирать по сетке с помощью кросс-валидации.
    
    \item \textbf{Остановка при отсутствии улучшения метрики}:  
    На каждом шаге проверяется, насколько новая комбинация признаков улучшает метрику модели (например, \(R^2\), \(MAPE\), RMSE). Если добавление нового признака не приводит к значимому улучшению (или ухудшает метрику), алгоритм прекращает выполнение.  
    \textit{Плюсы:} гибкость метода, так как он адаптируется к конкретной задаче.  
    \textit{Минусы:} возможно преждевременное завершение, если данные содержат шум.
\end{itemize}

Метод Add применяется, когда требуется построить интерпретируемую модель с допустимым уровнем качества за ограниченное время. Например, алгоритм широко используется в финансах для выделения ключевых факторов прогнозирования прибыли или моделирования рисков, а также в обработке медицинских данных. 

\textbf{Преимущества метода Add:}
\begin{itemize}
    \item Высокая скорость работы и масштабируемость для большого числа признаков;
    \item Возможность построить достаточно простую и интерпретируемую модель.
\end{itemize}

\textbf{Недостатки метода Add:}
\begin{itemize}
    \item Чувствительность к входным данным: выбросы и избыточные признаки могут искажать отбор на ранних этапах;
    \item Отсутствие глобальной оптимальности: алгоритм может игнорировать комбинации признаков, т.к. учитывает только влияние признаков по отдельности.
\end{itemize}

\subsection{Задачи}

\subsubsection{Задача 1.}

Есть набор данных с N = 10000 признаков, и задача состоит в отборе важных признаков. Отбор происходит с помощью метода Add, но на каждом шаге анализ всех оставшихся признаков (выбор из 10000, затем из 9999 и т.д.) занимает слишком много времени.

Как можно было бы улучшить этот метод?

\subsubsection{Ответ 1.}

Можно разделить все признаки случайным образом на блоки (например, по 100 признаков). В таком случае хорошей идеей будет выбрать лучший признак из каждого блока на предварительном этапе (т.е. жадный Add выполняется на подмножествах сначала локально в блоках), а затем продолжить работу с меньшим числом представителей от каждых блоков. Если блоки и так большого размера, то можно воспользоваться этой идеей рекурсивно для каждого подблока.

\subsubsection{Задача 2.}

Рассмотрим использование жадного алгоритма Add для выбора признаков из набора данных с 5 признаками ({A, B, C, D, E}) в задаче классификации.

График перезаписи последовательного роста метрики $R^2$ при добавлении выбранных признаков показан ниже:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Итерация} & \textbf{Добавленный признак} & \boldmath${R^2}$ \\ \hline
1                 & $A$                       & 0.45             \\ \hline
2                 & $B$                       & 0.53             \\ \hline
3                 & $C$                       & 0.58             \\ \hline
\end{tabular}
\end{table}

Между тем, известна модель из полного перебора, где признаковая комбинация $({A, D, E})$ даёт $R^2 = 0.67$.

Почему метод Add мог не найти эту комбинацию? Как можно было бы исправить эту ситуацию и повысить вероятность нахождения глобального оптимума?

\subsubsection{Ответ 2.}

Жадный алгоритм Add выбирает признак на каждом шаге, который локально улучшает метрику максимально. Однако комбинация $({A, D, E})$ могла быть значимой только в сочетании (то есть признаки дают прирост метрики только в комбинации), а по отдельности эти фичи дают не такой хороший прирост к метрике, как $B$ и $C$. Add не проверяет взаимодействие признаков, поэтому выбор локально наилучших признаков $({A, B, C})$ мог игнорировать комбинацию, которая глобально лучше.

\textbf{Как с этим можно бороться?}
\begin{itemize}
    \item Проверять метрику при добавлении не одного признака, а пары/тройки/произвольного числа $m$ признаков.
    \item Использовать модификацию жадного алгоритма с дополнительными "прыжками", то есть, например, после 3 итераций Add можно сделать перезапуск среди лучших комбинаций 2 признаков.
\end{itemize}

\subsubsection{Вопрос 3.}

Есть набор данных с 20 признаками. Известно, что 10 из них абсолютно не связана с целевой переменной, т.е. являются шумовыми. Однако не известно, какие именно из них являются шумовыми. Для отбора признаков был применен жадный алгоритм Add.

Предположим, что на первых итерациях жадный алгоритм случайно выбрал несколько шумовых признаков, так как они хорошо улучшили метрику на обучающей выборке.

Как это повлияет на работу алгоритма Add в следующих итерациях? Какие подходы вы бы предложили, чтобы минимизировать вероятность включения шумовых признаков на ранних этапах?

\subsubsection{Ответ 3.}\

\textbf{1. Как это повлияет на дальнейшую работу алгоритма?}

Жадный алгоритм фиксирует признаки и рассматривает следующие шаги на основе текущего набора. Если шумовые признаки остаются в модели, они могут "вытеснять" более значимые признаки в дальнейших итерациях.
Итоговый результат может быть хуже, так как модель становится менее интерпретируемой и более склонной к переобучению на шум.

\textbf{2. Как можно минимизировать влияние шума на обучение?}

Для этого стоит перед алгоритмом применить другие фильтрационные методы для удаления явно нерелевантных признаков, например, убрать признаки, плохо коррелирующие с целевой переменной.

Также для этого можно попробовать применить кросс-валидацию при оценке каждого нового признака, чтобы убедиться, что он действительно улучшает модель (а не только улучшает метрику на обучающей выборке).

\section{Методы преобразования категориальных признаков}

Категориальные признаки (или категориальные переменные) — это тип данных, который представляет собой категории или группы. В отличие от количественных признаков, которые принимают числовые значения, категориальные признаки описывают качественные характеристики.

\begin{itemize}
	\item Номинальные признаки -- эти признаки представляют собой категории, которые не имеют никакого порядка (город, где проживает человек; цвет машины).
	\item Порядковые признаки -- эти признаки также представляют категории, но в отличие от номинальных, они имеют естественный порядок (уровень образования; степень удовлетворенности).
\end{itemize}

Такие признаки невозможно напрямую использовать в моделях машинного обучения, поскольку они работают с числами. Для решения этой проблемы есть различные методы.

\subsection*{One-hot (dummy) encoding}

One-hot encoding — это метод кодирования категориальных переменных, который преобразует каждую категорию в бинарный вектор, где только один элемент равен 1 (представляет категорию), а все остальные элементы равны 0.

Преимущества:
\begin{itemize}
	\item Он легко реализуется, а данные легко интерпретируются.
	\item Хорошо совместим почти со всеми алгоритмами.
	\item Подходит для изначально неупорядоченных данных.
\end{itemize}

Недостатки:
\begin{itemize}
	\item В случае большого количества категорий сильно увеличивает размерность, может привести к переобучению.
	\item Полученные признаки сильно разреженны, неэффективно по памяти и скорости вычислений.
	\item Не подходит для упорядоченных или взаимосвязанных данных.
\end{itemize}

\subsection*{Effect (treatment, deviation) encoding}

Effect encoding  — это метод кодирования категориальных переменных, который представляет каждую категорию в виде разности между средним значением целевой переменной и средними значениями для каждой категории. Этот метод позволяет учитывать информацию о влиянии каждой категории на целевую переменную.

Преимущества:
\begin{itemize}
	\item Сохраняет информацию о влиянии категории на целевую переменную.
	\item Не увеличивает размерность пространства признаков.
	\item Создает порядок между категориями, основываясь на значении целевой переменной.
\end{itemize}

Недостатки:
\begin{itemize}
	\item Не так прост для интерпретации, как one-hot encoding.
	\item Может создать многократную коллинеарность между несколькими категориальными признаками.
\end{itemize}

\subsection*{Label (ordinal) encoding}

Label encoding — это метод кодирования категориальных переменных, при котором каждой категории присваивается уникальное целочисленное значение.

Преимущества:
\begin{itemize}
	\item Прост в реализации.
	\item Не увеличивает размерность пространства признаков.
	\item Сохраняет информацию порядковых признаков.
	\item Хорошо совместим с алгоритмами, не зависящими от расстояния между значениями (деревья решений).
\end{itemize}

Недостатки:
\begin{itemize}
	\item Создает ложный порядок в номинальных признаках.
	\item Плохо совместим с линейными моделями.
	\item Создает ложные расстояния между категориями.
\end{itemize}

\subsection*{Count encoding}

Count encoding — это метод кодирования категориальных переменных, при котором каждой категории присваивается количество её появлений в наборе данных. 
	
Преимущества:
\begin{itemize}
	\item Прост в реализации.
	\item Сохраняет информацию о частоте.
	\item Не увеличивает размерность пространства признаков.
\end{itemize}

Недостатки:
\begin{itemize}
	\item Не сохраняет информацию порядковых признаков.
	\item Может создать коллинеарность для разных категорий с близкими частотами.
	\item Создает ложные расстояния между категориями.
\end{itemize}

\subsection*{Задача 1}

В случае использования one-hot encoding для категориального признака с $N$ уникальными значениями, мы получим $N$ новых признаков. Однако любой признак выражается через остальные, поскольку единица всегда стоит только в одном из них. То есть мы получили мультиколлинеарность, которая может ухудшить качества модели! Каким образом можно решить эту проблему?

\subsection*{Решение}

Самым простым решением будет просто удалить любой из полученных признаков. Мы избавимся от мультиколлинеарности и сохраним всю информацию о выборке.

\subsection*{Задача 2}

Проведите преобразование категориальных признаков по методу effective encoding:
\begin{table}[ht]
	\footnotesize
	\begin{tabular}{lllll}
		\hline
		Пробег, тыс. км & Цвет    & Год выпуска & Тип кузова & Стоимость, у.е. \\ \hline
		100             & Красный & 2015        & Хэтчбэк    & 10           \\
		10              & Зеленый & 2019        & Cедан      & 17           \\
		17              & Cиний   & 2022        & Cедан      & 18           \\
		150             & Красный & 2019        & Универсал  & 15           \\
		30              & Красный & 2023        & Хэтчбэк    & 20           \\
		174             & Cиний   & 2017        & Хэтчбэк    & 12           \\
		89              & Зеленый & 2017        & Хэтчбэк    & 14           \\ \hline
	\end{tabular}
\end{table}

\subsection*{Решение}

Для каждого цвета вычислим средние значение стоимости:
\begin{itemize}
	\item Красный: $r = \frac{10+15+20}{3}=15$.
	\item Зеленый: $g = \frac{17+14}{2}=15.5$.
	\item Синий: $b = \frac{18+9}{2}=13.5$.
\end{itemize}

Тогда среднее для всех признаков:
$$ avg = \frac{15 + 15.5 + 13.5}{3} = 14.66. $$

Значение нового признака, например, для красного цвета:
$$ r - avg = 0.33. $$

\begin{table}[ht]
	\footnotesize
	\begin{tabular}{lllllll}
		\hline
		Пробег, тыс. км & Цвет    & Год выпуска & Тип кузова & Цвет (eff) & Тип кузова (eff) & Стоимость, у.е. \\ \hline
		100             & Красный & 2015        & Хэтчбэк    & 0,33        & -2,00           & 10           \\
		10              & Зеленый & 2019        & Cедан      & 0,83        & 2,25            & 17           \\
		17              & Cиний   & 2022        & Cедан      & -1,16      & 2,25             & 18           \\
		150             & Красный & 2019        & Универсал  & 0,33        & -0.25             & 15           \\
		30              & Красный & 2023        & Хэтчбэк    & 0,33        & -2,00            & 20           \\
		174             & Cиний   & 2014        & Хэтчбэк    & -1,16      & -2,00            & 9            \\
		89              & Зеленый & 2017        & Хэтчбэк    & 0,83        & -2,00            & 14           \\ \hline
	\end{tabular}
\end{table}

\subsection*{Задача 3}

Предложите методы обработки пропущенных значений признаков.
Подсказка: можно основываться на некоторых методах преобразования категориальных признаков.

\subsection*{Решение}

Некоторые из возможных вариантов:
\begin{itemize}
	\item Добавление отдельного бинарного признака: есть/нет значение у исходного признака.
	\item Вычисление среднего по всем объектам с пропущенным значением исходного признака.
	\item Задание произвольных, не совпадающих с остальными, значений для каждого пропущенного значения исходного признака.
	\item Вычисление частоты пропущенных признаков.
\end{itemize}





\section*{Случайный поиск с адаптацией}
Будем действовать, используя обозначения и задачу из предыдущей главы и попробуем продвинуться дальше.

Эволюционный алгоритм требует определения операций мутации и скрещивания, что может быть само по себе сложно (непонятно, как определять эти операции, и непонятно, как результаты и эффективность алгоритма зависят от определения). Потому оказывается удобным алгоритм \textit{случайного поиска с адаптацией}, который устроен похожим образом, но пользуется лишь генерацией случайных величин и функцией обновления $f$ --- функцией, которая описывает, как менять вероятность появления признака в зависимости от того, насколько он свойственнен лучшим или худшим индивидам популяции.

\begin{algorithmic}
\State \textbf{Вход:} $F$ --- множество признаков, $Q$ --- критерий качества модели, $d$ --- максимальное время ''простоя'', поколений без улучшения, $B$ --- размер ''популяции'' на каждом шаге, $T$ --- максимальное число поколений
\State \textbf{Переменная:} $R_t, \;t \in \{1, 2, \ldots, T\}$ --- популяции. Каждая популяция --- множество размера $B$, элементы которого --- $J_t^i,\;i \in \{1, 2, \ldots, B\}, J_t^i \subseteq F$.
\State \textbf{Переменная:} $p_t^i,\;t \in \{1, 2, \ldots, T\},\;i \in \{1, 2, \ldots, |F|\}$ --- вероятности включения $i$-го признака в $t$-е поколение.
\State \textbf{Переменная:} $t^*$ --- номер итерации, на которой был получен лучший индивид
\State $t^* := 0$
\For{$i \in \{1, 2, \ldots, |F|\}$}
    \State $p_1^i = \frac{1}{|F|}$
\EndFor
\For{$i \in \{1, 2, \ldots, B\}$}
    \State $J_1^j \sim \left(Bern(p_1^1), Bern(p_1^2), \ldots, Bern(p_1^{|F|})\right)$
\EndFor
\State Отсортировать $J_1^i$, чтобы $Q(J_1^1) \leqslant \ldots \leqslant Q(J_1^B)$
\For{$t \in \{1, 2, \ldots, T\}$, $t$ --- номер поколения} 
    \If{$t = 0$ или $Q(J_t^1) < Q(J_{t-1}^1)$}
        \State $t^* = t$
    \EndIf
    \If{$t - t^* \geqslant d$}
        \State \textbf{Вернуть:} $J_{t^*}^1$
    \EndIf
    \For{$i \in \{1, 2, \ldots, |F|\}$}
        \State $p_{t+1}^i = f(p_t^i, J_t^1, \ldots, J_t^B)$
    \EndFor
    \State $R_{t + 1} = R_t \cup \left\{J_{t + 1}^1, \ldots, J_{t + 1}^B \sim \left(Bern(p_{t + 1}^1), Bern(p_{t + 1}^2), \ldots, Bern(p_{t + 1}^{|F|})\right)\right\}$
    \State Отсортировать $J_{t + 1}^i$, чтобы $Q(J_{t + 1}^1) \leqslant \ldots \leqslant Q(J_{t + 1}^{2B})$
    \State Оставить в $R_{t + 1}$ только $B$ лучших (первых)
\EndFor 
\State \textbf{Вернуть:} $J_{t^*}^1$
\end{algorithmic}


\begin{problem}
    Почему в алгоритме случайного поиска с адаптацией $J_t^1$ сравнивается только с предыдущим $J_{t-1}^1$ (когда определяется, улучшился ли результат), когда в эволюционном алгоритме для этого специально хранили значение $Q^*$ и сравнивали с ним?
\end{problem}
\begin{solution}
    В алгоритме случайного поиска с адаптацией к каждому следующему поколению добавляется и предыдущее:\\ $R_{t + 1} = R_t \cup \left\{J_{t + 1}^1, \ldots, J_{t + 1}^B \sim \left(Bern(p_{t + 1}^1), Bern(p_{t + 1}^2), \ldots, Bern(p_{t + 1}^{|F|})\right)\right\}$. Поэтому лучший индивид из поколения $t-1$ будет не хуже, чем лучшие индивиды всех предыдущих поколений.
\end{solution}

\begin{problem}
    Пусть $F = \{U, V\}, Q(J) = |J \Delta F_0|$, где $F_0 \subseteq F$ --- ''лучший набор параметров''. $$f(p_i, J_t^1, \ldots, J_t^B) = \begin{cases}
    p_i, & \text{ если } $Q(J_t^1) = Q(J_t^B)$,\\
    p_i, & \text{ если } i \in J_t^1 \text{ и } i \in J_t^B,\\
    p_i, & \text{ если } i \notin J_t^1 \text{ и } i \notin J_t^B,\\
    \frac{p_i}{2}, & \text{ если } i \notin J_t^1 \text{ и } i \in J_t^B,\\
    \frac{1 + p_i}{2}, & \text{ если } i \in J_t^1 \text{ и } i \notin J_t^B
\end{cases}$$

    Докажите, что алгоритм вернёт $F_0$ с вероятностью, экспоненциально близкой к 1 по $d$.
\end{problem}
\begin{solution}
    Поскольку $Q$ и $f$ симметричны относительно замены $p \mapsto 1-p$, без ограничения общности можно считать, что $F_0 = \emptyset, Q(J) = |J|$. Из алгоритма следует, что он вернёт $F_0$, если хотя бы раз его сгенерирует. Теперь заметим, что из определения $f$, если $F_0 = \emptyset$, $p_i$ не могут увеличиваться (поскольку если $i \in J_1$, $i \notin J_2$, то $|J_1| \geqslant |J_2|$). А значит, на каждой итерации вероятность сгенерировать $F_0$ хотя бы $\left(1- \left(1 - \frac{1}{4}\right)^B\right)$ (поскольку изначально $p_i = \frac{1}{2}, i = 1,2$). А значит, с ростом $d$ вероятность того, что алгоритм ни разу не сгенерирует $F_0$ не превосходит $\frac{3}{4}^{Bd}$, то есть экспоненциально убывает по $d$.
\end{solution}
\begin{remark}
    Оценка в этой задаче очень грубая, так как с близкой к 1 вероятностью $p_i$ будут строго убывать, а значит, вероятность на каждом следующем шаге сгенерировать $F_0$ будет расти.
\end{remark}

\section*{Краткое описание теории схемы}
Чтобы обосновать корректность работы этого алгоритма, эволюционного алгоритма и подобных, была разработана \textit{теория схемы}.

\begin{definition}
    Схема --- это кортеж $H = (h_1, h_2, \ldots, h_{|F|}), \;h_i \in \{0, 1, *\}$. Множество $J \subseteq F$ называют подходящим под схему $H$, если $(h_i = 0 \Rightarrow F_i \notin J), (h_i = 1 \Rightarrow F_i \in J)$ (считаем $F = \{F_1, \ldots, F_{|F|}\}$). Обозначим это $J \in H$
\end{definition}
Интуитивно схемы --- это недоопределённые характеристические функции множеств.
\begin{definition}
    $m(H, t) = \#\{J_t^i \in H\}$ --- количество подходящих под схему $H$ индивидов из поколения $t$.
\end{definition}
\begin{definition}
    Приспособленность схемы $H$ на поколении $t$: $$f(H, t) = \frac{1}{m(H, t)}\sum_{J_t^i \in H}Q(J_t^i)$$
\end{definition}
Заметим, что $f(*^{|F|}, t)$ --- средняя приспособленность популяции. Обозначим её ха $\overline{f}(t)$.
\begin{definition}
    Порядок схемы: $o(H) = \#\{i|h_i \neq *\}$\\
    Длина схемы: $d(H) = \max\{i|h_i \neq *\} - \min\{i|h_i \neq *\}$
\end{definition}

Отсюда мы перейдём к несколько более неформальному языку, поскольку теория схемы довольно объемная и непростая, за подробностями отошлём к работе \cite{White14}.

\begin{definition}
    Строительный блок. Строительным блоком называют схему небольшой длины и небольшого порядка с приспособленностью выше средней по схемам с теми же показателями порядка и длины.
\end{definition}

\begin{hypothesis}
    Хорошие генетические алгоритмы комбинируют строительные блоки для получения лучших индивидов.
\end{hypothesis}

\begin{remark}
    Как отмечает автор \cite{White14}, гипотеза остаётся гипотезой во многом из-за того, что требует математической формализации, которую пока никто не сформулировал достаточно хорошо.
\end{remark}

Пусть теперь генетический алгоритм использует \textit{''одноточечное скрещивание''}: $$F_i \in A \times B \Leftrightarrow \begin{cases}
    F_i \in A, & \text{ если } i \leqslant k,\\
    F_i \in B, & \text{ если } i > k
\end{cases}, \textit{ для некоторого } k$$
а одна мутация может изменить принадлежность множеству лишь одного элемента ($|\sim X \Delta X| \leqslant 1$, где $\Delta$ --- это симметрическая разность).
Тогда можно сформулировать теорему:
\begin{theorem}
    Теорема Схемы.
    $$\mathbb{E}m(H, t + 1) \geqslant \frac{f(H, t)}{\overline{f}(t)}\cdot m(H, t)\cdot\left(1 - \alpha\frac{d(H)}{|F| - 1}\right)(1 - \beta)^{o(H)}$$
    где $\alpha, \beta$ --- некоторые константы, тоже зависящие от алгоритма.
\end{theorem}

\begin{corollary}
    В некотором смысле из этой теоремы следует гипотеза о строительных блоках: если $\frac{f(H, t)}{\overline{f}(t)} > 1$, а $d(H)$ и $o(H)$ небольшие, то $m(H, t)$ растёт, причём какое-то время --- экспоненциально. Соответственно, большая часть популяции будет соответствовать этому строительному блоку. Поскольку это верно для всех строительных блоков --- это и значит, что строительные блоки были скомбинированы, чтобы получить лучших индивидов.
\end{corollary}

\begin{problem}
    Пусть $H^1$ и $H^2$ --- два строительных блока, причём $h^1_i \neq * \Rightarrow h^2_i = *$ и наоборот: $h^2_i \neq * \Rightarrow h^1_i = *$. Найдите оценки для $k = \#\{J_t^i| J_t^i \in H^1, J_t^i \in H^2\}$, если известны $m(H^1, t)$ и $m(H^2, t)$.
\end{problem}
\begin{solution}
    Снизу, конечно, оценить можно только нулём --- ведь могло быть так, что все индивиды, подходящие под первую схему, не подходили под вторую. Оценка сверху интереснее: с одной стороны $k \leqslant \min\{m(H^1, t), m(H^2, t)\}$ просто потому, что $\{J_t^i| J_t^i \in H^1, J_t^i \in H^2\} \subseteq \{J_t^i \in H^i\}$ для $i \in \{1, 2\}$. С другой стороны, если $J$ подходит и под $H^1$, и под $H^2$, то различные такие $J$ могут отличаться лишь в тех $F_i$, что $h_i^1 = *$ и $h_i^2 = *$, а таких --- $|F| - o(H^1) - o(H^2)$, что даёт итоговую формулу:
    $$k \leqslant \min\{m(H^1, t), m(H^2, t), 2^{|F| - o(H^1) - o()H^2}\}$$
\end{solution}





\section*{SHAP-values}

\subsection*{Определение}
SHAP-values (SHapley Additive exPlanations) — это метод объяснения моделей машинного обучения, который помогает понять, как каждый признак влияет на предсказание модели. SHAP-values основаны на концепции теории Шепли из теории игр, которая используется для справедливого распределения вклада каждого игрока (в данном случае, признака) в общий результат (предсказание модели).\\\\
SHAP-value для признака $i$ в точке данных $x$ определяются как среднее значение маржинальных вкладов этого признака по всем возможным коалициям признаков. Формально можно записать так:

\[ \phi_i(x) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N|-|S|-1)!}{|N|!} [f_x(S \cup \{i\}) - f_x(S)] \]
где $N$ — множество всех признаков; $S$ — подмножество признаков, не включающее $i$; $f_x(S)$ — предсказание модели на подмножестве признаков $S$ в точке $x$.

\subsection*{Пример подсчёта SHAP-values}
Рассмотрим простую линейную модель:
$$ y = 2x_1 + 3x_2 + 5 $$
В качестве примера рассмотрим точку (сэмпл) $(1, 2)$. Для него модель предсказывает:
$$ y = 2 \cdot 1 + 3 \cdot 2 + 5 = 13 $$
Вычислим SHAP-value для этого наблюдения:
\begin{enumerate}
    \item Считаем предсказание для пустого множества признаков. В данном случае это просто свободный член, в общем случае это может быть усреднённое предсказание модели по всем сэмплам:
        $$ f(\emptyset) = 5 $$

    \item Считаем предсказание для отдельных признаков:
        $$ f(x_1) = 2 \cdot 1 + 5 = 7 $$
        $$ f(x_2) = 3 \cdot 2 + 5 = 11 $$

    \item Считаем полное предсказание для всех пар признаков:  
        $$ f(x_1, x_2) = 2 \cdot 1 + 3 \cdot 2 + 5 = 13 $$

    \item Если бы признаков было больше, то мы рассматривали остальные комбинации, но здесь мы рассмотрели все возможные.
\end{enumerate}

Теперь вычислим SHAP-values для каждого признака:
\begin{itemize}
    \item Для $x_1$:  
        $$
        \phi_{x_1} = \frac{1}{2} \left[ (f(x_1) - f(\emptyset)) + (f(x_1, x_2) - f(x_2)) \right] = \frac{1}{2} \left[ (7 - 5) + (13 - 11) \right] = 2
        $$
    \item Для $x_2$:
        $$
        \phi_{x_2} = \frac{1}{2} \left[ (f(x_2) - f(\emptyset)) + (f(x_1, x_2) - f(x_1)) \right] = \frac{1}{2} \left[ (11 - 5) + (13 - 7) \right] = 6
        $$
\end{itemize}

\subsection*{Применение}
SHAP-value для конкретного признака рассчитывается по всем наблюдениям, затем полученные значения суммируются по модулю, и получается итоговая важность этого признака.
В реальных задачах, особенно с большим количеством признаков, вычисление SHAP-values может быть вычислительно крайне затратной, поэтому под капотом используются различные алгоритмы оптимизации вычислений, эвристики и аппроксимации для формулы выше. Однако это уже детали реализации, про которые можно прочитать \href{https://github.com/shap/shap}{здесь}.

\subsection*{Преимущества и зоны риска}
SHAP-values учитывают взаимодействие между признаками и могут быть применены к любой модели машинного обучения, но особенно полезны они для интерпретации Black-Box моделей, таких как ансамбли деревьев или нейронные сети. Несмотря на сложность этих моделей, SHAP-values дают возможность понять, как признаки влияют на предсказание. Это делает их универсальным инструментом для улучшения интерпретируемости и производительности моделей.\\
\textbf{Важно!} понимать, что SHAP-values зависят от структуры модели, и разные модели могут давать разные SHAP-values для одних и тех же данных. Это следует учитывать при интерпретации результатов.

\subsection*{Задачи}
\begin{itemize}
    \item Рассчитайте SHAP-value для признака $x_1$ в линейной модели 
    $$y = 4 \cdot x_1 + x_2 + 6$$ для сэмпла $(2, 3)$\\\\
    \textit{Решение:\\
    Посчитаем предсказания модели на всевозможных комбинациях признаков
    $$ f(\emptyset) = 6 $$  
    $$ f(x_1) = 4x_1 + 6 = 4 \cdot 2 + 6 = 14 $$
    $$ f(x_2) = x_2 + 6 = 3 + 6 = 9 $$
    $$ f(x_1, x_2) = 4x_1 + x_2 + 6 = 4 \cdot 2 + 3 + 6 = 17 $$
    Теперь можем посчитать значения SHAP-values для признака $x_1$
    $$
    \phi_{x_1} = \frac{1}{2} \left[ (f(x_1) - f(\emptyset)) + (f(x_1, x_2) - f(x_2)) \right] = \frac{1}{2} \left[ (14 - 6) + (17 - 9)\right] = \boxed{8}
    $$}

    \item Петя посчитал SHAP-value для признака $x_1$ и признака $x_2$ по сэмплу $(1, 1)$ и получил $\phi_{x_1} = 0, \phi_{x_2} = -1$. Он читал, что чем больше shap-value признака, тем более он важен для модели, поэтому выбрал $x_1$. Прав ли Петя?\\\\
    \textit{Решение: Нет, признак $x_1$ не внёс совершенно никакого вклада в предсказание модели на данном сэмпле. Утверждение, которое он использовал, верно лишь тогда, когда SHAP-value для признаков проссумированы по модулю по всем наблюдениям.}
    
    \item Пети нужно выбрать, какой из признаков $x_1$ и $x_2$ более важен для модели. Петя посчитал для каждого наблюдения SHAP-value признаков $x_1$ и $x_2$. Просуммировав их, он получил $\phi_{x_1} = 0, \phi_{x_2} = 10$. Он читал, что чем больше shap-value признака, тем более он важен для модели, поэтому выбрал $x_2$. Прав ли Петя?\\\\
    \textit{Решение: Если суммировать SHAP-value признака по всем наблюдениям не по модулю, то может сложиться ситуация, в которой важный признак вносил большие, но симметричные относительно нуля вклады в предсказания по каждому сэмплу таким образом, что в сумме получился 0 (или что-то близкое к нулю), а неважный признак мог вносить исключительно небольшой вклад положительного знака, тем самым аккумулируя в сумме большую важность.} 
\end{itemize}


\section*{ROC, AUC и алгоритм построения кривой}

ROC-кривая (Receiver Operating Characteristic) и площадь под кривой (AUC, Area Under Curve) являются популярными инструментами для оценки качества бинарных классификаторов. Эти методы позволяют визуализировать и количественно оценить способность модели различать положительные и отрицательные классы.

ROC-кривая
ROC-кривая строится путём отображения отношений между двумя метриками при варьировании порога классификации:
\begin{itemize}
    \item \textbf{TPR (True Positive Rate):} доля правильно предсказанных положительных случаев среди всех положительных случаев:
    \[
    TPR = \frac{TP}{TP + FN},
    \]
    где $TP$ (True Positives) \textendash\ число истинно положительных, а $FN$ (False Negatives) \textendash\ число ложно отрицательных.
    \item \textbf{FPR (False Positive Rate):} доля отрицательных примеров, ошибочно классифицированных как положительные:
    \[
    FPR = \frac{FP}{FP + TN},
    \]
    где $FP$ (False Positives) \textendash\ число ложно положительных, а $TN$ (True Negatives) \textendash\ число истинно отрицательных.
\end{itemize}
ROC-кривая представляет собой график зависимости $TPR$ от $FPR$.

Площадь под кривой (AUC)
AUC (Area Under Curve) \textendash\ это площадь под ROC-кривой, которая показывает, насколько хорошо модель различает классы. Значения AUC интерпретируются следующим образом:
\begin{itemize}
    \item $AUC = 1$ \textendash\ идеальная модель.
    \item $AUC = 0.5$ \textendash\ модель не лучше случайного угадывания.
    \item $0.5 < AUC < 1$ \textendash\ модель имеет определённую способность различать классы.
\end{itemize}
Чем ближе $AUC$ к 1, тем лучше классификатор.

\subsection*{Алгоритм построения ROC-кривой}

\begin{enumerate}
    \item \textbf{Шаг 1. Сортировка предсказаний:} Отсортируйте примеры по предсказанной вероятности принадлежности к положительному классу в порядке убывания.
    \item \textbf{Шаг 2. Вычисление метрик:} Для каждого возможного порога:
    \begin{itemize}
        \item Рассчитайте $TP$, $FP$, $FN$, $TN$.
        \item Вычислите $TPR$ и $FPR$.
    \end{itemize}
    \item \textbf{Шаг 3. Построение графика:} Отобразите точки $(FPR, TPR)$ на графике и соедините их линиями.
\end{enumerate}


\subsection*{Задача 1: Построение ROC-кривой}

Вы создали модель, которая предсказывает вероятность заболевания. У вас есть следующие данные для 10 человек:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Человек} & \textbf{Вероятность $p$} & \textbf{Истинный класс $y$} \\
\hline
1 & 0.9 & 1 \\
2 & 0.8 & 1 \\
3 & 0.7 & 0 \\
4 & 0.6 & 1 \\
5 & 0.55 & 0 \\
6 & 0.5 & 1 \\
7 & 0.4 & 0 \\
8 & 0.3 & 1 \\
9 & 0.2 & 0 \\
10 & 0.1 & 0 \\
\hline
\end{tabular}
\end{table}

Постройте ROC-кривую и вычислите площадь под ней (AUC).

\subsection*{Решение}

Шаг 1: Сортировка по вероятностям $p$

Упорядочим строки по убыванию вероятностей $p$:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Человек} & \textbf{Вероятность $p$} & \textbf{Истинный класс $y$} \\
\hline
1 & 0.9 & 1 \\
2 & 0.8 & 1 \\
4 & 0.6 & 1 \\
6 & 0.5 & 1 \\
8 & 0.3 & 1 \\
3 & 0.7 & 0 \\
5 & 0.55 & 0 \\
7 & 0.4 & 0 \\
9 & 0.2 & 0 \\
10 & 0.1 & 0 \\
\hline
\end{tabular}
\end{table}

Шаг 2: Вычисление TPR и FPR для каждого порога

Определим пороги вероятности, подсчитаем количество True Positives ($TP$), False Positives ($FP$), False Negatives ($FN$) и True Negatives ($TN$), а затем рассчитаем $TPR = \frac{TP}{TP + FN}$ и $FPR = \frac{FP}{FP + TN}$:

\[
\text{Результаты расчетов:}
\]

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Порог} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{TN} & \textbf{TPR} & \textbf{FPR} \\
\hline
0.9 & 1 & 0 & 4 & 5 & 0.2 & 0.0 \\
0.8 & 2 & 0 & 3 & 5 & 0.4 & 0.0 \\
0.7 & 2 & 1 & 3 & 4 & 0.4 & 0.2 \\
0.6 & 3 & 1 & 2 & 4 & 0.6 & 0.2 \\
0.55 & 3 & 2 & 2 & 3 & 0.6 & 0.4 \\
0.5 & 4 & 2 & 1 & 3 & 0.8 & 0.4 \\
0.4 & 4 & 3 & 1 & 2 & 0.8 & 0.6 \\
0.3 & 5 & 3 & 0 & 2 & 1.0 & 0.6 \\
0.2 & 5 & 4 & 0 & 1 & 1.0 & 0.8 \\
0.1 & 5 & 5 & 0 & 0 & 1.0 & 1.0 \\
\hline
\end{tabular}
\end{table}



Шаг 3: Построение ROC-кривой

\includegraphics[width=0.8\textwidth]{roc_task1.png}

Шаг 4: Вычисление AUC

AUC вычисляем как площадь под ROC-кривой методом трапеций:
\[
AUC = 0.5 \cdot (0.2 + 0.4) \cdot 0.2 + \dots + 0.5 \cdot (1.0 + 1.0) \cdot 0.2 = 0.84.
\]

\subsection*{Задача 2: Сравнение моделей по AUC}

Даны результаты двух моделей \(A\) и \(B\) по классификации клиентов. Вычислены их ROC-координаты:

\begin{itemize}
    \item Модель \(A\): \((0, 0), (0.1, 0.5), (0.4, 0.8), (1, 1)\),
    \item Модель \(B\): \((0, 0), (0.2, 0.4), (0.5, 0.7), (1, 1)\).
\end{itemize}

Определите, какая модель лучше, вычислив AUC.

\subsection*{Решение}

Вычисление AUC для модели \(A\)

Используем метод трапеций для вычисления площади под ROC-кривой:
\[
AUC_A = \frac{1}{2} \cdot (0.5 + 0.8) \cdot (0.4 - 0.1) + \frac{1}{2} \cdot (0.8 + 1.0) \cdot (1 - 0.4).
\]

Подставляем значения:
\[
AUC_A = \frac{1}{2} \cdot 1.3 \cdot 0.3 + \frac{1}{2} \cdot 1.8 \cdot 0.6.
\]

Вычисляем:
\[
AUC_A = 0.195 + 0.54 = 0.79.
\]

Вычисление AUC для модели \(B\)

Аналогично, для модели \(B\):
\[
AUC_B = \frac{1}{2} \cdot (0.4 + 0.7) \cdot (0.5 - 0.2) + \frac{1}{2} \cdot (0.7 + 1.0) \cdot (1 - 0.5).
\]

Подставляем значения:
\[
AUC_B = \frac{1}{2} \cdot 1.1 \cdot 0.3 + \frac{1}{2} \cdot 1.7 \cdot 0.5.
\]

Вычисляем:
\[
AUC_B = 0.165 + 0.425 = 0.745.
\]

Сравнение

Поскольку:
\[
AUC_A = 0.79 > AUC_B = 0.745,
\]
модель \(A\) лучше, так как её показатель AUC выше.

\subsection*{Задача 3: Алгоритм построения ROC-кривой}

Имеется выборка из 6 наблюдений с предсказанными вероятностями и истинными классами:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Наблюдение} & \textbf{Вероятность $p$} & \textbf{Истинный класс $y$} \\
\hline
1 & 0.9 & 1 \\
2 & 0.85 & 0 \\
3 & 0.8 & 1 \\
4 & 0.7 & 0 \\
5 & 0.65 & 1 \\
6 & 0.4 & 0 \\
\hline
\end{tabular}
\end{table}

Опишите алгоритм построения ROC-кривой и постройте её.

\subsection*{Решение}

Шаг 1: Сортировка по вероятностям $p$

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Наблюдение} & \textbf{Вероятность $p$} & \textbf{Истинный класс $y$} \\
\hline
1 & 0.9 & 1 \\
2 & 0.85 & 0 \\
3 & 0.8 & 1 \\
4 & 0.7 & 0 \\
5 & 0.65 & 1 \\
6 & 0.4 & 0 \\
\hline
\end{tabular}
\end{table}

Шаг 2: Вычисление TPR и FPR для каждого порога

\[
\text{Результаты расчетов:}
\]

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Порог} & \textbf{TP} & \textbf{FP} & \textbf{FN} & \textbf{TN} & \textbf{TPR} & \textbf{FPR} \\
\hline
0.9 & 1 & 0 & 2 & 3 & 0.33 & 0.0 \\
0.85 & 1 & 1 & 2 & 2 & 0.33 & 0.25 \\
0.8 & 2 & 1 & 1 & 2 & 0.67 & 0.25 \\
0.7 & 2 & 2 & 1 & 1 & 0.67 & 0.5 \\
0.65 & 3 & 2 & 0 & 1 & 1.0 & 0.5 \\
0.4 & 3 & 3 & 0 & 0 & 1.0 & 0.75 \\
\hline
\end{tabular}
\end{table}

Шаг 3: Построение ROC-кривой

\includegraphics[width=0.8\textwidth]{roc_task3.png}

Шаг 4: Вычисление AUC

AUC вычисляется методом трапеций:
\[
AUC = 0.5 \cdot (0.33 + 0.33) \cdot 0.25 + \dots + 0.5 \cdot (1.0 + 1.0) \cdot 0.25 = 0.78.
\]
