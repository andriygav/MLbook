\section{Неразмеченные данные в глубоком обучении}

\subsection{Постановка}
\hspace{2em}Общий подход к решению задачи с неразмеченными данными следующий:

$\mathcal{U} \subset \mathcal{X}$ --- большая неразмеченная выборка,

$\mathcal{D} \subset  \mathcal{X}\times \mathcal{Y}$ --- небольшая размеченная выборка,

требуется построить отображение $f: \mathcal{X} \to \mathcal{Y}$.

\subsection{Суперпозиция}
\hspace{2em}Предположение $f = c  \circ  h$ --- отображение есть суперпозия двух функций:

$h$ --- генерация признакового описания $h: \mathcal{X} \to \mathcal{H}$,

$c$ --- классификатор $c: \mathcal{H} \to \mathcal{Y}$.

Заметим, что $c$ и $h$, например, это некоторое параметрические функции, параметры которых нужно найти.

Простой пример:

$h$ --- все слои полносвязного многослойного перцептрона,

$c$ --- последний слой.

Обычно $h$ является сложной моделью, а $c$ --- линейной. Рассмотрим более подробный пример.

\subsection{Постановка задачи SimCLR}

\hspace{2em}Постановка задачи SimCLR заключается в том, что даётся набор изображений без каких-либо меток, и нужно обучить модель на этих данных так, чтобы она могла быстро адаптироваться к любой задаче распознавания изображений впоследствии.

Цель обучения - найти такое признаковое пространство, в котором изображения одного класса располагаются близко по введённой метрике, а изображения разных классов - далеко. Для этого используют различные \textit{контрастивные функции потерь}.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{chapters/unlabeled/simclr.png}
    \caption{Схематичное представление алгоритма SimCLR}
    \label{fig:enter-label-1}
\end{figure}

На рисунке можем схематичное представление последовательности шагов алгоритма со следующими обозначениями:

\begin{quote}
$x$ - исходное изображение,

$t, t'$ - разные аугментации на исходное изображение $x$ для получения представлений $\tilde{x_i}$, $\tilde{x_j}$,

$f$ - функция, генерирующая представления (representation) $h_i$, $h_j$ в виде вектора для входных изображений,

$g$ - функция, которая переводит вектора $h_i$, $h_j$ в величины $z_i$, $z_j$, для которых минимизируется расстояние (maximize agreement) в процессе обучения для аугментаций одного изображения и максимизируется для разных изображений.
\end{quote}

Шаги в обучении следующие:

1. К исходному изображению $x$ применяются аугментации $t, t'$. \textit{Аугментация} - это процесс создания новых данных на основе существующих с помощью преобразований. Такими преобразованиями для изображений являются, например, поворот, изменение яркости, гауссовское размытие и так далее. Она необходима, чтобы в новом признаковом пространстве изменённые изображения так же находились близко к изображениям того же класса.

2. К аугментированным изображениям $\tilde{x_i}$, $\tilde{x_j}$ применяется функция $f$, генерирующая векторное представление этих изображений $h_i$, $h_j$.

3. К векторным представлениям $h_i$, $h_j$ применяется функция $g$ для перевода в другое векторное представление. Данный шаг необязательный для обучения методом SimCLR.

4. Для $z_i$, $z_j$ уменьшается расстояние, если $\tilde{x_i}$, $\tilde{x_j}$ - аугментации одного и того же изображения, и увеличивается - если разных. Происходит это путём минимизации контрастивной функции потерь. 

Таким образом мы находим новое признаковое описание для изображения, с помощью которого можно обучиться на задачу классификации изображений, то есть найти функция $c$ из раздела про Суперпозицию.

\subsection{Вопросы}
\hspace{2em}1. Что такое суперпозиция в контексте построения модели для неразмеченных данных, и как она помогает в решении задачи с использованием методов глубокого обучения?

2. Каковы основные этапы и задачи в методе SimCLR?

3. Как аугментация данных способствует улучшению качества обучаемых представлений?

\section{Метод Expectation Regularization (XR)}

Рассмотрим задачу частичного обучения (\textit{semi-supervised learning}). Пусть дано множество объектов $X$ и множество классов $Y$. Предположим, что у нас имеется небольшой набор размеченных данных:
\[
X^k = \{ x_1, \ldots, x_k \} \quad \text{с метками} \quad \{y_1, \ldots, y_k\},
\]
где $y_i \in Y$ – известная метка класса для объекта $x_i$. Кроме того, нам даны неразмеченные данные:
\[
U = \{x_{k+1}, \ldots, x_{\ell}\},
\]
для которых метки классов неизвестны. Основная цель частичного обучения – используя как размеченные, так и неразмеченные данные, построить алгоритм классификации $a: X \rightarrow Y$ с лучшими обобщающими свойствами. В трансдуктивном случае, зная заранее все неразмеченные объекты, задача сводится к определению для них меток: $\{x_{k+1}, \ldots, x_{\ell}\} \rightarrow \{a_{k+1}, \ldots, a_{\ell}\}$.

Частичное обучение широко применяется: от классификации текстов и изображений до каталогизации и группировки данных в сложных приложениях, где полностью размеченные выборки собрать затруднительно или дорого.

\subsection{Многоклассовая логистическая регрессия.}

В качестве базовой модели рассмотрим многоклассовую логистическую регрессию. Предположим, что имеется конечный набор классов $Y = \{1, \ldots, |Y|\}$. Рассмотрим линейный классификатор:
\[
a(x) = \arg \max_{y \in Y} \langle w_y, x \rangle, 
\]
где $x \in \mathbb{R}^n$ – вектор признаков объекта, а $w_y \in \mathbb{R}^n$ – вектор параметров (весов) для класса $y$.

Вероятность принадлежности объекта $x_i$ классу $y$, согласно модели логистической регрессии, задаётся с помощью функции softmax:
\[
P(y \mid x_i, w) = \frac{\exp\langle w_y, x_i \rangle}{\sum_{c \in Y} \exp\langle w_c, x_i \rangle},
\]
где $w = (w_y: y \in Y)$ – совокупность всех параметров модели.

Оценка параметров модели $w$ производится путём максимизации регуляризованного правдоподобия по размеченным данным:
\[
Q(w) = \sum_{i=1}^k \log P(y_i \mid x_i, w) - \frac{1}{2C}\sum_{y \in Y}\|w_y\|^2 \;\; \to \max_w.
\]
Здесь $C > 0$ – параметр регуляризации, контролирующий степень сглаживания весов. Оптимизацию критерия $Q(w)$ обычно проводят методом стохастического градиента по параметрам $w$.

\subsection{Согласование модели на размеченных и неразмеченных данных.}

Для улучшения качества обучения в частично размеченных задачах целесообразно использовать неразмеченные данные $U = \{x_{k+1}, \ldots, x_{\ell}\}$. Пусть $b_j(x)$ – бинарный признак, связанный с объектом $x$, где $j = 1, \ldots, m$. Например, в задаче классификации текстов признак $b_j(x)$ может означать наличие или отсутствие определённого термина $j$ в документе $x$. 

Наша цель – согласовать вероятностную модель с эмпирическим распределением классов, оценённым по признакам. Рассмотрим вероятность принадлежности класса $y$ объекту, для которого признак $b_j$ активен ($b_j(x)=1$):
\[
\mathrm{P}(y \mid b_j(x)=1).
\]

Эту вероятность можно оценить двумя способами:

1. \textbf{Эмпирическая оценка} по размеченным данным $X^k$:
\[
\hat{p}_j(y) = \frac{\sum_{i=1}^k b_j(x_i)[y_i = y]}{\sum_{i=1}^k b_j(x_i)},
\]
где $[y_i = y]$ – индикаторная функция. Таким образом, $\hat{p}_j(y)$ – это частота встречаемости класса $y$ среди тех размеченных объектов, для которых признак $b_j(x)=1$.

2. \textbf{Оценка по неразмеченным данным} $U$ с использованием текущей вероятностной модели:
\[
p_j(y \mid w) = \frac{\sum_{i=k+1}^{\ell} b_j(x_i) P(y \mid x_i, w)}{\sum_{i=k+1}^{\ell} b_j(x_i)}.
\]
Здесь $P(y \mid x_i, w)$ – вероятность, предсказываемая моделью логистической регрессии, а числитель и знаменатель вычисляют взвешенную частоту класса $y$ среди объектов, в которых признак $b_j$ активен, но метки неизвестны. Таким образом, $p_j(y \mid w)$ – модельная оценка распределения классов по признаку $b_j(x)$, учитывающая неразмеченные данные.

Наша задача – приблизить модельное распределение $p_j(y \mid w)$ к эмпирическому распределению $\hat{p}_j(y)$.

\subsection{Построение регуляризатора (eXpectation Regularization, XR).}

Идея метода XR, предложенная в работе \cite{mann2007simple}, состоит в том, чтобы заставить модельные вероятности согласоваться с эмпирическими оценками. Для этого мы вводим дополнительный регуляризатор, максимизирующий логарифм правдоподобия модельных распределений с учётом признаков.

Для каждого признака $j$ рассмотрим логарифмическое правдоподобие:
\[
L_j(w) = \sum_{y \in Y} \hat{p}_j(y) \log p_j(y \mid w).
\]
Максимизация $L_j(w)$ по $w$ стремится сделать модельные оценки распределения классов по признаку $b_j$ максимально близкими к эмпирическим оценкам. 

Объединяя это с исходным критерием $Q(w)$, получаем:
\[
Q(w) + \gamma \sum_{j=1}^m L_j(w) = \sum_{i=1}^k \log P(y_i \mid x_i, w) 
- \frac{1}{2C}\sum_{y \in Y}\|w_y\|^2 +
\]
\[
+ \gamma \sum_{j=1}^m \sum_{y \in Y} \hat{p}_j(y)\log\left(\sum_{i=k+1}^{\ell} b_j(x_i)P(y \mid x_i, w)\right) \;\; \to \max_w.
\]

Здесь $\gamma > 0$ – коэффициент, отвечающий за степень влияния регуляризации XR. Итоговый критерий учитывает как размеченные данные (первое слагаемое), так и неразмеченные данные через эмпирические распределения по признакам (слагаемое с $L_j(w)$).

Оптимизация проводится методом стохастического градиента, обновляя параметры $w$ итеративно.

\subsection{Особенности и преимущества метода XR.}

Метод XR обладает рядом преимуществ и особенностей:

1. XR – это метод частичного обучения, но он \textbf{не} основан на кластеризации. Вместо этого он стремится согласовать распределения классов, предсказываемые моделью, с эмпирическими распределениями по признакам, оцененными по ограниченному набору размеченных данных.

2. Оптимизация осуществляется методом стохастического градиента, что обеспечивает масштабируемость на большие объемы данных.

3. Выбор признаков $b_j(x)$:

--- Если $b_j(x) \equiv 1$ для всех $x$, тогда $p_j(y \mid b_j(x)=1)$ интерпретируется как априорная вероятность класса $y$. Данная модель называется \textit{label regularization}, она особенно полезна в задачах с несбалансированными классами.

--- Если $b_j(x)$ указывает на присутствие или отсутствие конкретного термина $j$ в тексте $x$, то он подходит для классификации текстовых данных, так как учитывает распределение классов по характерным признакам.

4. Метод XR слабо чувствителен к выбору гиперпараметров $C$ и $\gamma$, устойчив к погрешностям в оценках $\hat{p}_j(y)$ и не требует большого числа размеченных объектов $k$.

5. XR хорошо работает в задачах категоризации текстов, где есть много неразмеченных данных, а получение полного набора разметки обходится слишком дорого или занимает много времени.

\subsection{Задачи.}

\bigskip

\noindent\textbf{Задача 1. Вычисление градиента XR-члена функционала}

Рассмотрим XR-член функционала:
\[
F_{\text{XR}}(w) = \gamma \sum_{j=1}^m \sum_{y \in Y} \hat{p}_j(y) \log\left(\sum_{x \in U_j} P(y \mid x,w)\right),
\]
где $U_j = \{ x_{k+1}, \ldots, x_{\ell} \mid b_j(x)=1 \}$ — подмножество неразмеченных объектов, для которых признак $b_j$ активен, и $\hat{p}_j(y)$ — эмпирическое распределение классов по признаку $b_j$.

Найдите градиент $F_{\text{XR}}(w)$ по параметрам $w_y$.

\subsubsection*{Решение:}

Обозначим
\[
A_{j,y}(w) = \sum_{x \in U_j} P(y \mid x,w).
\]

Тогда
\[
F_{\text{XR}}(w) = \gamma \sum_{j=1}^m \sum_{y \in Y} \hat{p}_j(y) \log A_{j,y}(w).
\]

Частная производная по $w_y$:
\[
\nabla_{w_y} F_{\text{XR}}(w) = \gamma \sum_{j=1}^m \sum_{y' \in Y} \hat{p}_j(y') \frac{1}{A_{j,y'}(w)} \sum_{x \in U_j} \nabla_{w_y}P(y' \mid x,w).
\]

Для логистической регрессии:
\[
\nabla_{w_y}P(y' \mid x,w) = P(y' \mid x,w)(\mathbb{I}[y'=y]-P(y \mid x,w))x.
\]

Подставляя в выражение:
\[
\nabla_{w_y} F_{\text{XR}}(w) = \gamma \sum_{j=1}^m \sum_{y' \in Y} \hat{p}_j(y') \frac{\sum_{x \in U_j} P(y' \mid x,w)(\mathbb{I}[y'=y]-P(y \mid x,w))x}{A_{j,y'}(w)}.
\]

Таким образом, мы получили формулу для градиента по параметрам $w_y$ от XR-члена функционала.

\bigskip

\noindent\textbf{Задача 2. Смешанное влияние априорных предположений и неразмеченных данных}

Пусть мы имеем априорное предположение о распределении классов (например, мы знаем, что класс $y=1$ встречается в 70\% случаев), а также большие неразмеченные данные $U$. Объясните, как совместный учёт априорной информации и структуры неразмеченного множества может улучшить точность классификации по сравнению с использованием только одного из этих источников информации.

\subsubsection*{Решение:}
Априорное предположение о распределении классов помогает задать общий «баланс» между классами и избежать смещения в пользу редких классов. Однако без знания структуры данных оно может быть неточно применено. Неразмеченные данные дают понимание структуры распределения: где классы могут располагаться и как данные группируются. Совместное использование: априорная вероятность подсказывает, какие классы более вероятны в целом, а структура $U$ уточняет, где должна проходить граница, чтобы согласовать эти вероятности с реальным расположением точек. В итоге мы получаем более точный классификатор, чем если бы полагались исключительно на априор или только на структуру $U$.

\bigskip

\noindent\textbf{Задача 3. Интерпретация XR через эмпирические распределения}

Пусть у нас есть многоклассовая логистическая регрессия с параметрами $w$ и небольшой набор размеченных данных $X^k$. Для каждого бинарного признака $b_j(x)$ по размеченной части мы можем оценить эмпирическое распределение классов $\hat{p}_j(y)$. Метод XR добавляет к исходному критерию $Q(w)$ дополнительное слагаемое:
\[
\gamma \sum_{j=1}^m \sum_{y \in Y} \hat{p}_j(y) \log p_j(y \mid w),
\]

Объясните, почему максимизация совокупной функции стремится «подтянуть» модельные вероятности $p_j(y \mid w)$ к эмпирическим оценкам $\hat{p}_j(y)$. В чём заключается смысл регуляризатора XR с точки зрения использования информации о неразмеченных данных?

\subsubsection*{Решение:} 
Регуляризатор стремится сделать так, чтобы предсказания по неразмеченным данным были согласованы с эмпирическими частотами классов по признакам, оцененными на размеченных данных. Это означает, что модель не просто настраивается по размеченным объектам напрямую, но и пытается воспроизводить выявленные «шаблоны» вероятностей классов, используя набор неразмеченных объектов для уточнения вероятностных оценок. 

С точки зрения дивергенции Кульбака-Лейблера (KL-дивергенции), это дополнение минимизирует расхождение между эмпирическими распределениями $\hat{p}_j(y)$ и модельными предсказаниями $p_j(y \mid w)$. KL-дивергенция измеряет, насколько распределение $p_j(y \mid w)$ плохо аппроксимирует эмпирическое распределение $\hat{p}_j(y)$, и штрафует модель за это несоответствие. Таким образом, минимизация KL-дивергенции приводит к «подтягиванию» вероятностей модели к эмпирическим данным.

Смысл регуляризатора XR заключается в том, чтобы использовать информацию о неразмеченных данных для уточнения вероятностных оценок, согласованных с эмпирическими закономерностями, обнаруженными в размеченной выборке. Это снижает риск переобучения, улучшает обобщающую способность модели и позволяет использовать априорные знания для улучшения её предсказаний.

\section*{K-means}
\title{Конспект семинара по теме K-means}


\subsection*{Основные понятия}
\textbf{Обучение без учителя:} анализ данных без меток, задача — выявить скрытые структуры.\\
\textbf{Кластеризация:} разделение объектов на группы (кластеры), где объекты внутри группы схожи.\\
\textbf{K-means:}
\begin{itemize}
    \item Делит данные на $K$ кластеров.
    \item Использует евклидово расстояние для расчета близости.
    \item Основные этапы:
    \begin{enumerate}
        \item Инициализация центроидов.
        \item Назначение объектов к ближайшим центроидам.
        \item Пересчет центроидов.
        \item Повторение до сходимости.
    \end{enumerate}
\end{itemize}

\subsection*{Построение данных}
\begin{itemize}
    \item Используется распределение Дирихле (\texttt{np.random.dirichlet}) с добавлением шума (\texttt{np.random.randn}).
    \item Генерируются два набора данных ($X_1$ и $X_2$), объединенные в $X$.
    \item Визуализация данных:
    \[
    \texttt{plt.plot(X[:, 0], X[:, 1], '.', color=colors[0])}
    \]
\end{itemize}

\subsection*{Пример работы K-means}
\textbf{Шаги эксперимента:}
\begin{enumerate}
    \item Инициализация модели:
    \[
    \texttt{model = KMeans(n\_clusters=n, random\_state=42)}
    \]
    \item Обучение модели:
    \[
    \texttt{model.fit(X)}
    \]
    \item Визуализация кластеров:
    \begin{itemize}
        \item Точки кластера:
        \[
        \texttt{plt.plot(X[model.labels\_ == i, 0], X[model.labels\_ == i, 1], '.', color=colors[i])}
        \]
        \item Центры кластеров:
        \[
        \texttt{plt.plot([model.cluster\_centers\_[i][0]], [model.cluster\_centers\_[i][1]], 'x', c=colors[i], markersize=20)}
        \]
    \end{itemize}
\end{enumerate}

\textbf{Результаты:}
\begin{itemize}
    \item Запуск алгоритма с разным числом кластеров ($n\_clusters = 2, 4, 8$).
    \item При увеличении числа кластеров разделение становится более детальным.
\end{itemize}

\subsection*{Итоги и обсуждение}
\textbf{Преимущества K-means:}
\begin{itemize}
    \item Простота и скорость.
    \item Эффективность при небольшом числе кластеров.
\end{itemize}
\textbf{Недостатки K-means:}
\begin{itemize}
    \item Зависимость от начальной инициализации.
    \item Чувствительность к шуму и выбросам.
\end{itemize}
\textbf{Применение:} маркетинг, медицина, анализ поведения пользователей и др.



\subsection*{Задачи}

\textbf{Задача 1:} \textit{Предположим, у вас есть данные:} 
\[
X = \left\{
\begin{array}{cc}
(1, 2), & (2, 3), \\
(6, 7), & (7, 8)
\end{array}
\right\}.
\]
\textit{Используя K-means, разделите эти данные на 2 кластера.}

\textbf{Решение:}  
Алгоритм начнется с случайных центроидов. После первого шага, кластеры могут быть следующими:
- Кластер 1: $(1, 2), (2, 3)$
- Кластер 2: $(6, 7), (7, 8)$

Итоговые центры кластеров:
- Центр кластера 1: $(1.5, 2.5)$
- Центр кластера 2: $(6.5, 7.5)$

---

\textbf{Задача 2:} \textit{Даны три точки: $(1, 1)$, $(2, 2)$ и $(6, 6)$. Используя K-means с $n=2$, определите, как они будут разделены на два кластера.}

\textbf{Решение:}  
- Инициализация центроидов: случайно выбираем $(1, 1)$ и $(6, 6)$.
- Первый шаг:
  - Точка $(1, 1)$ ближе к центроиду $(1, 1)$.
  - Точка $(2, 2)$ ближе к центроиду $(1, 1)$.
  - Точка $(6, 6)$ ближе к центроиду $(6, 6)$.
- После пересчета центроидов:
  - Центр кластера 1: $(1.5, 1.5)$
  - Центр кластера 2: $(6, 6)$
  
Таким образом, точки $(1, 1)$ и $(2, 2)$ будут в одном кластере, а точка $(6, 6)$ в другом.

---

\textbf{Задача 3:} \textit{Предположим, у вас есть 6 точек: $(1, 2)$, $(2, 3)$, $(3, 4)$, $(8, 9)$, $(9, 10)$, $(10, 11)$. Используя K-means с $n=2$, как будет происходить кластеризация?}

\textbf{Решение:}  
1. Инициализация центроидов: предположим, что начальные центры $(1, 2)$ и $(10, 11)$.
2. После первого шага:
   - Точки $(1, 2)$, $(2, 3)$, $(3, 4)$ ближе к центроиду $(1, 2)$.
   - Точки $(8, 9)$, $(9, 10)$, $(10, 11)$ ближе к центроиду $(10, 11)$.
3. Пересчитаем центроиды:
   - Центр кластера 1: $(2, 3)$
   - Центр кластера 2: $(9, 10)$

Таким образом, кластер 1 содержит точки $(1, 2)$, $(2, 3)$, $(3, 4)$, а кластер 2 — точки $(8, 9)$, $(9, 10)$, $(10, 11)$.

\section{Агломеративная иерархическая кластеризация Ланса-Уильямса}

Агломеративная иерархическая кластеризация — это метод, в котором кластеры последовательно объединяются в более крупные группы. В 1967 году Ланс и Уильямс предложили обобщенную формулу для пересчёта расстояний между кластерами при их объединении.

\subsection{Описание алгоритма}
\begin{enumerate}
    \item Инициализация: каждый объект образует свой собственный кластер $C_1 = \{\{x_1\}, \dots, \{x_\ell\}\}$.
    \item Вычисляются расстояния между всеми парами кластеров: 
    \[
    R_{\{x_i\}\{x_j\}} = \rho(x_i, x_j).
    \]
    \item На каждой итерации $t = 2, \dots, \ell$:
    \begin{itemize}
        \item Найти пару кластеров $(U, V)$ с минимальным расстоянием $R_{UV}$, \textbf{при условии, что в $U \cup V$ нет объектов с разными метками}.
        \item Слить их в один кластер $W = U \cup V$:
        \[
        C_t := C_{t-1} \cup \{W\} \setminus \{U, V\}.
        \]
        \item Для всех остальных кластеров $S \in C_t$ пересчитать расстояния $R_{WS}$ по формуле Ланса–Уильямса:
        \[
        R_{WS} := \alpha_U R_{US} + \alpha_V R_{VS} + \beta R_{UV} + \gamma |R_{US} - R_{VS}|,
        \]
        где $\alpha_U, \alpha_V, \beta, \gamma$ — параметры, определяющие конкретный случай алгоритма.
    \end{itemize}
\end{enumerate}


\subsection{Частные случаи формулы Ланса–Уильямса}
Формула Ланса–Уильямса обобщает несколько известных способов пересчёта расстояний.

\begin{enumerate}
    \item \textbf{Расстояние ближайшего соседа:}
    \[
    R^{б}_{WS} = \min_{w \in W, s \in S} \rho(w, s);
    \]
    параметры:
    \[
    \alpha_U = \alpha_V = \frac{1}{2}, \; \beta = 0, \; \gamma = -\frac{1}{2}.
    \]

    \item \textbf{Расстояние дальнего соседа:}
    \[
    R^{д}_{WS} = \max_{w \in W, s \in S} \rho(w, s);
    \]
    параметры:
    \[
    \alpha_U = \alpha_V = \frac{1}{2}, \; \beta = 0, \; \gamma = \frac{1}{2}.
    \]

    \item \textbf{Групповое среднее расстояние:}
    \[
    R^{г}_{WS} = \frac{1}{|W||S|} \sum_{w \in W} \sum_{s \in S} \rho(w, s);
    \]
    параметры:
    \[
    \alpha_U = \frac{|U|}{|W|}, \; \alpha_V = \frac{|V|}{|W|}, \; \beta = \gamma = 0.
    \]

    \item \textbf{Расстояние между центрами:}
    \[
    R^{ц}_{WS} = \rho^2 \left( \sum_{w \in W} \frac{w}{|W|}, \; \sum_{s \in S} \frac{s}{|S|} \right);
    \]
    параметры:
    \[
    \alpha_U = \frac{|U|}{|W|}, \; \alpha_V = \frac{|V|}{|W|}, \; \beta = -\alpha_U \alpha_V, \; \gamma = 0.
    \]

    \item \textbf{Расстояние Уорда:}
    \[
    R^{y}_{WS} = \frac{|S||W|}{|S| + |W|} \rho^2 \left( \sum_{w \in W} \frac{w}{|W|}, \; \sum_{s \in S} \frac{s}{|S|} \right);
    \]
    параметры:
    \[
    \alpha_U = \frac{|S| + |U|}{|S| + |W|}, \; \alpha_V = \frac{|S| + |V|}{|S| + |W|}, \; \beta = \frac{-|S|}{|S| + |W|}, \; \gamma = 0.
    \]
\end{enumerate}

\subsection{Проблема выбора}
Одной из задач в агломеративной кластеризации является выбор функции расстояния. Разные варианты расстояний по-разному обрабатывают данные и влияют на результат кластеризации. В зависимости от структуры данных, конкретная функция может быть более или менее подходящей.

\subsection{Рекомендации по выбору и числу кластеров}
\begin{itemize}
    \item Рекомендуется пользоваться расстоянием Уорда $R^{y}$.
    \item Обычно строят несколько вариантов кластеризации и выбирают лучший визуально по дендрограмме.
    \item Определение числа кластеров осуществляется по максимуму разности расстояний на соседних итерациях:
    \[
    \max |R_{t+1} - R_t|,
    \]
    где $C_t$ — результирующее множество кластеров.
\end{itemize}


\subsection*{Вопросы для самопроверки}
\begin{enumerate}
    \item В чём заключается основная идея формулы Ланса–Уильямса и как она используется для пересчёта расстояний между кластерами?
    \item Какие частные случаи формулы Ланса–Уильямса вы знаете и чем они отличаются друг от друга?
    \item Как определяется число кластеров в агломеративной кластеризации на основе дендрограммы и разностей расстояний?
\end{enumerate}

