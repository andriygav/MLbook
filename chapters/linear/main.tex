% !TeX spellcheck = ru_RU-Russian

\section{О регуляризации}

При решении задачи машинного обучения часто возникает проблема переобучения, при котором модель подстраивается под шум данных, что снижает ее обобщаю способность.
Один из методов борьбы с этим --- регуляризации, или же сокращение весов (англ.: weight decay). Данный метод добавляет штраф к функции потерь за сложность модели, в случае линейных моделей~--- штраф за большие веса коэффициентов. Регуляризация ограничивает пространство решений и делает модель более устойчивой к шуму, что увеличивает вероятность корректных предсказаний на новых данных. Пример, когда усложнение модели, путем добавления избыточных коэффициентов полиномиальной модели представлен на рис.~\ref{liner-reg-overfitting}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{chapters/linear/pics/reg-overfitting.png}
	\caption{Иллюстрация проблемы переобучения для решения линейной задачи}
	\label{linear-reg-overfitting}
\end{figure}

В разделе~\ref{linear-reg-l1l2} рассмотрены основные методы регуляризации, применяемые в линейных моделях. Раздел~\ref{linear-reg-prob} описывает вероятностную трактовку причин возникновения регуляризации. Завершается глава разделом~\ref{linear-reg-task}, который содержит три теоретических задачи по теме регрессии.

\subsection{Гауссовский и лапласовский регуляризаторы}
\label{linear-reg-l1l2}

Гауссовский и лапласовский регуляризаторы представляют собой две разные техники регуляризации, которые используются для управления сложностью моделей и предотвращения переобучения. Они основаны на различных подходах к штрафованию весов модели.

\subsubsection{Лапласовский регуляризатор (L1 регуляризатор)}

Лапласовский (L1) регуляризатор использует сумму модулей значений весов модели в качестве штрафа. Формально новую функцию потерь можно записать следующим образом:
$L1 = L_0 + \lambda \sum_{i=1}^{n} |w_i|$,
где $L_0$ --- исходная функция потерь, $|w_i|$ --- абсолютные значения весов модели, $\lambda$ --- коэффициент регуляризации.
\noindent
Преимущества:
\begin{itemize}
	\item Лапласовский регуляризатор может приводить к обнулению некоторых весов, что делает модель более интерпретируемой и позволяет выделять наиболее важные признаки.
	\item Он может быть особенно полезен в задачах с высокой размерностью, где много признаков могут быть неинформативными.
\end{itemize}
Недостатки:
\begin{itemize}
	\item Оптимизация с использованием L1 регуляризации может быть более сложной и требовать специальных алгоритмов (например, координатного спуска или методов, основанных на субградиенте).
\end{itemize}

\subsubsection{Гауссовский регуляризатор (L2 регуляризатор)}

Гауссовский (L2) регуляризатор использует штраф в виде суммы квадратов весов модели. Формально новую функцию потерь можно записать следующим образом:
$L2 = L_0 + \lambda \sum_{i=1}^{n} w_i^2$,
где $L_0$ — исходная функция потерь (например, среднеквадратичная ошибка для задачи регрессии), $w_i$ — веса модели, $\lambda$ — коэффициент регуляризации, который контролирует величину штрафа.
Преимущества:
\begin{itemize}
	\item Гауссовский регуляризатор помогает сгладить веса, что делает модель более устойчивой к шуму в данных.
	\item Он способствует распределению весов по всем признакам, уменьшая вероятность того, что некоторые признаки будут доминировать.
\end{itemize}
Недостатки:
\begin{itemize}
	\item Может не приводить к полному обнулению весов, поэтому не всегда приводит к интерпретируемым моделям.
\end{itemize}

\subsubsection {Сравнений L1 и L2 регуляризаторов}

Выбор между гауссовским и лапласовским регуляризаторами зависит от конкретной задачи и целей (сравнение см. в таблице~\ref{linear-reg-comp}). Если важна интерпретируемость модели и выделение значимых признаков, то стоит рассмотреть L1 регуляризацию. Если же цель — улучшить общее качество модели без сильного сокращения количества признаков, то L2 регуляризация может быть предпочтительнее. Это связано с тем, что в L2 регуляризации за счет возведения в квадрат значений весов вклад нулевого веса и просто малого веса неразличим на при наличии других выделенных признаков с весами порядка или более единицы. Таким образом, L2 регуляризация, в отличии от L1 не стремится обнулить коэффициенты, что снижает интерпретируемость модели. Однако квадратичная функция является гладкой, поэтому лучше поддается вычислительным методам оптимизации.

\begin{table}[ht]
	\caption{Сравнение L1 и L2 регуляризаторов}
	\label{linear-reg-comp}
	\begin{tabular}{l|l|l}
		Характеристика & Лапласовский (L1) & Гауссовский (L2) \\
		\hline
		Штраф & Сумма абсолютных значений весов & Сумма квадратов весов \\
		Эффект на веса & Обнуление (спарсность) & Сглаживание \\
		Интерпретируемость & Выше & Меньше \\
		Оптимизация & Сложнее & Легче
	\end{tabular}
\end{table}

В ситуациях используется комбинация обоих методов регуляризации. Для этого вводится дополнительный гиперпараметр $\alpha$~--- доля первой нормы в штрафе за вес. Получается так называемая эластичная сеть (англ.: elastic net). В таком случае:
$L = L_0 + \lambda [\alpha \sum_{i=1}^{n} |w_i| + (1 - \alpha) \sum_{i=1}^{n} w_i^2]$. Данный подход позволяет учесть особенности двух подходов, однако усложняет модель.

\subsection {Вероятностная интерпретация регуляризации}
\label{linear-reg-prob}

В первом рассмотрении регуляризацию можно рассматриваться как введение априорной информации о параметрах модели. Рассмотрим вводимые предположения:
\begin{itemize}
	\item в случае L1 регуляризации мы предполагаем, что многие веса могут быть равны нулю, это соответствует идее о том, что истинная модель простая и присутствуют лишние признаки;
	\item в случае L2~--- веса распределены вблизи общего малого среднего значения, это отражает предположение о том, что все признаки вносят сопоставимый вклад в предсказание.
\end{itemize}
\noindent
Описанным выше предположениям о весах соответствуют экспоненциальное и нормальное распределения (см. рис.~\ref{linear-reg-distribution}). Рассмотрим их влияние на штраф и функцию потерь.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{chapters/linear/pics/reg-distributions.png}
	\caption{Сравнение экспоненциального и нормального распределений}
	\label{linear-reg-distribution}
\end{figure}

\subsubsection {L1 регуляризация}

предполагает, что веса $w_j$ распределены по лапласовскому закону (или двойному экспоненциальному распределению), $w_j - Laplace(0, b)$.

\subsubsection{L2 регуляризация}

предполагает, что веса модели $w_j$ имеют нормальное распределение с нулевым средним и некоторой дисперсией $\sigma^2$. Это можно записать как $w_j - N(0, \sigma^2)$.

\subsection {Задачи}
\label{linear-reg-task}


\subsubsection{Вопрос 1}
\noindent Как изменение коэффициента $\lambda$ влияет на величину весов $w_j$?

\textbf{L1 регуляризация}

\noindent При увеличении $\lambda$ происходит обнулению некоторых весов $w_j$. Это приводит к тому, что с увеличением $\lambda$ количество ненулевых весов уменьшается, что может помочь в отборе признаков и упрощении модели.

\textbf{L2 регуляризация}

\noindent При увеличении $\lambda$ происходит увеличение штрафа за большие значения весов. Это приводит к уменьшению величины весов $w_j$ (все веса стремятся к нулю), что помогает избежать переобучения. В случае $\lambda$ = 0 модель не имеет регуляризации, и веса могут принимать любые значения, что может привести к переобучению.

\subsubsection{Вопрос 2}
\noindent Какова геометрическая интерпретация регуляризации в пространстве весов?

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{chapters/linear/pics/reg-geom.png}
	\caption{Геометрическая интерпретация регуляризации в пространстве весов}
	\label{linear-reg-geom}
\end{figure}

\textbf{L1 регуляризация}

\noindent Геометрически L1 регуляризация создает ромбовидные (или параллелепипедные) области в пространстве весов. Оптимальные веса находятся на вершинах этих ромбов, что приводит к обнулению некоторых весов и, следовательно, к отбору признаков.

$L1(w_1,w_2) = const <=> |w_1|+|w_2| = const$

\textbf{L2 регуляризация}

\noindent Геометрически L2 регуляризация создает сферу (или гиперсферу) в пространстве весов, внутри которой минимизируется функция потерь. Это означает, что оптимальные веса будут находиться на поверхности этой сферы, что приводит к сглаживанию и уменьшению значений весов.

$L2(w_1,w_2) = const <=> w_1^2+w_2^2 = const$

\subsubsection{Вопрос 3}
\noindent Какие особенности признаков компенсируют регуляризации?

\textbf{L1 регуляризация}

\noindent Используя L1 регуляризацию, можно обнулить веса для менее значимых признаков. После обучения модели можно проанализировать ненулевые веса и оставить только те признаки, которые имеют значимые коэффициенты, тем самым осуществляя отбор признаков.

\textbf{L2 регуляризация}

\noindent L2 регуляризация помогает сгладить веса при наличии мультиколлинеарности, уменьшая их величину и тем самым снижая влияние коррелирующих признаков. Это позволяет избежать чрезмерного увеличения весов для сильно коррелирующих признаков.

\section*{Основная идея}

Градиентные методы --- это широкий класс оптимизационных алгоритмов, используемых не только в машинном обучении. Здесь градиентный подход будет рассмотрен в качестве способа подбора вектора синаптических весов \( w \) в линейном классификаторе. Пусть \( y^*: \, X \to Y \) — целевая зависимость, известная только на объектах обучающей выборки: \( X^l = (x_i, y_i)_{i=1}^l \), где \( y_i = y^*(x_i) \).

Найдём алгоритм \( a(x, w) \), аппроксимирующий зависимость \( y^* \). В случае линейного классификатора искомый алгоритм имеет вид:
$$ a(x, w) = \varphi\left(\sum_{j=1}^n w_j x^j - w_0\right), $$
где \( \varphi(z) \) играет роль функции активации (в простейшем случае можно положить \( \varphi(z) = \operatorname{sign}(z) \)).

Согласно принципу минимизации эмпирического риска, для этого достаточно решить оптимизационную задачу:
$$ Q(w) = \sum_{i=1}^l L(a(x_i, w), y_i) \to \min_w, $$
где \( L(a, y) \) — заданная функция потерь.

Для минимизации применим метод градиентного спуска (gradient descent). Это пошаговый алгоритм, на каждой итерации которого вектор \( w \) изменяется в направлении наибольшего убывания функционала \( Q \) (то есть в направлении антиградиента):
$$ w := w - \eta \nabla Q(w), $$
где \( \eta \) — положительный параметр, называемый темпом обучения (learning rate).

\subsection*{Основные подходы к реализации градиентного спуска}
\begin{enumerate}
    \item \textbf{Пакетный (batch):} на каждой итерации обучающая выборка просматривается целиком, и только после этого изменяется \( w \). Этот подход требует больших вычислительных затрат.
    \item \textbf{Стохастический (stochastic/online):} на каждой итерации из обучающей выборки случайным образом выбирается один объект. Таким образом, вектор \( w \) настраивается на каждый вновь выбираемый объект.
\end{enumerate}

\subsection*{Алгоритм Stochastic Gradient (SG)}
\textbf{Вход:}
\begin{itemize}
    \item \( X^l \) --- обучающая выборка;
    \item \( \eta \) --- темп обучения;
    \item \( \lambda \) --- параметр сглаживания функционала \( Q \).
\end{itemize}

\textbf{Выход:} Вектор весов \( w \)

\textbf{Тело алгоритма:}
\begin{enumerate}
    \item Инициализировать веса \( w_j \), \( j = 0, \dots, n \);
    \item Инициализировать текущую оценку функционала: \( Q := \sum_{i=1}^l L(a(x_i, w), y_i) \);
    \item Повторять:
    \begin{enumerate}
        \item выбрать объект \( x_i \) из \( X^l \) (например, случайным образом);
        \item вычислить выходное значение алгоритма \( a(x_i, w) \) и ошибку: \( \varepsilon_i := L(a(x_i, w), y_i) \);
        \item сделать шаг градиентного спуска:
        $$ w := w - \eta L_a^\prime (a(x_i, w), y_i) \varphi^\prime (\langle w, x_i \rangle)x_i; $$
        \item оценить значение функционала:
        $$ Q := (1 - \lambda)Q + \lambda\varepsilon_i; $$
    \end{enumerate}
    пока значение \( Q \) не стабилизируется и/или веса \( w \) не перестанут изменяться.
\end{enumerate}

\subsection*{Порядок выбора объектов}
В случае стохастического градиентного спуска объекты следует выбирать случайным образом, однако существуют эвристики, направленные на улучшение сходимости:
\begin{itemize}
    \item Перемешивание (shuffling): случайно выбирать объекты, попеременно из разных классов. Идея в том, что объекты из разных классов менее "похожи", чем объекты одного класса, поэтому вектор \( w \) будет сильнее изменяться.
    \item Можно выбирать объект с вероятностью, обратно пропорциональной величине ошибки на объекте. Следует учитывать, что такая эвристика делает метод чувствительным к шумам.
\end{itemize}

\subsection*{Способы инициализации весов}
\begin{enumerate}
    \item Инициализация вектора \( w \) нулями.
    \item \( w_j := \operatorname{rand}\left(-\frac{1}{n}, \frac{1}{n}\right) \), где \( n \) — размерность пространства признаков.
    \item Решение исходной оптимизационной задачи при условии статистически независимых признаков, линейной функции активации (\( \varphi \)) и квадратичной функции потерь (\( L \)):
    $$ w_j := \frac{\langle y, f_j \rangle}{\langle f_j, f_j \rangle}. $$
\end{enumerate}

\subsection*{Параметр сглаживания}
Для оценки функционала \( Q \) на каждой итерации используется его приближённое значение по методу экспоненциального сглаживания, откуда \( \lambda \) лучше брать порядка \( \frac{1}{l} \).

\subsection*{Известные частные случаи алгоритма}
Метод SG (при соответствующем выборе функций активации и потерь) является обобщением следующих эвристик подбора \( w \) и алгоритмов классификации:
\begin{itemize}
    \item Адаптивный линейный элемент (Adalines);
    \item Правило Хэбба;
    \item Алгоритм \( k \)-средних (K-Means);
    \item Learning Vector Quantization (LVQ).
\end{itemize}

\subsection*{Преимущества SG}
\begin{itemize}
    \item Метод подходит для динамического (online) обучения.
    \item Алгоритм способен обучаться на избыточно больших выборках.
    \item Различные стратегии обучения позволяют адаптировать алгоритм для задач с избыточной или небольшой выборкой.
\end{itemize}

\subsection*{Недостатки SG и способы их устранения}
\begin{itemize}
    \item Возможны проблемы сходимости. Для борьбы с этим применяют технику встряхивания коэффициентов.
    \item При высокой размерности пространства признаков \( n \) и/или малой длине выборки \( l \) возможно переобучение. Для борьбы с этим применяют метод сокращения весов:
    $$ Q_{\tau}(w) = Q(w) + \frac{\tau}{2}||w||^2. $$
    Тогда правило обновления весов принимает вид:
    $$ w := w(1 - \eta \tau) - \eta \nabla Q(w). $$
    \item При больших значениях \( \langle w, x_i \rangle \) значение \( \varphi^\prime \) может становиться близким к нулю. Для предотвращения этого состояния вводят нормализацию признаков:
    $$ x^j := \frac{x^j - x_{\min}^j}{x_{\max}^j - x_{\min}^j}, \quad j = 1, \dots, n, $$
    где \( x_{\min}^j, x_{\max}^j \) — минимальное и максимальное значения признака \( j \)-го признака. Регуляризация, такая как weight decay, также помогает избежать "паралича".
\end{itemize}

\subsection*{Сходимость алгоритма}
Сходимость гарантируется при выпуклой функции \( Q(w) \) и выполнении следующих условий:
$$ \eta_t \xrightarrow{t \to \infty} 0, \quad \sum_{t=1}^{\infty} \eta_t = \infty, \quad \sum_{t=1}^{\infty} \eta_t^2 < \infty. $$
Например, можно положить \( \eta_t = \frac{\eta_0}{t} \), хотя на практике это не всегда удачно.

\section*{Задачи}

\subsection*{Задача 1: Доказать сходимость алгоритма при условиях выше}

\textbf{Решение:}

\begin{enumerate}
    \item \textbf{Выпуклость функции:} Поскольку \( Q(w) \) выпукла, мы можем использовать свойства выпуклых функций. Для любого \( w \) и \( w^* \) (где \( w^* \) — точка минимума функции \( Q \)) выполняется неравенство:
    $$ Q(w) \geq Q(w^*) + \nabla Q(w^*)^T (w - w^*). $$

    \item \textbf{Итерация метода стохастического градиента:} Обновление весов в SGD задается следующим образом:
    $$ w_{t+1} = w_t - \eta_t \nabla Q(w_t; \xi_t), $$
    где \( \xi_t \) — случайная переменная, представляющая выборку данных на итерации \( t \).

    \item \textbf{Анализ изменения функции:} Мы можем оценить изменение функции \( Q \) на каждой итерации:
    $$ Q(w_{t+1}) \leq Q(w_t) + \nabla Q(w_t; \xi_t)^T (w_{t+1} - w_t) + \frac{L}{2} \|w_{t+1} - w_t\|^2, $$
    где \( L \) — константа Липшица для градиента \( \nabla Q \).

    Подставляя обновление:
    $$ Q(w_{t+1}) \leq Q(w_t) - \eta_t \nabla Q(w_t; \xi_t)^T \nabla Q(w_t) + \frac{L}{2} \eta_t^2 \|\nabla Q(w_t; \xi_t)\|^2. $$

    \item \textbf{Суммирование изменений:} Суммируя по всем итерациям, мы получаем:
    $$ \sum_{t=1}^{T} Q(w_{t+1}) - Q(w_1) \leq -\sum_{t=1}^{T} \eta_t \nabla Q(w_t; \xi_t)^T \nabla Q(w_t) + \sum_{t=1}^{T} \frac{L}{2} \eta_t^2 \|\nabla Q(w_t; \xi_t)\|^2. $$

    \item \textbf{Использование условий:} Условия \( \sum_{t=1}^{\infty} \eta_t = \infty \) и \( \sum_{t=1}^{\infty} \eta_t^2 < \infty \) позволяют нам сделать вывод о том, что:
    \begin{itemize}
        \item Сумма шагов обучения стремится к бесконечности, что означает, что веса \( w_t \) будут продолжать обновляться.
        \item Сумма квадратов шагов обучения конечна, что позволяет контролировать величину изменений на каждой итерации.
    \end{itemize}

    \item \textbf{Сходимость к минимуму:} В результате, при условии, что \( Q(w) \) выпукла, и учитывая условия на шаги обучения, мы можем утверждать, что последовательность \( w_t \) будет сходиться к некоторой точке \( w^* \), которая является минимумом функции \( Q(w) \).
\end{enumerate}

Таким образом, метод стохастического градиента сходится к минимуму выпуклой функции \( Q(w) \) при выполнении заданных условий.

\subsection*{Задача 2: Оценка вариации градиента}

\textbf{Условие:} Пусть \( \xi_1, \xi_2, \ldots, \xi_n \) — независимые и одинаково распределённые (i.i.d.) случайные переменные, представляющие собой выборки из обучающего набора. Рассмотрим стохастический градиент \( \nabla L(\theta; \xi_t) \).

\textbf{Задача:} Доказать, что математическое ожидание стохастического градиента совпадает с истинным градиентом функции потерь:
\[
\mathbb{E}[\nabla L(\theta; \xi_t)] = \nabla L(\theta)
\]
и оценить дисперсию \( \operatorname{Var}(\nabla L(\theta; \xi_t)) \) в зависимости от размера выборки \( n \).

\subsection*{Доказательство}

\begin{enumerate}
    \item \textbf{Определение стохастического градиента:} Пусть \( L(\theta) \) — функция потерь, зависящая от параметров \( \theta \) и от выборки \( \xi \). Мы можем записать функцию потерь как среднее значение по всем данным:
    $$ L(\theta) = \frac{1}{n} \sum_{i=1}^{n} l(\theta; x_i, y_i), $$
    где \( l(\theta; x_i, y_i) \) — функция потерь для примера \( (x_i, y_i) \).

    \item \textbf{Истинный градиент:} Тогда истинный градиент функции потерь можно выразить как:
    $$ \nabla L(\theta) = \frac{1}{n} \sum_{i=1}^{n} \nabla l(\theta; x_i, y_i). $$

    \item \textbf{Математическое ожидание стохастического градиента:} Теперь рассмотрим стохастический градиент:
    $$ \nabla L(\theta; \xi_t) = \nabla l(\theta; \xi_t), $$
    где \( \xi_t \) — случайная выборка. Поскольку \( \xi_t \) выбирается из одного из \( n \) примеров, математическое ожидание стохастического градиента будет:
    \[
    \mathbb{E}[\nabla L(\theta; \xi_t)] = \mathbb{E}[\nabla l(\theta; \xi_t)] = \frac{1}{n} \sum_{i=1}^{n} \nabla l(\theta; x_i, y_i) = \nabla L(\theta).
    \]
    Таким образом, мы доказали, что:
    \[
    \mathbb{E}[\nabla L(\theta; \xi_t)] = \nabla L(\theta).
    \]

    \item \textbf{Оценка дисперсии:} Теперь найдём дисперсию стохастического градиента:
    \[
    \operatorname{Var}(\nabla L(\theta; \xi_t)) = \mathbb{E}[(\nabla L(\theta; \xi_t) - \mathbb{E}[\nabla L(\theta; \xi_t)])^2].
    \]
    Подставим выражение для стохастического градиента:
    \[
    \operatorname{Var}(\nabla L(\theta; \xi_t)) = \mathbb{E}[(\nabla l(\theta; \xi_t) - \nabla L(\theta))^2].
    \]
    Поскольку \( \xi_t \) является случайным выбором, мы можем использовать свойства дисперсии. Для \( n \) независимых и одинаково распределённых (i.i.d.) выборок дисперсия стохастического градиента будет уменьшаться с увеличением размера выборки:
    $$ \operatorname{Var}(\nabla L(\theta; \xi_t)) = \frac{1}{n} \operatorname{Var}(l(\theta; x, y)), $$
    где \( (x, y) \) — случайная выборка из обучающего набора. Это означает, что дисперсия стохастического градиента уменьшается с увеличением размера выборки \( n \).
\end{enumerate}

\subsection*{Задача 3: Регуляризация и стохастический градиент}

\subsection*{Условие}
Рассмотрим функцию потерь с L2-регуляризацией:
$$ L(\theta) = \frac{1}{n} \sum_{i=1}^{n} l(\theta; x_i, y_i) + \frac{\lambda}{2} \|\theta\|^2 $$
где \( l(\theta; x_i, y_i) \) — функция потерь для примера \( (x_i, y_i) \), а \( \lambda \) — коэффициент регуляризации.

\subsection*{Задача}
Обосновать, как регуляризация влияет на сходимость метода стохастического градиента, и показать, что использование регуляризации может помочь избежать переобучения, уменьшая значение функции потерь на валидационном наборе.

\subsection*{Влияние регуляризации на сходимость метода стохастического градиента}
\begin{enumerate}
    \item \textbf{Сглаживание функции потерь:}
    \begin{itemize}
        \item Добавление L2-регуляризации к функции потерь делает её более гладкой и выпуклой. Это связано с тем, что регуляризационный член \( \frac{\lambda}{2} \|\theta\|^2 \) добавляет "наказание" за большие значения параметров, что предотвращает резкие изменения градиента.
        \item Гладкость функции потерь способствует более стабильному обновлению параметров при использовании стохастического градиента. Это означает, что обновления параметров будут более предсказуемыми и менее подвержены шуму, что улучшает сходимость алгоритма.
    \end{itemize}

    \item \textbf{Уменьшение переобучения:}
    \begin{itemize}
        \item Регуляризация способствует уменьшению значений параметров модели, что, в свою очередь, снижает сложность модели. Это позволяет избежать переобучения, когда модель слишком точно подстраивается под тренировочные данные, включая шум.
        \item В результате, при использовании регуляризации, модель будет лучше обобщаться на новых данных, что выражается в меньшем значении функции потерь на валидационном наборе.
    \end{itemize}
\end{enumerate}

\subsection*{Доказательство эффекта регуляризации на валидационном наборе}
\begin{enumerate}
    \item \textbf{Функция потерь на валидационном наборе:}
    \begin{itemize}
        \item Пусть \( L_{val}(\theta) \) — функция потерь на валидационном наборе. При использовании регуляризации, мы можем записать:
        $$ L_{val}(\theta) = \frac{1}{m} \sum_{j=1}^{m} l(\theta; x_j, y_j) + \frac{\lambda}{2} \|\theta\|^2 $$
        где \( m \) — количество примеров в валидационном наборе.
    \end{itemize}

    \item \textbf{Сравнение значений функции потерь:}
    \begin{itemize}
        \item Без регуляризации, модель может иметь высокую функцию потерь на валидационном наборе из-за переобучения. При добавлении L2-регуляризации, даже если функция потерь на тренировочном наборе остаётся низкой, регуляризация помогает поддерживать значение функции потерь на валидационном наборе на более низком уровне.
    \end{itemize}

    \item \textbf{Кросс-валидация для выбора \( \lambda \):}
    \begin{itemize}
        \item Оптимальное значение \( \lambda \) можно выбрать с помощью кросс-валидации. Это позволяет находить компромисс между сложностью модели и её обобщающей способностью, что в конечном итоге приводит к меньшему значению функции потерь на валидационном наборе.
    \end{itemize}
\end{enumerate}

\subsection*{Заключение по задаче 3}
Регуляризация, особенно L2-регуляризация, играет ключевую роль в улучшении сходимости метода стохастического градиента и в предотвращении переобучения модели. Она помогает сделать функцию потерь более гладкой и выпуклой, что способствует стабильности обновлений параметров. В результате, использование регуляризации приводит к лучшему обобщению модели и снижению значения функции потерь на валидационном наборе, что является важным аспектом при разработке надёжных моделей в машинном обучении.

\section*{Линейный дискриминантный анализ (LDA)}

Линейный дискриминантный анализ (LDA) — это статистический метод для решения задач классификации, который используется для поиска линейных комбинаций признаков, наиболее эффективно разделяющих два или более классов. Основной задачей LDA является минимизация внутриклассовой дисперсии и максимизация межклассовой дисперсии, что позволяет лучше различать классы на основе их характеристик.

\subsection*{Предположения LDA}

LDA предполагает следующие условия для классов данных:
\begin{enumerate}
    \item \textbf{Нормальность распределений.} Признаки \( x \in \mathbb{R}^m \) для каждого класса \( C_k \) распределены нормально с параметрами: средним вектором \( \mu_k \in \mathbb{R}^m \) и ковариационной матрицей \( \Sigma_k \in \mathbb{R}^{m \times m} \).
    \item \textbf{Одинаковые ковариационные матрицы.} Все классы имеют одинаковую ковариационную матрицу \( \Sigma \), что значительно упрощает задачу классификации, так как для построения линейной границы между классами используется одна и та же матрица ковариаций.
\end{enumerate}

Согласно этим предположениям, распределение признаков в каждом классе можно выразить через многомерное нормальное распределение:
\[
P(x | C_k) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (x - \mu_k)^T \Sigma^{-1} (x - \mu_k) \right),
\]
где \( \mu_k \) — средний вектор признаков для класса \( C_k \), а \( \Sigma \) — ковариационная матрица, одинаковая для всех классов.

\subsection*{Задача LDA}

Цель LDA заключается в нахождении линейного классификатора, который разделяет классы с минимальной ошибкой. Для этого LDA ищет линейную функцию от признаков \( x \) вида:
\[
\delta(x) = w^T x + b,
\]
где \( w \) — вектор весов, \( b \) — смещение. Классы разделяются гиперплоскостью, заданной уравнением:
\[
w^T x + b = 0.
\]

Классификация основывается на выборе того класса, для которого значение \( \delta(x) \) наибольшее:
\[
\hat{y} = \text{sign}(w^T x + b).
\]

\subsection*{Вывод классификатора LDA}

Для решения задачи классификации методом LDA необходимо максимизировать правдоподобие для наблюдаемых данных, предполагая, что каждый класс имеет нормальное распределение с одинаковыми ковариационными матрицами. Рассмотрим два класса \( C_1 \) и \( C_2 \). Обозначим средние векторы классов как \( \mu_1 \) и \( \mu_2 \), а ковариационную матрицу как \( \Sigma \).

В соответствии с теоремой Байеса, для каждого класса вероятность \( P(C_k | x) \) вычисляется как:
\[
P(C_k | x) = \frac{P(x | C_k) P(C_k)}{P(x)}.
\]
Для того чтобы классифицировать объект \( x \), необходимо выбрать класс с наибольшей апостериорной вероятностью. Так как \( P(x) \) не зависит от класса, задача сводится к сравнению правдоподобий:
\[
P(C_1 | x) > P(C_2 | x) \quad \text{или} \quad \log P(C_1 | x) > \log P(C_2 | x).
\]

Подставив выражения для \( P(x | C_1) \) и \( P(x | C_2) \), получаем:
\[
- \frac{1}{2} (x - \mu_1)^T \Sigma^{-1} (x - \mu_1) + \log P(C_1) > - \frac{1}{2} (x - \mu_2)^T \Sigma^{-1} (x - \mu_2) + \log P(C_2).
\]

Упростив это выражение, мы приходим к линейному решению:
\[
w^T x + b = 0,
\]
где
\[
w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}.
\]

Таким образом, линейное правило классификации LDA основывается на разности средних \( \mu_1 \) и \( \mu_2 \), взвешенных инвертированной ковариационной матрицей \( \Sigma^{-1} \).

\subsection*{Оптимизация LDA}

Задача оптимизации LDA заключается в том, чтобы найти параметры классификатора, минимизируя ошибку классификации. Это достигается путём минимизации внутриклассовой дисперсии и максимизации межклассовой дисперсии. Внутриклассовая дисперсия характеризует разброс объектов внутри одного класса, а межклассовая дисперсия — разброс между классами. В результате, LDA позволяет найти оптимальную гиперплоскость, которая максимизирует различие между классами.

\subsection*{Основные шаги алгоритма LDA}
\begin{enumerate}
    \item Рассчитываем среднее для каждого класса \( \mu_k \) и ковариационную матрицу для всего набора данных \( \Sigma \).
    \item Вычисляем вектор весов \( w = \Sigma^{-1} (\mu_1 - \mu_2) \) и смещение \( b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)} \).
    \item Классифицируем объект \( x \), вычисляя \( w^T x + b \) и присваивая метку класса, соответствующую наибольшему значению.
\end{enumerate}

\section*{Задача 1: Основное правило классификации}

Дано два класса данных \( C_1 \) и \( C_2 \), каждый из которых представлен наборами векторов признаков \( X_1, X_2 \in \mathbb{R}^m \). Пусть векторы признаков для каждого класса распределены нормально с одинаковыми ковариационными матрицами: \( \Sigma_1 = \Sigma_2 = \Sigma \in \mathbb{R}^{m \times m} \) и средними \( \mu_1 \) и \( \mu_2 \).

\begin{enumerate}
    \item Используя принцип максимизации правдоподобия, выведите линейное правило классификации в LDA для двух классов \( C_1 \) и \( C_2 \).
    \item Докажите, что это правило эквивалентно выбору гиперплоскости, которая разделяет два класса, используя линейную комбинацию признаков. Определите, как вычисляется граница между классами.
\end{enumerate}

\subsection*{Решение:}

1. Для нахождения линейного классификатора мы предполагаем, что признаки \( x \) для каждого класса следуют нормальному распределению с различными средними \( \mu_1, \mu_2 \), но одинаковыми ковариационными матрицами \( \Sigma \). Согласно методу максимизации правдоподобия, логарифм правдоподобия для каждого класса выглядит следующим образом:

   \[
   \log P(C_k | x) = -\frac{1}{2} \log |\Sigma| - \frac{1}{2} (x - \mu_k)^T \Sigma^{-1} (x - \mu_k) + \log P(C_k)
   \]

   Для классификации выбираем класс с максимальным правдоподобием, что эквивалентно выбору гиперплоскости, которая разделяет два класса. После упрощений получаем линейное правило классификации:

   \[
   \delta(x) = w^T x + b \quad \text{где} \quad w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}
   \]

   Гиперплоскость, разделяющая классы, определяется по линейному выражению \( w^T x + b = 0 \).

2. Линейное правило классификации \( \delta(x) \) позволяет разделить классы с помощью гиперплоскости, где весовой вектор \( w \) пропорционален разности средних \( \mu_1 - \mu_2 \), а смещение \( b \) зависит от ковариационной матрицы и вероятностей классов. Это утверждение доказывается тем, что линейный классификатор LDA минимизирует ошибку классификации для нормальных распределений с одинаковыми ковариациями.

\section*{Задача 2: Оптимизация классификатора}

Дано два класса данных \( C_1 \) и \( C_2 \), каждый из которых имеет нормальное распределение признаков с одинаковыми ковариационными матрицами \( \Sigma \), но с различными средними значениями \( \mu_1 \) и \( \mu_2 \).

\begin{enumerate}
    \item Используя предположения о нормальности распределений и одинаковости ковариационных матриц, выведите общее правило для классификатора LDA для разделения классов \( C_1 \) и \( C_2 \).
    \item Покажите, что гиперплоскость, разделяющая классы, определяется разностью средних \( \mu_1 - \mu_2 \) и инвертированной ковариационной матрицей \( \Sigma^{-1} \). Докажите, что правило классификации LDA можно записать как линейную функцию от признаков.
\end{enumerate}

\subsection*{Решение:}

1. Используя предположения о нормальности распределений и одинаковости ковариационных матриц, максимизируем правдоподобие:

   \[
   P(x | C_1) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left(-\frac{1}{2} (x - \mu_1)^T \Sigma^{-1} (x - \mu_1)\right)
   \]
   \[
   P(x | C_2) = \frac{1}{(2\pi)^{m/2} |\Sigma|^{1/2}} \exp\left(-\frac{1}{2} (x - \mu_2)^T \Sigma^{-1} (x - \mu_2)\right)
   \]

   Для классификации, принимаем решение на основе сравнения логарифмов правдоподобий:

   \[
   \log P(C_1 | x) - \log P(C_2 | x)
   \]

   Упрощая выражения, получаем линейное правило классификации:

   \[
   w^T x + b = 0 \quad \text{где} \quad w = \Sigma^{-1} (\mu_1 - \mu_2), \quad b = -\frac{1}{2} (\mu_1^T \Sigma^{-1} \mu_1 - \mu_2^T \Sigma^{-1} \mu_2) + \log \frac{P(C_1)}{P(C_2)}
   \]

2. Гиперплоскость, разделяющая два класса, имеет уравнение \( w^T x + b = 0 \), где \( w \) пропорционален разности средних \( \mu_1 - \mu_2 \), а \( b \) зависит от ковариационной матрицы и вероятностей классов. Это доказательство основано на том, что для нормальных распределений с одинаковыми ковариационными матрицами оптимальное решение для классификации представляет собой линейную функцию от признаков.

\section*{Задача 3: Оценка ошибки классификации}

Предположим, что у нас есть линейный классификатор, полученный методом LDA, который разделяет два класса \( C_1 \) и \( C_2 \). Пусть обучающий набор данных состоит из \( n \) объектов: \( \{(x_i, y_i)\} \), где \( x_i \in \mathbb{R}^m \), а \( y_i \in \{-1, 1\} \) — метки классов. Классификатор работает по правилу: если \( w^T x + b \geq 0 \), то класс \( C_1 \), иначе класс \( C_2 \).

\begin{enumerate}
    \item Докажите, что ошибка классификации на обучающих данных для классификатора, построенного методом LDA, может быть выражена как сумма индикаторов неверной классификации для каждого примера.
    \item Для случая, когда классы разделены линейной гиперплоскостью, выведите верхнюю границу ошибки классификации с использованием теоремы о обобщающей способности линейных классификаторов.
\end{enumerate}

\subsection*{Решение:}

1. Ошибка классификации на обучающих данных для классификатора \( h(x) = \text{sign}(w^T x + b) \) выражается как сумма индикаторов неверной классификации:

   \[
   \text{Ошибка} = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}(y_i \neq \text{sign}(w^T x_i + b))
   \]

   где \( \mathbb{I}(\cdot) \) — индикатор неверной классификации.

2. Для оценки ошибки на тестовых данных используется теорема о обобщающей способности, которая дает верхнюю границу ошибки классификации через максимальное расстояние от гиперплоскости до ближайших точек обучающей выборки. Для линейных классификаторов верхняя граница ошибки может быть выражена как:

   \[
   \text{Ошибка} \leq \frac{1}{\sqrt{n}} \cdot \left( \max_{i} \| x_i \| \right)
   \]

   Эта граница зависит от структуры обучающей выборки и обеспечивает оценку ошибки классификатора на новых данных.
   

\newpage

\section{Метод наименьших квадратов (МНК) в общем случае}

\subsection{Про линейную регрессию и МНК}

Линейная регрессия — это метод анализа данных, который используется для определения линейной зависимости между зависимой переменной \(y\) и одной или несколькими независимыми переменными \(x_1, x_2, \dots, x_n\). Цель метода заключается в построении модели, которая минимизирует ошибку предсказания.

Метод наименьших квадратов (МНК) — это наиболее распространённый способ нахождения коэффициентов линейной регрессии. Он минимизирует сумму квадратов отклонений предсказанных значений от наблюдаемых. Таким образом, МНК позволяет определить такие коэффициенты \( \beta_0, \beta_1, \dots, \beta_n \), которые обеспечивают наилучшее соответствие модели данным.

\textbf{Основная идея МНК:} минимизация ошибки предсказания, заданной формулой:
\[
Q(\beta) = \sum_{i=1}^{N} (y_i - \hat{y_i})^2,
\]
где \(y_i\) — наблюдаемые значения, а \( \hat{y_i} \) — предсказанные моделью значения.

\subsection{МНК в общем случае}

\textbf{\textit{Определение:}}
В общем случае задача линейной регрессии может быть представлена в матричной форме:
\[
\mathbf{y} = X \beta + \epsilon,
\]
где:
- \(y\) — вектор целевых значений (\(N \times 1\)), \\
- \(X\) — матрица признаков (\(N \times p\)), \\
- \(\beta\) — вектор коэффициентов модели (\(p \times 1\)), \\
- \(\epsilon\) — вектор ошибок (\(N \times 1\)).

Решение задачи МНК определяется как:
\[
\hat{\beta} = (X^T X)^{-1} X^T \mathbf{y}.
\]

\textbf{\textit{Интерпретация:}}
Этот результат минимизирует сумму квадратов остатков \(\epsilon = \mathbf{y} - X\beta\). В случае, если матрица \(X^T X\) вырожденная, решение может быть некорректным или недоступным, что требует применения регуляризации.

\subsection{Проблемы и ограничения МНК}

Несмотря на простоту и эффективность, метод МНК имеет ограничения:

\begin{enumerate}

    \item \textbf{Мультиколлинеарность}
		\begin{itemize}
			\item \textbf{Определение:} мультиколлинеарность возникает, когда между независимыми переменными в матрице признаков X существует сильная линейная зависимость;
			\item \textbf{Почему это проблема:} при мультиколлинеарности матрица \(X^T X\) становится плохо обусловленной (или даже вырожденной), что затрудняет нахождение её обратной матрицы. Это может привести к неустойчивым решениям, при которых малые изменения в данных существенно изменяют значения коэффициентов.
		\end{itemize}

	\item \textbf{Чувствительность к выбросам}
		\begin{itemize}
			\item \textbf{Определение:} МНК минимизирует сумму квадратов ошибок, что делает его очень чувствительным к выбросам (аномальным точкам);
			\item \textbf{Почему это проблема:} выбросы имеют большое влияние на значение целевой функции \(Q(\beta)\), что может привести к сильному смещению коэффициентов регрессии.
		\end{itemize}

	\item \textbf{Нарушение предположений:} МНК предполагает линейность модели, гомоскедастичность (постоянную дисперсию ошибок) и отсутствие автокорреляции.

	\item \textbf{Высокая вычислительная сложность}
		\begin{itemize}
			\item \textbf{Определение:} МНК требует вычисления матрицы \(X^T X\) и её обратной, что имеет временную сложность \(O(Np^2+p^3)O(Np^2+p^3)\), где N — количество наблюдений, p — количество признаков;
			\item \textbf{Почему это проблема:} для больших наборов данных с большим количеством признаков вычислительная сложность становится значительной, что может сделать процесс обучения долгим.
		\end{itemize}

\end{enumerate}

\subsection{Задачи}

\textbf{Задача 1:}
Докажите, что решение системы нормальных уравнений для метода наименьших квадратов существует и единственно, если матрица \(X^T X\) положительно определённая. \\
\textbf{Решение:}
Метод наименьших квадратов минимизирует квадратичную функцию:
\[
Q(\beta) = \|y - X\beta\|^2 = (y - X\beta)^T (y - X\beta)
\]
Рассмотрим стационарные точки функции \(Q(\beta)\), задаваемые системой нормальных уравнений:
\[
X^TX\beta = X^Ty
\]
- Условие существования решения: \\
Решение существует, если матрица \(X^T X\) невырожденная, то есть её детерминант \(\det(X^T X) \neq 0\). Это выполняется, если признаки в X линейно независимы (нет мультиколлинеарности). \\
- Условие единственности решения: \\
Если \(X^T X\) положительно определённая, то:
\begin{enumerate}
	\item \((X^T X)\) симметрична.
	\item Для любого ненулевого вектора \(v\), \(v^T(X^T X)v > 0\).
\end{enumerate}
Положительная определённость гарантирует, что квадратичная форма \(Q(\beta)\) строго выпуклая, а значит, имеет единственную точку минимума.

\textbf{Задача 2:}
Опишите, как изменится целевая функция метода наименьших квадратов \( Q(\beta) = \|y - X\beta\|^2 \), если в данных присутствует выброс. Почему минимизация квадратичной ошибки делает метод чувствительным к таким точкам? \\
\textbf{Решение:}
Выбросы увеличивают квадратичную ошибку, так как вклад отклонений от линии регрессии для таких точек пропорционален квадрату расстояния. Это означает, что несколько больших ошибок могут доминировать над множеством малых, и решение будет смещено в сторону выбросов. Например, если одна ошибка вдвое больше остальных, её вклад в целевую функцию будет в четыре раза больше. Это делает МНК очень чувствительным к выбросам и может привести к неверным коэффициентам модели.

\textbf{Задача 3:}
Реализуйте простой случай МНК для одномерной линейной регрессии, где \(X = [1, 2, 3]\), \(y = [2, 4, 6]\). Найдите коэффициенты \(\beta_0\) и \(\beta_1\). \\
\textbf{Решение:}
Для одномерного случая формула нормальных уравнений имеет вид:
\[
\hat{\beta} = (X^T X)^{-1} X^T y.
\]
Подставляя значения:
\[
X = \begin{bmatrix}
1 & 1 \\
1 & 2 \\
1 & 3
\end{bmatrix}, \quad y = \begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix}.
\]
Рассчитаем:
\[
X^T X = \begin{bmatrix}
3 & 6 \\
6 & 14
\end{bmatrix}, \quad X^T y = \begin{bmatrix}
12 \\
28
\end{bmatrix}.
\]
Получаем:
\[
\hat{\beta} = \begin{bmatrix}
3 & 6 \\
6 & 14
\end{bmatrix}^{-1} \begin{bmatrix}
12 \\
28
\end{bmatrix}.
\]
После вычислений \(\hat{\beta} = \begin{bmatrix} 0 \\ 2 \end{bmatrix}\). Таким образом, уравнение линейной регрессии: \(y = 2x\).

\newpage

\section{Вероятностные функции потерь}

\subsection{Принцип максимума правдоподобия}

Предположим, что \(X\times Y\) - \textbf{вероятностное пространство} с некоторой \textbf{плотностью совместного распределения} пары объект-ответ \(p(x,y)\).
Пусть \(X^{l}\) - \textit{простая} (i.i.d., или independent identically distributed - независимо из одного и того же распределения) выборка: \({(x_{i}, y_{i})^{l}}\), порожденная \(p(x,y)\).

Задача состоит в том, чтобы оценить по выборке \(X^{l}\) плотность распределения \(p(x,y)\). Получив оценку плотности, то с его помощью возможна классификация объекта \(x\) - мы сможем вычислять вероятность класса \(y\) для любого объекта \(x\).

Далее введем \textbf{параметризацию} плотности, взяв за основу формулу условной вероятности: \(p(x,y) = P(y | x,w)p(x)\), где \(p(x,y)\) - искомая плотность; \(P(y|x,w\) - модель условной вероятности класса с параметром \(w\); \(p(x)\) - непараметризуемое распределение в пространстве \(X\). Возможны и другие способы введения параметризации, однако сейчас будет рассматриваться именно этот.

Так как выборка простая, то плотность порожденной выборки является произведением плотностей отдельных порожденных пар \((x_{i}, y_{i})\). Таким образом, \(\prod_{i=1}^{l}{p(x_{i},y_{i})}\) - \textit{правдоподобие данных}.

В качестве критерия оптимизации возьмем один из фундаментальных методов в математической статистике - \textbf{принцип максимума правдоподобия}:

\[
\prod_{i=1}^{l}{p(x_{i},y_{i})} = \prod_{i=1}^{l}{P(y_{i}|x_{i},w)p(x_{i})} \xrightarrow{} \max_{w}
\]

В силу того, что \(p(x_{i})\) - сомножитель, не зависящий от \(w\), от него можно избавиться.

\[
\prod_{i=1}^{l}{P(y_{i}|x_{i},w)} \xrightarrow{} \max_{w}
\]

Поскольку стоит задача максимизации, критерий в виде произведения по всем объектам выборки неудобен. Чтобы избавиться от произведения, прологарифмируем критерий. Логарифм - монотонная функция, поэтому несущественно, что мы оптимизируем - функционал или его логарифм.

\textbf{Логарифм правдоподобия} (log-likehood, log-loss):

\[
L(w) = \sum_{i=1}^{l}{log \ P(y_{i}|x_{i},w)} \xrightarrow{} \max_{w}
\]

\subsection{Связь правдоподобия и аппроксимации эмпирического риска}

Посмотрим на одну и ту же задачу классификации на два класса \(Y = \{+1; -1\}\) с двух сторон:
\begin{enumerate}
    \item \(P(y|x,w)\) - вероятностная модель классификации.
    \item \(g(x,w)\) - разделяющая (дискриминантная) функция - геометрический взгляд на задачу.
\end{enumerate}

Критерии, возникающие в разных случаях:
\begin{enumerate}

    \item \textit{Максимизация правдоподобия} (Maximum Likehood):
    \[
    L(w) = \sum_{i=1}^{l}{log \ P(y_{i}|x_{i},w)} \xrightarrow{} \max_{w};
    \]

    \item \textit{Минимизация аппроксимированного эмпирического риска}:
    \[
    Q(w) = \sum_{i=1}^{l}{L(y_{i}g(x_{i},w))} \xrightarrow{} \min_{w};
    \]
    Здесь \(L(M)\) - функция потерь; \(y_{i}g(x_{i}, w)\) - значение отступa.

\end{enumerate}


Оба критерия представляют собой оптимизацию некоторой величины, являющейся суммой по всем объектам выборки, по параметру. Каждое слагаемое суммы зависит только от одного объекта.

Эти два принципа \textbf{эквиваленты}, если положить:

\[
-log \ P(y_{i}|x_{i},w) = L(y_{i}g(x_{i},w)
\]

\subsection{Вероятностный смысл регуляризации}

Рассматривается двухуровневая модель порождения данных:
\begin{enumerate}
    \item \(P(y|x,w\) - вероятностная модель данных.
    \item \(p(w;y)\) - априорное распределение параметров модели.
    \item \(\gamma\) - вектор гиперпараметров.
\end{enumerate}

Теперь не только появление выборки \(X^{l}\), но и модели \(w\) полагается стохастическим.

Совместное правдоподобие данных и модели по формуле условной плотности:

\[
p(X^{l},w) = p(X^{l}|w)p(w;\gamma)
\]

\textit{Принцип максимума апостериорной вероятности} (Maximum a Posteriori Probability, MAP):

\[
L(w) = log \ p(X^{l},w) = \sum_{i=1}^{l}{log \ P(y_{i}|x_{i},w) + log \ p(w;\gamma)} \xrightarrow{} \max_{w}
\]

Таким образом, слагаемое \(-log \ p(w;\gamma)\) является \textbf{регуляризатором} с вероятностной точки зрения.

\subsection{Задачи}

\subsubsection{Задача 1.}
Какому регуляризатору соответствует апостериорное распределение параметров модели, имеющее вид распределения Гаусса?

\textit{Решение:}

Веса \(w_{j}\) независимы, \(E[w_{j}]=0\), \(D[w_{j}]=C\).

\[
p(w;C) = \frac{1}{{(2\pi C)}^{\frac{n}{2}}}exp(-\frac{||w^2||}{2C}), ||w^2||=\sum_{j=1}^{n}{w_{j}^2}
\]

\[
-ln \ p(w;C)=\frac{1}{2C}||w^2|| + const
\]

От константы можно избавиться:

\[
-ln \ p(w;C)=\frac{1}{2C}||w^2||
\]

Получаем квадратичный \((L_{2})\) регуляризатор. \(C\) является гиперпараметром, \(\tau = \frac{1}{C}\) - коэффициент регуляризации.

\subsubsection{Задача 2.}
Какому виду регуляризации соответствует апостериорное распределение параметров модели, имеющее вид распределения Лапласа?

\textit{Решение:}

Веса \(w_{j}\) независимы, \(E[w_{j}]=0\), \(D[w_{j}]=C\).

\[
p(w;C) = \frac{1}{{(2C)}^{n}}exp(-\frac{||w||}{C}), ||w||=\sum_{j=1}^{n}{|w_{j}|}
\]

\[
-ln \ p(w;C)=\frac{1}{C}||w|| + const
\]

От константы можно избавиться:

\[
-ln \ p(w;C)=\frac{1}{C}||w||
\]

Получаем абсолютный \((L_{1})\) регуляризатор. \(C\) является гиперпараметром, \(\tau = \frac{1}{C}\) - коэффициент регуляризации.

\subsubsection{Задача 3.}
Найти вид апостериорного распределения параметров модели, соответствующий регуляризатору Elastic Net:

\[
R(w;C_{1};C_{2}) = \frac{1}{C_{1}}\sum_{i=1}^{l}{|w_{i}|} + \frac{1}{2C_{2}}\sum_{i=1}^{l}{w_{i}^{2}}
\]

\textit{Решение:}

\[
-ln \ p(w;C_{1};C_{2}) = \frac{1}{C_{1}}||w|| + \frac{1}{2C_{2}}||w^2||
\]

С точностью до умножения на константу, получим:

\[
p(w;C_{1};C_{2}) = exp(-\frac{||w||}{C_{1}})exp(-\frac{||w^2||}{2C_{2}})
\]

\[
p(w;C_{1};C_{2}) = exp(-\frac{||w||}{C_{1}}-\frac{||w^2||}{2C_{2}})
\]


\section{Методы оценки и проверки моделей}

Оценка и проверка моделей являются важными этапами в построении машинного обучения. Эти методы позволяют определить, насколько хорошо модель обучается на данных и обобщает свои выводы на новых, ранее невиданных данных. Ниже представлены основные подходы к оценке и проверке моделей.

\subsection*{Кросс-валидация}
Кросс-валидация --- это метод проверки модели, который заключается в разбиении данных на несколько подвыборок (folds). Основные виды кросс-валидации:
\begin{itemize}
    \item \textbf{K-блочная кросс-валидация} (K-fold cross-validation): данные делятся на $K$ частей, и обучение проводится на $K-1$ частях, а тестирование на оставшейся части. Процесс повторяется $K$ раз, чтобы каждая часть данных использовалась для тестирования.
    \item \textbf{Leave-One-Out (LOO)}: частный случай кросс-валидации, где тестовая выборка состоит из одного наблюдения, а оставшиеся используются для обучения. Этот метод особенно полезен для небольших наборов данных, но может быть вычислительно затратным.
    \item \textbf{Stratified K-fold}: разновидность K-блочной кросс-валидации, где сохраняются пропорции классов в каждой из выборок, что особенно важно для несбалансированных данных.
\end{itemize}

Кросс-валидация помогает уменьшить риск переобучения и получить более надежные оценки качества модели.

\subsection*{Метрики качества}
Для оценки модели применяются различные метрики, выбор которых зависит от задачи (регрессия или классификация):
\begin{itemize}
    \item \textbf{Для регрессии:}
    \begin{itemize}
        \item Среднеквадратичная ошибка (MSE):
        \[
        \text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2.
        \]
        Эта метрика чувствительна к выбросам, так как большие ошибки квадратично увеличивают значение MSE.
        \item Средняя абсолютная ошибка (MAE):
        \[
        \text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|.
        \]
        MAE более устойчива к выбросам, так как ошибки учитываются линейно.
        \item Коэффициент детерминации ($R^2$):
        \[
        R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}.
        \]
        Значение $R^2$ показывает, какую долю дисперсии целевой переменной объясняет модель.
    \end{itemize}
    \item \textbf{Для классификации:}
    \begin{itemize}
        \item Точность (Accuracy):
        \[
        \text{Accuracy} = \frac{\text{Количество верных предсказаний}}{\text{Общее количество наблюдений}}.
        \]
        Используется для сбалансированных данных.
        \item Precision, Recall и $F_1$-мера:
        \[
        \text{Precision} = \frac{TP}{TP + FP}, \quad \text{Recall} = \frac{TP}{TP + FN}, \quad F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}.
        \]
        Эти метрики особенно важны для несбалансированных классов.
        \item ROC-кривые и площадь под кривой (AUC):
        ROC-кривая показывает соотношение TPR (True Positive Rate) и FPR (False Positive Rate) при различных порогах классификации, а AUC характеризует общую способность модели различать классы.
    \end{itemize}
\end{itemize}

\subsection*{Разделение данных}
Одним из простейших методов проверки модели является разделение данных на обучающую и тестовую выборки. Чаще всего используется пропорция 70\%/30\% или 80\%/20\%. Однако этот метод имеет недостаток: если данные случайно разделены неудачно, это может привести к неверным оценкам качества модели.

Для улучшения оценки часто используется тройное разбиение данных:
\begin{itemize}
    \item \textbf{Обучающая выборка} (Train set): используется для обучения модели.
    \item \textbf{Валидационная выборка} (Validation set): используется для подбора гиперпараметров и предотвращения переобучения.
    \item \textbf{Тестовая выборка} (Test set): применяется для окончательной оценки модели.
\end{itemize}

\subsection*{Проблемы и рекомендации}
\begin{itemize}
    \item \textbf{Переобучение:} Если модель слишком сложная, она может хорошо работать на обучающих данных, но плохо обобщаться на тестовые. Регуляризация и кросс-валидация помогают бороться с этой проблемой.
    \item \textbf{Недообучение:} Слишком простые модели могут не учитывать важные зависимости в данных. Следует выбирать более сложные модели или добавлять новые признаки.
    \item \textbf{Сбалансированность данных:} Для несбалансированных данных рекомендуется использовать метрики, такие как Precision, Recall или AUC.
\end{itemize}

\section*{Задачи}

\begin{enumerate}
    \item Для датасета (сгенерируйте сами) с 10 000 объектов примените 5-блочную кросс-валидацию. Опишите, как будут разделены данные на обучающие и тестовые выборки на каждом шаге. Рассчитайте среднее значение метрики Accuracy, если на каждом шаге она принимает значения: 0.85, 0.87, 0.86, 0.84, 0.88.

    \item Для задачи регрессии выберите подходящую метрику качества из MSE, MAE или $R^2$ и объясните, почему вы сделали такой выбор. Рассчитайте её значение для предсказаний $\hat{y} = [3, 5, 2, 7]$ и истинных значений $y = [3, 5, 4, 6]$.

    \item В задаче классификации модель предсказала 100 объектов, из которых 70 были классифицированы правильно, 20 --- ложно положительными, а 10 --- ложно отрицательными. Рассчитайте Precision, Recall и $F_1$-меру.
\end{enumerate}

\section{Линейная классификация}
\subsection{Постановка задачи}
Представим, что у нас есть множество объектов $X$ и мы хотим каждому объекту сопоставить некоторый класс. Например, есть набор клиентов банков и хотим понять кому из них стоит выдавать кредит, а кому нет. Формализуя имеем отображение из множества объектов $X$ в некоторое множество классов: $$X \rightarrow \{0, 1, \ldots, K\}, \text{где } 0, \ldots, K - \text{номера классов}.$$
Такая задача называется задачей классификации.

Будем искать решения в виде некоторой линейной функции $y = w_1x_1 + \ldots + w_nx_n + w_0$, где $y$ - целевая переменная (target), $(x_1, \ldots, x_n)$ вектор признаков объекта выборки (features), вектор $w = (w_1, \ldots, w_n)$ называют вектором весов (weights), а $w_0$ - свободный коэффициентом, или сдвигов (bias). Более компактно можно записать в виде: $y = <x, w> + w_0$. Теперь наша задача свелась к подбору конкретного вектора $(w_0, w_1, \ldots, w_n)$, задающего наше отображение. 

Не сложно заметить, что сейчас наша функция имеет некоторое числовое значение, а мы бы хотели категориальное. Поправим это сказав, что если $y > 0$ это один класс, иначе - второй. $y = sign (<x, w> + w_0)$. Многокотегариальный случай рассмотрим чуть позже.

Итого имеем некоторую разделяющую прямую (или гиперплоскость в случае больших размерностей) которая делит наше пространство на два класса.

В идеальном случае найдется плоскость, которая разделит классы, так чтобы первый оказался с одной стороны, а второй с другой. В таком случае выборка называется линейно разделимой, но чаще всего так получаться не будет.

\subsection{Многоклассовая классификация}
В случае если у нас больше двух классов, воспользуемся набором бинарных классификаторов. Разберем два самых популярных способа это сделать - one-vs-all и all-vs-all.
\subsubsection*{Один против всех}
Обучим $K$ линейных классификаторов $b_1(x), \ldots, b_k(x)$, выдающих оценки принадлежности классам $1, \ldots, K$ соответственно. В случае с линейными моделями эти классификаторы будут иметь вид:
$$b_k(x) = sign(<w_k, x> + w_{0k}).$$
Каждый классификатор будем обучать отличать $k$-й класс от все остальных. Тогда логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность в каком-то смысле можно измерить с помощью значений линейных функций:
$$y(x) = argmax_k(<w_k, x> + w_{0k}).$$
\subsubsection*{Все против всех}
Обучим $C_K^2$ классификаторов $b_{ij}(x)$, $i, j = 1, \ldots, K, i \neq j$. Для линейной модели они будут иметь вид:
$$b_{ij}(x) = sign(<w_{ij}, x> + w_{0,ij}).$$ 
Каждый классификатор будем обучать только на объектах классов $i, j$. Тогда наш классификатор будет выдавать для любого объекта либо класс $i$, либо класс $j$. Чтобы получить итоговый класс, пусть каждый классификатор проголосует за свой класс, а в качестве ответа выберем тот класс, за который будет больше голосов:
$$y(x) = argmax_k\sum_{i=1}^{K}\sum_{i \neq j}[b_{ij}(x)=k].$$
\subsection{Задачи}
\subsubsection*{Задача 1.}
Почему существует линейный модели, но нет "полиномиальных" или "логарифмических", хотя зависимости между данными бывают довольно сложными?

\textit{Решение:} На самом деле если мы подозреваем какую-то более сложную зависимость данных, то мы можем ввести новые признаки со сложной зависимостью, получив задачу в большей размерности, но все еще решаемую линейной моделью.

\subsubsection*{Задача 2.}
Что делать если есть категориальный признаки, то есть он принимает какие-то значения, не обязательно являющиеся числами?

\textit{Решение:} Линейная модель работает только с числовыми признаками, поэтому категориальный придется закодировать. Например, можно использовать технику one-hot encoding. Пусть наш признак может принимать $k$ значений. Заменим его на $k$ новых признаков, для которых один принимает единицу (в зависимости от значения категориального признака), а все остальные ноль.

\subsubsection*{Задача 2.}
Каким еще может быть ответ у классифицирующей модели, помимо простой принадлежности какому-то классу?

\textit{Решение:} Модель может выдавать не принадлежность классу, а вероятность с которой она бы отнесла его к соответствующему классу. Такой подход называется логистической регрессий и очень часто встречается, поскольку нам часто хочется знать насколько модель уверена в своем выборе.


\section{Линейные методы для интерпретации моделей}

Интерпретация моделей машинного обучения играет важную роль в задачах, где требуется понять, какие факторы влияют на предсказания модели. Линейные модели, благодаря своей простой структуре, являются одними из наиболее интерпретируемых алгоритмов. В этой главе мы рассмотрим основные подходы к интерпретации линейных моделей.

\subsection*{Значимость коэффициентов}
В линейных моделях каждый коэффициент отражает вклад соответствующего признака в итоговый результат. Для интерпретации коэффициентов можно использовать следующие подходы:
\begin{itemize}
    \item \textbf{Проверка знаков коэффициентов:} Знак коэффициента указывает на направление влияния признака. Положительный знак говорит о прямой зависимости, отрицательный --- об обратной.
    \item \textbf{Нормализация признаков:} Перед обучением модели признаки часто стандартизируют (приводят к нулевому среднему и единичной дисперсии), чтобы значения коэффициентов можно было сравнивать между собой.
    \item \textbf{Статистическая значимость:} Для проверки важности коэффициентов можно использовать t-тесты, вычисляя p-значения для каждого коэффициента.
\end{itemize}

\subsection*{Доверительные интервалы}
Для оценки надежности коэффициентов модели используются доверительные интервалы. Они позволяют определить диапазон значений, в котором с определённой вероятностью находится истинное значение коэффициента.
\[
CI_j = \hat{\beta}_j \pm t_{\alpha/2} \cdot SE_j,
\]
где $\hat{\beta}_j$ --- оценка коэффициента, $SE_j$ --- стандартная ошибка, $t_{\alpha/2}$ --- квантиль распределения Стьюдента.

Интервалы, включающие ноль, указывают на возможную незначимость соответствующего признака.

Можем на примере одномерного случая задачи линйной регрессии убедится в значимости главного параметра. Пусть в нашем распоряжении есть набор точек:

\begin{align}
x = \{1, 2, 3, 4, 5\}; \text{\space\space} y = \{2, 3, 5, 7, 11\}.
\end{align}

Задача заключается в построении линейной регрессии \(y = \beta_0 + \beta_1 x\), а также определении доверительного интервала для коэффициента \(\beta_1\) при \(p = 0.05\) . Используя формулы для коэфициентнов МНК можно легко определить стандартное отклонение для \(\beta_1\); подставив все в формулу выше получим границы доверительного интервала для \(\beta_1\):
\begin{align*}
CI_{\text{lower}} &= \beta_1 - t \cdot \text{SE}(\beta_1) = 2.2 - 3.182 \cdot 0.275 \approx 1.32, \\
CI_{\text{upper}} &= \beta_1 + t \cdot \text{SE}(\beta_1) = 2.2 + 3.182 \cdot 0.275 \approx 3.08.
\end{align*}

Сравнивая значение \(\beta_1\) с границами доверительного интервала пониманием что \(\beta_1\) является значимым параметром построенной линейной модели.

\subsection*{Методы визуализации влияния признаков}
Для упрощения интерпретации линейных моделей часто используют визуальные методы. Некоторые из них:
\begin{itemize}
    \item \textbf{Partial Dependence Plots (PDP):} Помогает визуализировать влияние одного или нескольких признаков на предсказания модели, усредняя влияние других признаков. Крутизна кривой в PDP покажет силу влияния этого признака.

    Строгое математическое опрдеделение PD:
    \begin{equation}
    pd_{X_S}(x_S) \overset{\text{def}}{=} \mathbb{E}_{X_C} \big[f(x_S, X_C)\big]
    = \int f(x_S, x_C) p(x_C) \, dx_C,
    \end{equation}

    \begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/linear/pics/partial_dependence.png}
    \caption{Пример PDP в задаче числа суточной аренды велосипедов.}
    \label{fig:pdp}
    \end{figure}

    \item \textbf{Влияние признаков (SHAP и LIME):} Современные методы, такие как SHAP (SHapley Additive exPlanations) и LIME (Local Interpretable Model-agnostic Explanations), позволяют объяснить предсказания модели для отдельных объектов.
\end{itemize}

\subsection*{Влияние мультиколлинеарности}
Мультиколлинеарность возникает, когда между признаками существует сильная корреляция. Это может приводить к нестабильным оценкам коэффициентов. Для её диагностики используют:
\begin{itemize}
    \item \textbf{Фактор инфляции дисперсии (VIF):}
    \[
    VIF_j = \frac{1}{1 - R_j^2},
    \]
    где $R_j^2$ --- коэффициент детерминации при регрессии $j$-го признака на остальные.

    \subsubsection{Коэффициент детерминации \( R^2 \)}

    Коэффициент детерминации (\( R^2 \)) — это метрика, используемая для оценки качества модели регрессии. Он показывает, какую долю дисперсии зависимой переменной (\( Y \)) модель способна объяснить.

    \subsubsection*{Формула}
    Коэффициент \( R^2 \) рассчитывается следующим образом:
    \[
    R^2 = 1 - \frac{SS_{\text{res}}}{SS_{\text{tot}}},
    \]
    где:
    \begin{itemize}
    \item \( SS_{\text{res}} = \sum_{i=1}^n (y_i - \hat{y}_i)^2 \) — остаточная сумма квадратов (сумма квадратов отклонений между реальными значениями \( y_i \) и предсказанными значениями \( \hat{y}_i \));
    \item \( SS_{\text{tot}} = \sum_{i=1}^n (y_i - \bar{y})^2 \) — общая сумма квадратов (сумма квадратов отклонений реальных значений \( y_i \) от среднего значения \( \bar{y} \));
    \item \( \bar{y} \) — среднее значение зависимой переменной:
    \[
    \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i.
    \]
\end{itemize}

\subsection*{Интерпретация}
Значение \( R^2 \) находится в диапазоне от 0 до 1:
\begin{itemize}
    \item \( R^2 = 1 \): модель идеально объясняет дисперсию данных.
    \item \( R^2 = 0 \): модель не объясняет дисперсию данных (эквивалентно случайному предсказанию среднего значения \( \bar{y} \)).
    \item \( R^2 < 0 \): модель объясняет дисперсию хуже, чем случайное предсказание среднего значения.
\end{itemize}

Для задачи определения значимого признака, каждый признак по очереди берется в качестве независимой переменной и для каждого формулируется задача регрессии:

\begin{align}
X_{j} = \beta_0 + \sum_{i \neq j}^n\beta_{i} * X_{i}
\end{align}

Таким образом высокое значение VIF для отдельной переменной говорит об ее избыточности в обучаемой выборке, т.к. информация о ней (для линейной модели) почти полностью содержится в других признаках. На практике при значениях VIF > 10 говорят о мультиколениарности данных и избавляются от таких признаков или применяют L1, L2 регуляризации.

\subsection*{Практические примеры}
Рассмотрим несколько примеров использования линейных методов для интерпретации:
\begin{itemize}
    \item \textbf{Прогнозирование цен на недвижимость:} Вклад признаков, таких как площадь, расположение и возраст здания, можно интерпретировать напрямую через коэффициенты линейной модели.
    \item \textbf{Медицинская диагностика:} В задачах прогнозирования риска заболеваний линейные модели позволяют определить, какие факторы (например, возраст, уровень холестерина) оказывают наибольшее влияние.
\end{itemize}

\subsection*{Задачa 1: Доверительный интервал \(\beta_1\).}

Требуется найти доверительный интервал для \(\beta_1\), используя точки из этой главы.

\textbf{Решение:}

Для коэффициентов линейной регрессии используем формулы метода наименьших квадратов:
\begin{align*}
\beta_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}, \\
\beta_0 &= \bar{y} - \beta_1 \bar{x},
\end{align*}
где \(\bar{x}\) и \(\bar{y}\) — средние значения \(x\) и \(y\) соответственно.

Подставляя значения:
\begin{align*}
\bar{x} &= 3, \quad \bar{y} = 5.6, \\
\beta_1 &= \frac{\sum (x_i - 3)(y_i - 5.6)}{\sum (x_i - 3)^2} = 2.2, \quad \beta_0 = 5.6 - 2.2 \cdot 3 = -0.4.
\end{align*}

Средняя квадратная ошибка (MSE) определяется как:
\[
\text{MSE} = \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n - 2},
\]
где \(\hat{y}_i\) — предсказанное значение для \(y_i\). Подставляя значения:
\[
\text{MSE} = \frac{(2 - 1.8)^2 + (3 - 3.6)^2 + (5 - 5.8)^2 + (7 - 8)^2 + (11 - 10.2)^2}{5 - 2} = 0.76.
\]

Стандартная ошибка для \(\beta_1\):
\[
\text{SE}(\beta_1) = \sqrt{\frac{\text{MSE}}{\sum_{i=1}^n (x_i - \bar{x})^2}} = \sqrt{\frac{0.76}{10}} = 0.275.
\]

Квантиль распределения Стьюдента для уровня доверия 95\% и \(n-2=3\) степеней свободы:
\[
t_{0.025, 3} \approx 3.182.
\]

Границы доверительного интервала:
\begin{align*}
CI_{\text{lower}} &= \beta_1 - t \cdot \text{SE}(\beta_1) = 2.2 - 3.182 \cdot 0.275 \approx 1.32, \\
CI_{\text{upper}} &= \beta_1 + t \cdot \text{SE}(\beta_1) = 2.2 + 3.182 \cdot 0.275 \approx 3.08.
\end{align*}

\textbf{Иллюстрация:}
На рисунке показана линия регрессии (красная), а также линии, соответствующие границам доверительного интервала (зелёная и оранжевая).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{chapters/linear/pics/beta_range.png}
    \caption{Пример линейной регрессии с доверительными интервалами.}
\end{figure}

\subsection*{Задача 2: Интерпретация PDP.}

Глядя на \ref{fig:pdp}, проведите анализ значимости изображенных признаков - температуры и влажности воздуха на общее количество арендуемых в день велосипедов. Какое влияние оказывают эти признаки на предсказываемую велечину? \\

\textbf{Решение:}

\begin{itemize}
 \item \textbf{Температура} оказывает значительное положительное влияние на предсказываемую величину, особенно в диапазоне 20-30 градусов
 \item \textbf{Влажность} оказывает отрицательное влияние: по мере её увеличения предсказания снижаются.
 \item \textbf{Совместное влияние} показало, что оптимальная комбинация — высокая температура и низкая влажность.
\end{itemize}

Оба эти признака являются значимыми для построения предсказательной модели, т.к. линии графиков PD имеют крутой наклон. Также видно что наклон на графике не постоянный и целесообразно задуматься об использовании нелинейной регресии или градиентного бустинга. \\\\

\subsection*{Задача 3: Определение мультиколениарности переменных по VIF.}

Сделать вывод о значимости переменных \(X_{2}\) и \(X_{3}\) \\

\begin{table}[h!]
\centering
\caption{Тренировочная выборка}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\(Y\)} & \textbf{\( X_1 \)} & \textbf{\( X_2 \)} & \textbf{\( X_3 \)} \\ \hline
1                  & 1                  & 2                  & 3                  \\ \hline
2                  & 2                  & 4                  & 6                  \\ \hline
3                  & 3                  & 6                  & 9                  \\ \hline
4                  & 4                  & 8                  & 12                 \\ \hline
5                  & 5                  & 10                 & 15                 \\ \hline
\end{tabular}
\label{tab:example_vif}
\end{table}

\textbf{Решение:}

Не трудно видеть что:

\begin{align}
X_{2} = 2*X_{1} \text{\space\space} X_{3} = 3*X_{1}
\end{align}

Таким образом оба этих признака линейно зависимы и никакой информации в себе не несут. При использовании формул для VIF, можно также убедится

\begin{align}
VIF_{2} -> \infty \text{\space\space} VIF_{3}-> \infty
\end{align}
\section{Многоклассовая классификация}

Задача многоклассовой классификации решает проблему нахождения принадлежности объекта к одному из $K$ классов: $Y = \{1, 2, ..., K\}$. В этом разделе будут разобраны некоторые из самых популярных подходов: one-vs-all, all-vs-all и многоклассовая логистическая регрессия. В качестве примера возьмем датасет из \href{https://education.yandex.ru/handbook/ml/article/linear-models}{хендбука Яндекса}, продемонстрированный на Рис. \ref{fig:linear-multi-dataset}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-dataset.png}
	\caption{Пример датасета задачи многоклассовой классификации}
	\label{fig:linear-multi-dataset}
\end{figure}

\subsection{Один против всех (one-versus-all)}

Обучим $K$ линейных классификаторов $b_1(x),...,b_K(x)$, выдающих оценки принадлежности классам $1,...,K$ соответственно. В случае с линейными моделями эти классификаторы будут иметь вид $b_k(x) = \operatorname{sign}(\langle w_k, x \rangle+w_{0k})$

Классификатор с номером $k$ будем обучать по выборке $(x_i, 2 \mathbb{I}[y_i = k] -1)^\ell_{i=1} $; иными словами, мы учим классификатор отличать $k$-й класс от всех остальных.

Логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность можно в каком-то смысле измерить с помощью значений линейных функций:

$ a(x)= \operatorname{arg}\max\limits_{k \in Y} (\langle w_k, x \rangle+w_{0k})$

Давайте посмотрим, что даст этот подход применительно к нашему датасету. Обучим три линейных модели, отличающих один класс от остальных (Рис. \ref{fig:linear-multi-ova-models}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ova-models.png}
	\caption{Каждая из трех моделей, отделяющие свои классы}
	\label{fig:linear-multi-ova-models}
\end{figure}

Теперь сравним значения линейных функций на Рис. \ref{fig:linear-multi-ova-values}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ova-values.png}
	\caption{Значения функций моделей}
	\label{fig:linear-multi-ova-values}
\end{figure}

и для каждой точки выберем тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор, и изобразим это на Рис. \ref{fig:linear-multi-ova-final}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ova-final.png}
	\caption{Итог разделения пространства на классы}
	\label{fig:linear-multi-ova-final}
\end{figure}

Хочется сказать, что самый маленький класс «обидели».

Проблема данного подхода заключается в том, что каждый из классификаторов $b_1(x),...,b_K(x)$ обучается на своей выборке, и значения линейных функций $\langle w_k, x \rangle+w_{0k}$ или, проще говоря, "выходы" классификаторов могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно. Нормировать вектора весов, чтобы они выдавали ответы в одной и той же шкале, не всегда может быть разумным решением: так, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка изменит норму весов.

\subsection*{Задача}

Подумайте, какой простой двумерный датасет особенно плохо работает с данным подходом с линейным классификатором (что вызвано исключительно характером распределения классов, а не выбросами, количеством данных и т.п.).

\subsection*{Ответ}

Примером такого датасета могут послужить три класса, такие что один находится между двумя другими, как на Рис. \ref{fig:linear-multi-ova-contrprimer}. В этом случае нельзя полагаться на значения разделяющей функции, так как, например, зеленый класс лежит сильно дальше границы желтого и синего классов, чем сам желтый класс. Поэтому, желто-синий классификатор будет относить зеленые точки к желтому цвету с большей уверенностью, чем желтые.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ova-contrprimer.png}
	\caption{Контрпример к one-vs-all}
	\label{fig:linear-multi-ova-contrprimer}
\end{figure}

\subsection{Все против всех (all-versus-all)}

Обучим  $C^2_k$ классификаторов $a_{ij}(x), i, j = 1,..,K, i \neq j$. Например, в случае с линейными моделями эти модели будут иметь вид

$a_{ij}(x) = \operatorname{sign}(\langle w_{ij}, x \rangle+w_{0,ij})$

Классификатор $a_{ij}(x)$ будем настраивать по подвыборке $X_{ij} \subset X$, содержащей только объекты классов $i$ и $j$. Соответственно, классификатор $a_{ij}(x)$ будет выдавать для любого объекта либо класс $i$, либо класс $j$. Проиллюстрируем это для нашей выборки на Рис. \ref{fig:linear-multi-ava-models}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ava-models.png}
	\caption{Классификаторы, разделяющие по два класса}
	\label{fig:linear-multi-ava-models}
\end{figure}

Чтобы классифицировать новый объект, подадим его на вход каждого из построенных бинарных классификаторов. Каждый из них проголосует за свой класс; в качестве ответа выберем тот класс, за который наберется больше всего голосов:

$a(x) = \operatorname{arg}\max\limits_{k \in Y} \sum\limits_{i=1}^K\sum\limits_{j\neq i} \mathbb{I}[a_{ij}(x) = k]$

Для нашего датасета получается следующая картинка на Рис. \ref{fig:linear-multi-ava-final}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/multi-ava-final.png}
	\caption{Итоговый результат для all-vs-all}
	\label{fig:linear-multi-ava-final}
\end{figure}

Обратите внимание на серый треугольник на стыке областей. Это точки, для которых голоса разделились (в данном случае каждый классификатор выдал какой-то свой класс, то есть у каждого класса было по одному голосу). Для этих точек нет явного способа выдать обоснованное предсказание.

\subsection{Многоклассовая логистическая регрессия}

Некоторые методы бинарной классификации можно напрямую обобщить на случай многих классов. Выясним, как это можно проделать с логистической регрессией.

В логистической регрессии для двух классов мы строили линейную модель

$b(x) = \langle w, x \rangle+w_0$

а затем переводили её прогноз в вероятность с помощью сигмоидной функции $\sigma(M) = \frac{1}{1+\operatorname{exp}(-M)}$. Допустим, что мы теперь решаем многоклассовую задачу и построили $K$ линейных моделей

$b_k(x) = \langle w_k, x \rangle+w_{0k}$

каждая из которых даёт оценку принадлежности объекта одному из классов. Как преобразовать вектор оценок $(b_1(x),...,b_K(x))$ в вероятности? Для этого можно воспользоваться оператором $\operatorname{softmax}(z_1,...,z_k)$,

\subsection*{Задача}

Подумайте, как должен выглядеть этот оператор, зная, что в случае двух классов он совпадает с сигмоидой, принимает значения от нуля до единицы и равен вектору вероятностей принадлежности каждому из классов.

\subsection*{Ответ}

$\operatorname{softmax}(z_1,...,z_k) = \left( \frac{\exp{(z_1)}}{\sum^K_{k=1}\exp{(z_k)}}, ..., \frac{\exp{(z_K)}}{\sum^K_{k=1}\exp{(z_k)}}, \right)$ \newline

В этом случае вероятность $k$-го класса будет выражаться как

$P(y=k|x,w) = \frac{\exp{(\langle w_k, x \rangle+w_{0k})}}{\sum^K_{j=1}\exp{(\langle w_j, x \rangle+w_{0j})}}$

Обучать эти веса предлагается с помощью метода максимального правдоподобия: так же, как и в случае с двухклассовой логистической регрессией:

$\sum\limits_{i=1}^\ell \log P(y=y_i|x_i,w) \xrightarrow{} \max\limits_{w_1,...,w_K}$

\subsection*{Задача}

Подумайте, какой существует простой многоклассовый (нелинейный) классификатор, использующий только расстояние между объектами и не требующий обучения (у него отсутствуют параметры, есть только гиперпараметр).

\subsection*{Ответ}

Таким классификатором является KNN, или метод $k$ ближайших соседей. Этот алгоритм причисляет объект к самому популярному классу среду его $k$ ближайших соседей.

\section{Логистиеская регрессия}
\subsection*{Что такое логистическая регрессия?}

Логистическая регрессия — это статистический метод, используемый для классификации объектов на два или более классов. Она применяется, когда целевая переменная (\(y\)) принимает дискретные значения, чаще всего \(y \in \{0, 1\}\). Основной задачей логистической регрессии является предсказание вероятности принадлежности объекта к определённому классу.
 Примеры таких задач: Классификация писем на спам и не спам, предсказание вероятности заболевания на основе медицинских данных, прогноз поступления студента на основе экзаменационных баллов.

\subsection*{Идея логистической регрессии}

Логистическая регрессия основывается на линейной регрессии, но с одной важной модификацией: вместо того, чтобы предсказывать значения на бесконечном числовом отрезке, она ограничивает прогнозируемые значения интервалом \([0, 1]\). Это достигается с помощью логистической функции, которая преобразует линейное выражение в вероятность.


\subsection*{Математическая формулировка}


Сначала вычисляется линейная комбинация входных признаков:
\[
z = b_0 + b_1x_1 + b_2x_2 + \dots + b_nx_n,
\]
где:
- \(b_0\) — свободный член (интерсепт),
- \(b_1, b_2, \dots, b_n\) — коэффициенты модели,
- \(x_1, x_2, \dots, x_n\) — входные признаки.


Логистическая функция (или сигмоида) преобразует \(z\) в значение вероятности \(P(y=1)\):
\[
P(y = 1) = \frac{1}{1 + e^{-z}} = \sigma(z)
\]

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{chapters/linear/pics/sigmoida.png}
	\caption{График сигмоидной функции}
	\label{fig:sigmoida}
\end{figure}
Вероятность принадлежности к классу \(y=0\) вычисляется как:
\[
P(y = 0) = 1 - P(y = 1).
\]


Если вероятность \(P(y=1) \geq 0.5\), объект относят к классу \(y=1\); иначе — к классу \(y=0\).


Чтобы упростить обучение модели, применяется логарифмическая трансформация. Логарифмические шансы (логиты) определяются как:
\[
\text{logit}(P) = \ln\left(\frac{P(y = 1)}{1 - P(y = 1)}\right).
\]

Так как \(P(y = 1) = \frac{1}{1 + e^{-z}}\), подставим:
\[
\ln\left(\frac{P(y = 1)}{1 - P(y = 1)}\right) = z = b_0 + b_1x_1 + \dots + b_nx_n.
\]

\subsection*{Обучение логистической регрессии}

1. Функция правдоподобия

Вероятность \(P(y)\) для одного наблюдения записывается как:
\[
P(y) = P(y = 1)^{y} \cdot (1 - P(y = 1))^{1 - y}.
\]

Для всех наблюдений функция правдоподобия равна произведению вероятностей:
\[
L(\mathbf{b}) = \prod_{i=1}^m P(y_i | x_i).
\]

2. Логарифм правдоподобия

Чтобы упростить вычисления, берётся логарифм функции правдоподобия:
\[
\ell(\mathbf{b}) = \sum_{i=1}^m \left[y_i \ln(P(y_i)) + (1 - y_i) \ln(1 - P(y_i))\right].
\]

3. Максимизация логарифма правдоподобия

Коэффициенты \(\mathbf{b} = [b_0, b_1, \dots, b_n]\) определяются так, чтобы логарифм правдоподобия был максимален. Это достигается методами оптимизации, например, градиентным спуском.


\subsection*{Задача 1: Голосование на выборах}

\textbf{Условие:}  
Политическая партия пытается спрогнозировать, проголосует ли человек за неё, исходя из возраста \(x_1\) и политической активности \(x_2\) (в часах участия в митингах за год).  
Известны данные:  
\[
\begin{aligned}
    &\text{Человек 1: } x_1 = 22, x_2 = 15, \text{ проголосовал (}\, y = 1). \\
    &\text{Человек 2: } x_1 = 45, x_2 = 2, \text{ не проголосовал (}\, y = 0). \\
    &\text{Человек 3: } x_1 = 30, x_2 = 10, \text{ проголосовал (}\, y = 1).
\end{aligned}
\]

Определите, проголосует ли человек с \(x_1 = 35\) и \(x_2 = 8\). Используйте коэффициенты \(b_0 = -8\), \(b_1 = 0.2\), \(b_2 = 0.5\).  

\textbf{Решение:}

1. Записываем логистическую функцию:  
\[
P(y = 1) = \frac{1}{1 + e^{-(b_0 + b_1x_1 + b_2x_2)}}.
\]



2. Подставляем значения \(x_1 = 35\), \(x_2 = 8\):  
\[
z = b_0 + b_1x_1 + b_2x_2 = -8 + 0.2 \cdot 35 + 0.5 \cdot 8 = -8 + 7 + 4 = 3.
\]

3. Вычисляем вероятность:  
\[
P(y = 1) = \frac{1}{1 + e^{-3}} \approx 0.9526.
\]

4. Так как \(P(y = 1) > 0.5\), человек проголосует.  
Ответ: проголосует.


\subsection*{Задача 2: Магазин}

\textbf{Условие:}  
Магазин оценивает вероятность покупки товара клиентом в зависимости от времени, которое клиент проводит на сайте. Для этого применяется логистическая регрессия. Её уравнение:
\[
P(y = 1) = \frac{1}{1 + e^{-(b_0 + b_1x_1)}}.
\]

Где x - время проведённое на сайте в минутах, b_0 = -1.5, b_1 = 0.7


Какова вероятность того, что клиент, проведший 3 минуты на сайте, сделает покупку?

\textbf{Решение:}  

1. Записываем логистическую функцию:  
\[
P(y = 1) = \frac{1}{1 + e^{-(b_0 + b_1x_1)}}.
\]

3. Подставляем значения \(b_0 = -1.5\), \(b_1 = 0.7\):  
\[
z = b_0 + b_1x_1 = -1.5 + 2.1 = 0.6
\]

4. Вычисляем вероятность:  
\[
P(y = 1) = \frac{1}{1 + e^{-0.6}} \approx 0.645
\]

Ответ: 64.5\%


\subsection*{Задача 3: Утечка газа}

\textbf{Условие:}  
На химическом заводе нужно спрогнозировать, есть ли утечка газа в системе на основе двух факторов:  
- \(x_1\): температура трубы (в градусах);  
- \(x_2\): давление внутри трубы (в барах).  

Известные данные:  
\[
\begin{aligned}
    &\text{Ситуация 1: } x_1 = 500, x_2 = 100, \text{ утечка (}\, y = 1). \\
    &\text{Ситуация 2: } x_1 = 300, x_2 = 80, \text{ нет утечки (}\, y = 0). \\
    &\text{Ситуация 3: } x_1 = 400, x_2 = 90, \text{ утечка (}\, y = 1).
\end{aligned}
\]

Определите, будет ли утечка при \(x_1 = 450\) и \(x_2 = 85\). Используйте коэффициенты \(b_0 = -30\), \(b_1 = 0.05\), \(b_2 = 0.1\).

\textbf{Решение:}  

1. Записываем логистическую функцию:  
\[
P(y = 1) = \frac{1}{1 + e^{-(b_0 + b_1x_1 + b_2x_2)}}.
\]

2. Подставляем значения \(x_1 = 450\), \(x_2 = 85\):  
\[
z = b_0 + b_1x_1 + b_2x_2 = -30 + 0.05 \cdot 450 + 0.1 \cdot 85 = -30 + 22.5 + 8.5 = 1.
\]

3. Вычисляем вероятность:  
\[
P(y = 1) = \frac{1}{1 + e^{-1}} \approx 0.731.
\]

4. Так как \(P(y = 1) > 0.5\), утечка будет.  
Ответ: утечка будет.

\section{Алгоритмы Passive-Aggressive (PA) в линейной классификации}
\subsection*{Базовые сведения.}

Алгоритмы Passive-Aggressive (PA) являются онлайн-алгоритмами для обучения линейных моделей классификации.
Эти алгоритмы предназначены для обработки данных в режиме реального времени, где модель обновляется по мере поступления новых данных. PA-алгоритмы широко используются в задачах, где данные поступают последовательно, и требуется быстро адаптироваться к новой информации.

\subsection*{Классификафия PA алгоритмов}

PA-алгоритмы балансируют между "пассивным" и "агрессивным" обновлением весов модели:

PA-I (Passive-Aggressive I): Обновляет веса только в случае ошибочной классификации, используя минимальное изменение весов для исправления ошибки.

PA-II (Passive-Aggressive II): Всегда обновляет веса, но размер обновления зависит от правильности классификации и параметра регуляризации C.

\subsection*{Математическая формулировка}

Для PA-I, Если $y_t(w_t \cdot x_t) < 1$, $\eta = \frac{1 - y_t(w_t \cdot x_t)}{||x_t||^2}$

\[
    w_{t+1} = w_t + \eta y_t x_t
\]


Для PA-II
\[
\eta = \frac{1 - y_t(w_t \cdot x_t)}{C||x_t||^2 + ||x_t||^2}
\]

\[
    w_{t+1} = w_t + \eta y_t x_t
\]


\subsection*{Шаги алгоритма}

1) Инициализация: Начальная инициализация весов модели (обычно нулевой вектор).

2) Обработка каждого примера:

Получить входной вектор $x$ и метку $y$ $(y \in \{−1,+1\})$.

Вычислить предсказание: $y_{\text{pred}} = \sign (w^T x)$

Если $y_{\text{pred}} \ne y$, произошла ошибка, обновить веса согласно PA-I или PA-II.

3) Завершение: После обработки всех примеров модель готова к использованию для классификации новых данных.

\subsection*{Применения PA}

Текстовая классификация: PA-алгоритмы хорошо подходят для задач классификации текстов, таких как спам-фильтрация и анализ sentiment.

Рекомендательные системы: Используются для рекомендации товаров, фильмов и музыки.

Обработка потоковых данных: Эффективны в обработке данных в реальном времени, например, в анализе социальных сетей и торговых данных.


\subsection*{Задача 1: Обновление весов в PA-I}

\textbf{Условие:}  

Начальные веса модели $w = (0, 0)$

Входной вектор $x = (1, 2)$

Метка $y = 1$

Предсказание было ошибочным.

\textbf{Решение:}

1. Вычислим скалярное произведение:
\[
    w \cdot x = 0 \cross 1 + 0 \cross 2 = 0
\]


2. Вычислим $y \cross (w \cdot x)$
\[
y \cross (w \cdot x) = 1 \cross 0 = 0
\]

3. Вычислим $\eta$:

\[
    \eta = \frac{1 - y\cross(w \cdot x)}{||x||^2} = \frac{1 - 0}{1^2 + 2^2} = \frac{1}{5} = 0.2
\]

4. Обновим веса

\[
    w_{\text{new}} = w + \eta \cross y \cross x = (0, 0) + 0.2 \cross 1 \cross (1, 2)  = (0.2, 0.4)
\]

\subsection*{Задача 2: Обновление весов в PA-II}

\textbf{Условие:}

Начальные веса модели $w = (1, -1)$

Входной вектор $x = (2, 1)$

Метка $y = -1$

Параметр регуляризации $C = 0.5$

Предсказание ошибочным.


\textbf{Решение:}

1. Вычислим скалярное произведение:
\[
    w \cdot x = 1 \cross 2 + (-1) \cross 1 = 2 - 1 = 1
\]


2. Вычислим $y \cross (w \cdot x)$
\[
    y \cross (w \cdot x) = (-1) \cross 1 = -1
\]


3. Вычислим \eta
\[
    \eta = \frac{1 - y\cross(w \cdot x)}{C||x||^2 + ||x||^2} = \frac{1 - (-1)}{0.5 \cross (2^2 + 1^2)} = \frac{2}{0.5 \cross 5 + 5} = \frac{2}{7.5} \eqiv 0.26
\]

4. Обновим веса

\[
    w_{\text{new}} = w + \eta \cross y \cross x = (1, -1) + 0.26 \cross (-1) \cross (1, 1)  = (1 - 0.53, -1 - 0.26) = (0.46, -1,26)
\]

\subsection*{Задача 3: Сравнение PA-I и PA-II}

\textbf{Условие:}  
Сравните алгоритмы PA-I и PA-II в терминах обновления весов при правильной и ошибочной классификации. В каких случаях PA-II может быть предпочтительнее PA-I и наоборот? Объясните, используя математические формулы и примеры.
\textbf{Решение:}  
PA-I (Passive-Aggressive I):

Обновляет веса только в случае ошибки классификации.
Использует минимальное изменение весов для исправления ошибки.

\[
    \eta = \frac{1 - y_t\cross(w_t \cdot x_t)}{||x_t||^2}
\]

Если  $y \cross (w \cdot x) \ge 1$, обновление не происходит (пассивное поведение).

Если  $y \cross (w \cdot x) < 1$, обновление не происходит (агрессивное поведение).

PA-I предпочтительнее в случаях, когда нужно минимизировать обновления и поддерживать стабильность модели, если ошибок нет.


Не обновляет веса, если предсказание правильное, это позволяет PA-II постепенно адаптироваться к новым данным, даже если предсказание было правильным


PA-II (Passive-Aggressive II):
Всегда обновляет веса, но размер обновления зависит от уверенности предсказания.


\[
\eta = \frac{1 - y_t(w_t \cdot x_t)}{C||x_t||^2 + ||x_t||^2}
\]

Где $C$ - параметр регуляризации, который контролирует "агрессивность" обновления.


Обновляет веса даже при правильной классификации, но с небольшим шагом ($\eta$ мало).
Это позволяет PA-II постепенно адаптироваться к новым данным, даже если предсказание было правильным.

\section*{Обобщённые линейные модели (GLM)}

Обобщённые линейные модели расширяют линейную регрессию для оперирования целевыми переменными, которые обладают различными распределениями. Такие модели состоят из трёх компонентов:
\begin{itemize}
    \item Систематической части: линейного предсказателя $\eta = X\beta$, где $X$ — это матрица признаков, а $\beta$ — вектор коэффициентов.
    \item Случайной части: распределение выборки, например нормальное, Пуассоновское, биномиальное и т.д.
    \item Функции связи $g(\cdot)$: увязывает средний ответ $E[Y]$ с линейным предсказателем $\eta$ через $g(E[Y]) = \eta$.
\end{itemize}

\section*{Функции связи}

Функции связи преобразуют линейную комбинацию объясняющих переменных в шкалу, которая уместна для распределения отклика. Ниже описаны несколько популярных функций связи:

\subsection*{Логистическая функция связи}

Используется в логистической регрессии для двоичных классификаций. Функция логистической связи представлена следующим образом:
\[
g(\mu) = \log \left( \frac{\mu}{1-\mu} \right)
\]
где $\mu = E[Y]$ и $Y \sim \text{Bernoulli}(p)$.

\section*{Логистическая функция и сигмоида}

Логистическая функция связи часто представляется в виде сигмоидной функции \( \sigma(t) \), которая преобразует любое вещественное число в значение в диапазоне от 0 до 1:

\[
\sigma(t) = \frac{1}{1 + e^{-t}}
\]

где \( t = X\beta \), а \( X\beta \) — это линейный предсказатель, комбинация независимых переменных и их коэффициентов.

\section*{Применение в логистической регрессии}

Задача логистической регрессии заключается в оценке вероятности принадлежности объекта к одному из двух классов. Вероятность успешного исхода определяется как:

\[
P(Y=1 | X) = \sigma(X\beta) = \frac{1}{1 + e^{-(X\beta)}}
\]

Кроме того, вероятность принадлежности ко второму классу:

\[
P(Y=0 | X) = 1 - \sigma(X\beta)
\]

Таким образом, логистическая функция связи позволяет задействовать линейные модели в задачах нелинейной классификации.

\subsection*{Пробитная функция связи}

Пробитная связь применима как альтернатива логистической для задач бинарной классификации. Она определяется через обратную функцию нормального распределения:
\[
g(\mu) = \Phi^{-1}(\mu)
\]
где $\Phi^{-1}(\cdot)$ — обратная функция стандартного нормального распределения.

\section*{Сравнение с логистической функцией связи}

Пробитная и логистическая функции связи очень похожи и часто дают схожие результаты в задачах бинарной классификации. Следует отметить различие в функциональной форме: в пробитной регрессии используется нормальное распределение, в то время как в логистической — логистическое распределение.

\section*{Применение}

Пробитная функция связи находит применение в экономиках и финансах, особенно когда распределение ошибок предполагается нормальным. Она известна в анализе бинарных выборов, таких как покупательское поведение или инвестиционные решения.

\subsection*{Логарифмическая функция связи}

Часто используется в Пуассоновской регрессии и моделировании счётных данных:
\[
g(\mu) = \log(\mu)
\]
Подходит для моделирования данных, у которых средний уровень экспоненциально увеличивается.

\section*{Применение в моделях}

Логарифмическая функция связи часто используется в:

\begin{itemize}
    \item \textbf{Пуассоновской регрессии:} Моделирование частоты событий, которые происходят в фиксированное количество времени, например, количество звонков в колл-центр за час.
    \item \textbf{Гамма-регрессии:} Работает с положительными вещественными данными, такими как время до события или расходы.
\end{itemize}

В обобщённой линейной модели (GLM) с логарифмической функцией связи, линейный предсказатель \(X\beta\) связан с ожиданием зависимой переменной через:

\[
\log(\mu) = X\beta
\]

или, эквивалентно,

\[
\mu = e^{X\beta}
\]

\section*{Интерпретация и особенности}

Логарифмическая функция связи позволяет моделям учитывать экспоненциальные изменения в данных, что делает её мощным инструментом для анализа данных, в которых изменения варьируются в широком диапазоне.

\subsection*{Идентичная функция связи}

В линейной регрессии используется идентичная функция связи, что делает предсказание тождественным линейному предсказателю:
\[
g(\mu) = \mu
\]
\section*{Задача 1: Анализ страховых выплат}

\textbf{Сценарий:} 
Страховая компания анализирует данные о выплатах по страховым случаям. Необходимо понять, как разные зависимости признаков влияют на выплату. Имеется информация о возрастах клиентов, продолжительности страховки и числе страховых случаев.

\textbf{Вопрос:} 
Какая функция связи будет наиболее подходящей для моделирования положительных страховых выплат?

\textbf{Решение:} 
Для задачи прогнозирования средних положительных величин, как страховые выплаты, часто используется гамма-регрессия. Здесь логарифмическая функция связи будет уместной:
\[
g(\mu) = \log(\mu)
\]
Причина в том, что логарифмическая функция связи позволяет адекватно моделировать данные с ненормальным распределением, характеризующиеся только положительными значениями и результатами, зависящими от экспоненциального роста.

\section*{Задача 2: Классификация рисков клиентов}

\textbf{Сценарий:} 
Финансовая организация хочет классифицировать клиентов по вероятности неудачного возвращения кредита. Данные включают демографические характеристики, кредитную историю и текущие обязательства.

\textbf{Вопрос:} 
Какая функция связи наиболее подходит для логистической регрессии, применимой для двоичной классификации? Предположите, что выходные данные — вероятность неудачного погашения кредита.

\textbf{Решение:} 
Для задач, связанных с вероятностными предсказаниями, логистическая функция связи — лучший выбор:
\[
g(\mu) = \log \left( \frac{\mu}{1-\mu} \right)
\]
где $\mu = E[Y]$, отражает вероятность нахождения клиента в группе "рискованных". Логистическая функция переводит значения в диапазон от 0 до 1, который интерпретируется как вероятность принадлежности к классу.
